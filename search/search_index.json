{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Inteligencia Artificial y Big Data \u00b6 Apuntes realizados para el curso de especialista de Inteligencia Artificial y Big Data impartido en el IES Severo Ochoa de Elche. En este sitio web podr\u00e1s consultas los apuntes y ejercicios trabajados durante el curso. Despliega el men\u00fa de la izquierda para consultar los materiales.","title":"Inicio"},{"location":"index.html#inteligencia-artificial-y-big-data","text":"Apuntes realizados para el curso de especialista de Inteligencia Artificial y Big Data impartido en el IES Severo Ochoa de Elche. En este sitio web podr\u00e1s consultas los apuntes y ejercicios trabajados durante el curso. Despliega el men\u00fa de la izquierda para consultar los materiales.","title":"Inteligencia Artificial y Big Data"},{"location":"apuntes/arquitecturas01.html","text":"Arquitecturas Big Data \u00b6 Ya sabemos en qu\u00e9 consiste Big Data, y que dentro de sus 5V, dos de las m\u00e1s importantes son el volumen y la velocidad . Para cumplir con estas necesidades, necesitamos una infraestructura que dote a nuestras aplicaciones de toda la potencia y robustez necesarias. Caracter\u00edsticas \u00b6 Escalabilidad : permite aumentar f\u00e1cilmente las capacidades de procesamiento y almacenamiento de datos. Tolerancia a fallos : garantiza la disponibilidad del sistema, aunque se produzcan fallos en algunas de las m\u00e1quinas. Datos distribuidos : los datos est\u00e1n almacenados entre diferentes m\u00e1quinas evitando as\u00ed el problema de almacenar grandes vol\u00famenes de datos. Procesamiento distribuido : el tratamiento de los datos se realiza entre diferentes m\u00e1quinas para mejorar los tiempos de ejecuci\u00f3n y dotar al sistema de escalabilidad. Localidad del dato : los datos a trabajar y los procesos que los tratan deben estar cerca para evitar las transmisiones por red que a\u00f1aden latencias y aumentan los tiempos de ejecuci\u00f3n. Tipos de arquitecturas \u00b6 https://www.futurespace.es/como-disenar-una-arquitectura-big-data-y-no-morir-en-el-intento https://blog.powerdata.es/el-valor-de-la-gestion-de-datos/los-pilares-de-la-gestion-del-big-data-y-arquitectura-big-data Debido a que las empresas disponen de un volumen cada vez mayor de datos y a la necesidad de analizarlos y obtener valor de ellos lo antes posible, surge la necesidad de definir nuevas arquitecturas para cubrir casos de uso distintos a los que hab\u00eda hasta el momento. Las arquitecturas m\u00e1s comunes en estos proyectos son principalmente dos: Lambda y Kappa . La principal diferencia entre ambas son los flujos de tratamiento de datos que intervienen. Un par de conceptos que tenemos que definir antes de ver las caracter\u00edsticas de ambas, son el procesamiento batch y el procesamiento en streaming. Procesamiento Batch \u00b6 Batch hace referencia a un proceso en el que intervienen un conjunto de datos y que tiene un inicio y un fin en el tiempo. https://www.franciscojavierpulido.com/2013/11/paradigmas-bigdata-el-procesamiento.html Procesamiento en Streaming \u00b6 Un procesamiento es de tipo streaming cuando est\u00e1 continuamente recibiendo y tratando nueva informaci\u00f3n seg\u00fan va llegando sin tener un fin en lo referente al apartado temporal. Arquitectura Lambda \u00b6 Representada mediante la letra griega, apareci\u00f3 en el a\u00f1o 2012 y se atribuye a Nathan Marz . Nathan Marz La defini\u00f3 en base a su experiencia en sistemas de tratamiento de datos distribuidos durante su etapa como empleado en las empresas Backtype y Twitter, y est\u00e1 inspirada en su art\u00edculo How to beat the CAP theorem . Su objetivo era tener un sistema robusto tolerante a fallos, tanto humanos como de hardware, que fuera linealmente escalable y que permitiese realizar escrituras y lecturas con baja latencia. Para ello, se compone de tres capas: Capa batch : se encarga de (a) gestionar los datos hist\u00f3ricos y (b) recalcular los resultados, por ejemplo, de los modelos de machine learning . Capa de streaming / speed : Capa de serving : permite la consulta de los resultados enviados desde las dos capas anteriores. The batch layer has two major tasks: (a) managing historical data; and (b) recomputing results such as machine learning models. Specifically, the batch layer receives arriving data, combines it with historical data and recomputes results by iterating over the entire combined data set. The batch layer operates on the full data and thus allows the system to produce the most accurate results. However, the results come at the cost of high latency due to high computation time. The speed layer is used in order to provide results in a low-latency, near real-time fashion. The speed layer receives the arriving data and performs incremental updates to the batch layer results. Thanks to the incremental algorithms implemented at the speed layer, computation cost is significantly reduced. Podemos ver un esquema de la arquitectura en el siguiente gr\u00e1fico: https://www.paradigmadigital.com/techbiz/de-lambda-a-kappa-evolucion-de-las-arquitecturas-big-data/ El flujo de trabajo es el siguiente: La nueva informaci\u00f3n recogida por el sistema se env\u00eda tanto a la capa de batch como a la capa de streaming (denominada como Speed Layer en la imagen anterior). En la capa batch (Batch Layer) se gestiona la informaci\u00f3n en crudo, es decir, sin modificar. Los datos nuevos se a\u00f1aden a los ya existentes. Seguidamente se hace un tratamiento mediante un proceso batch cuyo resultado ser\u00e1n las denominadas Batch Views, que se usar\u00e1n en la capa que sirve los datos para ofrecer la informaci\u00f3n ya transformada al exterior. La capa que sirve los datos o Serving Layer, indexa las Batch Views generadas en el paso anterior de forma que puedan ser consultadas con baja latencia. La capa de streaming o Speed Layer, compensa la alta latencia de las escrituras que ocurre en la serving layer y solo tiene en cuenta los datos nuevos. Finalmente, la respuesta a las consultas realizadas se construye combinando los resultados de las Batch Views y de las vistas en tiempo real (Real-time Views), las cuales se han generado en el paso anterior. https://www.ericsson.com/en/blog/2015/11/data-processing-architectures--lambda-and-kappa Arquitectura Kappa \u00b6 https://www.treelogic.com/es/Arquitectura_Kappa.html El t\u00e9rmino Arquitectura Kappa, representada por la letra , fue introducido en 2014 por Jay Kreps en su art\u00edculo Questioning the Lambda Architecture. En \u00e9l se\u00f1ala los posibles puntos \u201cd\u00e9biles\u201d de la Arquitectura Lambda y c\u00f3mo solucionarlos mediante una evoluci\u00f3n. Su propuesta consiste en eliminar la capa batch dejando solamente la capa de streaming. Esta capa, a diferencia de la de tipo batch, no tiene un comienzo ni un fin desde un punto de vista temporal y est\u00e1 continuamente procesando nuevos datos a medida que van llegando. Como un proceso batch se puede entender como un stream acotado, podr\u00edamos decir que el procesamiento batch es un subconjunto del procesamiento en streaming. Esta evoluci\u00f3n consiste en una simplificaci\u00f3n de la Arquitectura Lambda, en la que se elimina la capa batch y todo el procesamiento se realiza en una sola capa denominada de tiempo real o Real-time Layer, dando soporte a procesamientos tanto batch como en tiempo real. Podemos decir que sus cuatro pilares principales son los siguientes: Todo es un stream: las operaciones batch son un subconjunto de las operaciones de streaming, por lo que todo puede ser tratado como un stream. Los datos de partida no se modifican: los datos son almacenados sin ser transformados y las vistas se derivan de ellos. Un estado concreto puede ser recalculado puesto que la informaci\u00f3n de origen no se modifica. Solo existe un flujo de procesamiento: puesto que mantenemos un solo flujo, el c\u00f3digo, el mantenimiento y la actualizaci\u00f3n del sistema se ven reducidos considerablemente. Posibilidad de volver a lanzar un procesamiento: se puede modificar un procesamiento concreto y su configuraci\u00f3n para variar los resultados obtenidos partiendo de los mismos datos de entrada. Como requisito previo a cumplir, se tiene que garantizar que los eventos se leen y almacenan en el orden en el que se han generado. De esta forma, podremos variar un procesamiento concreto partiendo de una misma versi\u00f3n de los datos. Casos de uso \u00b6 \u00bfQu\u00e9 arquitectura se adapta mejor a nuestro problema? \u00bfC\u00faal encaja mejor en nuestro modelo de negocio?. https://www.ericsson.com/en/blog/2015/11/data-processing-architectures--lambda-and-kappa-examples Por lo general, no existe una \u00fanica respuesta. La arquitectura Lambda es m\u00e1s vers\u00e1til y es capaz de cubrir un mayor n\u00famero de casos, muchos de ellos que requieren incluso procesamiento en tiempo real. Una pregunta que debemos plantearnos para poder decidir es, \u00bfel an\u00e1lisis y el procesamiento que vamos a realizar en las capas batch y streaming es el mismo? En ese caso la opci\u00f3n m\u00e1s acertada ser\u00eda la Arquitectura Kappa. Como ejemplo real de esta arquitectura podr\u00edamos poner un sistema de geolocalizaci\u00f3n de usuarios por la cercan\u00eda a una antena de telefon\u00eda m\u00f3vil. Cada vez que se aproximase a una antena que le diese cobertura se generar\u00eda un evento. Este evento se procesar\u00eda en la capa de streaming y servir\u00eda para pintar sobre un mapa su desplazamiento respecto a su posici\u00f3n anterior. Sin embargo, en otras ocasiones necesitaremos acceder a todo el conjunto de datos sin penalizar el rendimiento por lo que la Arquitectura Lambda puede ser m\u00e1s apropiada e incluso m\u00e1s f\u00e1cil de implementar. Tambi\u00e9n nos inclinaremos hacia una Arquitectura Lambda si nuestros algoritmos de batch y streaming generan resultados muy distintos, como puede suceder con operaciones de procesamiento pesado o en modelos de Machine Learning. Un caso de uso real para una arquitectura Lambda podr\u00eda ser un sistema que recomiende libros en funci\u00f3n de los gustos de los usuarios. Por un lado, tendr\u00eda una capa batch encargada de entrenar el modelo e ir mejorando las predicciones; y por otro, una capa streaming capaz de encargarse de las valoraciones en tiempo real. Para finalizar, hay que destacar lo r\u00e1pido que evolucionan los casos de uso que queremos cubrir con nuestras soluciones Big Data, y eso supone que hay que adaptarse a ellos lo antes posible. Cada problema a resolver tiene unos condicionantes particulares y en muchos casos habr\u00e1 que evolucionar la arquitectura que est\u00e1bamos utilizando hasta el momento, o como se suele decir: \u201crenovarse o morir\u201d. Referencias \u00b6 Arquitectura Big Data: \u00bfen qu\u00e9 consiste y para qu\u00e9 se utiliza? What Is Lambda Architecture? Arquitectura Lambda vs Arquitectura Kappa https://medium.com/dataprophet/4-big-data-architectures-data-streaming-lambda-architecture-kappa-architecture-and-unifield-d9bcbf711eb9","title":"1.- Arquitecturas"},{"location":"apuntes/arquitecturas01.html#arquitecturas-big-data","text":"Ya sabemos en qu\u00e9 consiste Big Data, y que dentro de sus 5V, dos de las m\u00e1s importantes son el volumen y la velocidad . Para cumplir con estas necesidades, necesitamos una infraestructura que dote a nuestras aplicaciones de toda la potencia y robustez necesarias.","title":"Arquitecturas Big Data"},{"location":"apuntes/arquitecturas01.html#caracteristicas","text":"Escalabilidad : permite aumentar f\u00e1cilmente las capacidades de procesamiento y almacenamiento de datos. Tolerancia a fallos : garantiza la disponibilidad del sistema, aunque se produzcan fallos en algunas de las m\u00e1quinas. Datos distribuidos : los datos est\u00e1n almacenados entre diferentes m\u00e1quinas evitando as\u00ed el problema de almacenar grandes vol\u00famenes de datos. Procesamiento distribuido : el tratamiento de los datos se realiza entre diferentes m\u00e1quinas para mejorar los tiempos de ejecuci\u00f3n y dotar al sistema de escalabilidad. Localidad del dato : los datos a trabajar y los procesos que los tratan deben estar cerca para evitar las transmisiones por red que a\u00f1aden latencias y aumentan los tiempos de ejecuci\u00f3n.","title":"Caracter\u00edsticas"},{"location":"apuntes/arquitecturas01.html#tipos-de-arquitecturas","text":"https://www.futurespace.es/como-disenar-una-arquitectura-big-data-y-no-morir-en-el-intento https://blog.powerdata.es/el-valor-de-la-gestion-de-datos/los-pilares-de-la-gestion-del-big-data-y-arquitectura-big-data Debido a que las empresas disponen de un volumen cada vez mayor de datos y a la necesidad de analizarlos y obtener valor de ellos lo antes posible, surge la necesidad de definir nuevas arquitecturas para cubrir casos de uso distintos a los que hab\u00eda hasta el momento. Las arquitecturas m\u00e1s comunes en estos proyectos son principalmente dos: Lambda y Kappa . La principal diferencia entre ambas son los flujos de tratamiento de datos que intervienen. Un par de conceptos que tenemos que definir antes de ver las caracter\u00edsticas de ambas, son el procesamiento batch y el procesamiento en streaming.","title":"Tipos de arquitecturas"},{"location":"apuntes/arquitecturas01.html#procesamiento-batch","text":"Batch hace referencia a un proceso en el que intervienen un conjunto de datos y que tiene un inicio y un fin en el tiempo. https://www.franciscojavierpulido.com/2013/11/paradigmas-bigdata-el-procesamiento.html","title":"Procesamiento Batch"},{"location":"apuntes/arquitecturas01.html#procesamiento-en-streaming","text":"Un procesamiento es de tipo streaming cuando est\u00e1 continuamente recibiendo y tratando nueva informaci\u00f3n seg\u00fan va llegando sin tener un fin en lo referente al apartado temporal.","title":"Procesamiento en Streaming"},{"location":"apuntes/arquitecturas01.html#arquitectura-lambda","text":"Representada mediante la letra griega, apareci\u00f3 en el a\u00f1o 2012 y se atribuye a Nathan Marz . Nathan Marz La defini\u00f3 en base a su experiencia en sistemas de tratamiento de datos distribuidos durante su etapa como empleado en las empresas Backtype y Twitter, y est\u00e1 inspirada en su art\u00edculo How to beat the CAP theorem . Su objetivo era tener un sistema robusto tolerante a fallos, tanto humanos como de hardware, que fuera linealmente escalable y que permitiese realizar escrituras y lecturas con baja latencia. Para ello, se compone de tres capas: Capa batch : se encarga de (a) gestionar los datos hist\u00f3ricos y (b) recalcular los resultados, por ejemplo, de los modelos de machine learning . Capa de streaming / speed : Capa de serving : permite la consulta de los resultados enviados desde las dos capas anteriores. The batch layer has two major tasks: (a) managing historical data; and (b) recomputing results such as machine learning models. Specifically, the batch layer receives arriving data, combines it with historical data and recomputes results by iterating over the entire combined data set. The batch layer operates on the full data and thus allows the system to produce the most accurate results. However, the results come at the cost of high latency due to high computation time. The speed layer is used in order to provide results in a low-latency, near real-time fashion. The speed layer receives the arriving data and performs incremental updates to the batch layer results. Thanks to the incremental algorithms implemented at the speed layer, computation cost is significantly reduced. Podemos ver un esquema de la arquitectura en el siguiente gr\u00e1fico: https://www.paradigmadigital.com/techbiz/de-lambda-a-kappa-evolucion-de-las-arquitecturas-big-data/ El flujo de trabajo es el siguiente: La nueva informaci\u00f3n recogida por el sistema se env\u00eda tanto a la capa de batch como a la capa de streaming (denominada como Speed Layer en la imagen anterior). En la capa batch (Batch Layer) se gestiona la informaci\u00f3n en crudo, es decir, sin modificar. Los datos nuevos se a\u00f1aden a los ya existentes. Seguidamente se hace un tratamiento mediante un proceso batch cuyo resultado ser\u00e1n las denominadas Batch Views, que se usar\u00e1n en la capa que sirve los datos para ofrecer la informaci\u00f3n ya transformada al exterior. La capa que sirve los datos o Serving Layer, indexa las Batch Views generadas en el paso anterior de forma que puedan ser consultadas con baja latencia. La capa de streaming o Speed Layer, compensa la alta latencia de las escrituras que ocurre en la serving layer y solo tiene en cuenta los datos nuevos. Finalmente, la respuesta a las consultas realizadas se construye combinando los resultados de las Batch Views y de las vistas en tiempo real (Real-time Views), las cuales se han generado en el paso anterior. https://www.ericsson.com/en/blog/2015/11/data-processing-architectures--lambda-and-kappa","title":"Arquitectura Lambda"},{"location":"apuntes/arquitecturas01.html#arquitectura-kappa","text":"https://www.treelogic.com/es/Arquitectura_Kappa.html El t\u00e9rmino Arquitectura Kappa, representada por la letra , fue introducido en 2014 por Jay Kreps en su art\u00edculo Questioning the Lambda Architecture. En \u00e9l se\u00f1ala los posibles puntos \u201cd\u00e9biles\u201d de la Arquitectura Lambda y c\u00f3mo solucionarlos mediante una evoluci\u00f3n. Su propuesta consiste en eliminar la capa batch dejando solamente la capa de streaming. Esta capa, a diferencia de la de tipo batch, no tiene un comienzo ni un fin desde un punto de vista temporal y est\u00e1 continuamente procesando nuevos datos a medida que van llegando. Como un proceso batch se puede entender como un stream acotado, podr\u00edamos decir que el procesamiento batch es un subconjunto del procesamiento en streaming. Esta evoluci\u00f3n consiste en una simplificaci\u00f3n de la Arquitectura Lambda, en la que se elimina la capa batch y todo el procesamiento se realiza en una sola capa denominada de tiempo real o Real-time Layer, dando soporte a procesamientos tanto batch como en tiempo real. Podemos decir que sus cuatro pilares principales son los siguientes: Todo es un stream: las operaciones batch son un subconjunto de las operaciones de streaming, por lo que todo puede ser tratado como un stream. Los datos de partida no se modifican: los datos son almacenados sin ser transformados y las vistas se derivan de ellos. Un estado concreto puede ser recalculado puesto que la informaci\u00f3n de origen no se modifica. Solo existe un flujo de procesamiento: puesto que mantenemos un solo flujo, el c\u00f3digo, el mantenimiento y la actualizaci\u00f3n del sistema se ven reducidos considerablemente. Posibilidad de volver a lanzar un procesamiento: se puede modificar un procesamiento concreto y su configuraci\u00f3n para variar los resultados obtenidos partiendo de los mismos datos de entrada. Como requisito previo a cumplir, se tiene que garantizar que los eventos se leen y almacenan en el orden en el que se han generado. De esta forma, podremos variar un procesamiento concreto partiendo de una misma versi\u00f3n de los datos.","title":"Arquitectura Kappa"},{"location":"apuntes/arquitecturas01.html#casos-de-uso","text":"\u00bfQu\u00e9 arquitectura se adapta mejor a nuestro problema? \u00bfC\u00faal encaja mejor en nuestro modelo de negocio?. https://www.ericsson.com/en/blog/2015/11/data-processing-architectures--lambda-and-kappa-examples Por lo general, no existe una \u00fanica respuesta. La arquitectura Lambda es m\u00e1s vers\u00e1til y es capaz de cubrir un mayor n\u00famero de casos, muchos de ellos que requieren incluso procesamiento en tiempo real. Una pregunta que debemos plantearnos para poder decidir es, \u00bfel an\u00e1lisis y el procesamiento que vamos a realizar en las capas batch y streaming es el mismo? En ese caso la opci\u00f3n m\u00e1s acertada ser\u00eda la Arquitectura Kappa. Como ejemplo real de esta arquitectura podr\u00edamos poner un sistema de geolocalizaci\u00f3n de usuarios por la cercan\u00eda a una antena de telefon\u00eda m\u00f3vil. Cada vez que se aproximase a una antena que le diese cobertura se generar\u00eda un evento. Este evento se procesar\u00eda en la capa de streaming y servir\u00eda para pintar sobre un mapa su desplazamiento respecto a su posici\u00f3n anterior. Sin embargo, en otras ocasiones necesitaremos acceder a todo el conjunto de datos sin penalizar el rendimiento por lo que la Arquitectura Lambda puede ser m\u00e1s apropiada e incluso m\u00e1s f\u00e1cil de implementar. Tambi\u00e9n nos inclinaremos hacia una Arquitectura Lambda si nuestros algoritmos de batch y streaming generan resultados muy distintos, como puede suceder con operaciones de procesamiento pesado o en modelos de Machine Learning. Un caso de uso real para una arquitectura Lambda podr\u00eda ser un sistema que recomiende libros en funci\u00f3n de los gustos de los usuarios. Por un lado, tendr\u00eda una capa batch encargada de entrenar el modelo e ir mejorando las predicciones; y por otro, una capa streaming capaz de encargarse de las valoraciones en tiempo real. Para finalizar, hay que destacar lo r\u00e1pido que evolucionan los casos de uso que queremos cubrir con nuestras soluciones Big Data, y eso supone que hay que adaptarse a ellos lo antes posible. Cada problema a resolver tiene unos condicionantes particulares y en muchos casos habr\u00e1 que evolucionar la arquitectura que est\u00e1bamos utilizando hasta el momento, o como se suele decir: \u201crenovarse o morir\u201d.","title":"Casos de uso"},{"location":"apuntes/arquitecturas01.html#referencias","text":"Arquitectura Big Data: \u00bfen qu\u00e9 consiste y para qu\u00e9 se utiliza? What Is Lambda Architecture? Arquitectura Lambda vs Arquitectura Kappa https://medium.com/dataprophet/4-big-data-architectures-data-streaming-lambda-architecture-kappa-architecture-and-unifield-d9bcbf711eb9","title":"Referencias"},{"location":"apuntes/arquitecturas02.html","text":"Cloud Computing \u00b6 Computaci\u00f3n en la nube for ( int = 0 ; i < 30 ; i ++ ) { System . out . println ( \"Hola Mundo\" ); } Tipos de arquitectura seg\u00fan la infraestructura \u00b6 Arquitecturas on premise \u00b6 Arquitecturas cloud \u00b6 Arquitecturas h\u00edbridas \u00b6 Referencias \u00b6 aaa","title":"2.- Cloud Computing"},{"location":"apuntes/arquitecturas02.html#cloud-computing","text":"Computaci\u00f3n en la nube for ( int = 0 ; i < 30 ; i ++ ) { System . out . println ( \"Hola Mundo\" ); }","title":"Cloud Computing"},{"location":"apuntes/arquitecturas02.html#tipos-de-arquitectura-segun-la-infraestructura","text":"","title":"Tipos de arquitectura seg\u00fan la infraestructura"},{"location":"apuntes/arquitecturas02.html#arquitecturas-on-premise","text":"","title":"Arquitecturas on premise"},{"location":"apuntes/arquitecturas02.html#arquitecturas-cloud","text":"","title":"Arquitecturas cloud"},{"location":"apuntes/arquitecturas02.html#arquitecturas-hibridas","text":"","title":"Arquitecturas h\u00edbridas"},{"location":"apuntes/arquitecturas02.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/arquitecturas03.html","text":"Amazon Web Services \u00b6 Referencias \u00b6 aaa","title":"3.- AWS"},{"location":"apuntes/arquitecturas03.html#amazon-web-services","text":"","title":"Amazon Web Services"},{"location":"apuntes/arquitecturas03.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/arquitecturas04.html","text":"AWS EC2 \u00b6 Referencias \u00b6 aaa","title":"4.- AWS EC2"},{"location":"apuntes/arquitecturas04.html#aws-ec2","text":"","title":"AWS EC2"},{"location":"apuntes/arquitecturas04.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/arquitecturas05.html","text":"Almacenamiento distribuido: AWS S3 \u00b6 Referencias \u00b6 aaa","title":"5.- AWS S3"},{"location":"apuntes/arquitecturas05.html#almacenamiento-distribuido-aws-s3","text":"","title":"Almacenamiento distribuido: AWS S3"},{"location":"apuntes/arquitecturas05.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/arquitecturas06.html","text":"Azure \u00b6 Referencias \u00b6 aaa","title":"6.- Azure"},{"location":"apuntes/arquitecturas06.html#azure","text":"","title":"Azure"},{"location":"apuntes/arquitecturas06.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado01.html","text":"Hadoop \u00b6 Las nuevas tecnolog\u00edas como Hadoop y Spark facilitan el trabajo y la gesti\u00f3n de un cluster de ordenadores. Hadoop puede escalar hasta miles de ordenadores creando un cluster con un almacenamiento con un orden de petabytes de informaci\u00f3n. Estas tecnolog\u00edas son las que realmente catalizan el Big Data . Apache Hadoop ( http://hadoop.apache.org/ ) es un framework que facilita el trabajo con un cluster de ordenadores. Sus caracter\u00edsticas son: Confiable: crea m\u00faltiples copias de los datos de manera autom\u00e1tica y, en caso de fallo, vuelve a desplegar la l\u00f3gica de procesamiento. Tolerante a fallos: tras detectar un fallo aplica una recuperaci\u00f3n autom\u00e1tica. Escalable: los datos y su procesamiento se distribuyen sobre un cluster de ordenadores (escalado horizontal) Portable: se puede instalar en todo tipos de hardware y sistemas operativos. Componentes \u00b6 El n\u00facleo se compone de: un sistema de ficheros distribuidos ( HDFS ). un gestor de recursos para el manejo del cluster ( YARN ) un sistema para ejecutar programas distribuidos a gran escala ( MapReduce ) Estos elementos permiten trabajar de casi la misma forma que si tuvi\u00e9ramos un sistema de fichero locales en nuestro ordenador personal, pero realmente los datos est\u00e1n repartidos entre miles de servidores. Sobre este conjunto de herramientas existe un ecosistema \"infinito\" con tecnolog\u00edas que facilitan el acceso, gesti\u00f3n y extensi\u00f3n del propio Hadoop. MapReduce \u00b6 Es el algoritmo que utiliza Hadoop para paralelizar las tareas. Un algoritmo MapReduce divide los datos, los procesa en paralelo, los reordena, combina y agrega de vuelta los resultados. Sin embargo, este algoritmo no casa bien con el an\u00e1lisis interactivo o programas iterativos, ya que persiste los datos en disco entre cada uno de los pasos del mismo, lo que con grandes datasets conlleva una penalizaci\u00f3n en el rendimiento. El siguiente gr\u00e1fico muestra un ejemplo de una empresa de juguete que fabrica juguetes de colores. Cuando un cliente compra un juguete desde la p\u00e1gina web, el pedido se almacena como un fichero en Hadoop con los colores de los juguetes adquiridos. Para averiguar cuantas unidades de cada color ha de preparar la f\u00e1brica, se emplea un algoritmo MapReduce para contar los colores: Como sugiere el nombre, el proceso se divide principalmente en dos fases: Fase de mapeo ( Map ) \u2014 Los documentos se parten en pares de clave/valor. Hasta que no se reduzca, podemos tener muchos duplicados. Fase de reducci\u00f3n ( Reduce ) \u2014 Es en cierta medida similar a un \"group by\" de SQL. Las ocurrencias similares se agrupan, y dependiendo de la funci\u00f3n de reducci\u00f3n, se puede crear un resultado diferente. En nuestro ejemplo queremos contar los colores, y eso es lo que devuelve nuestra funci\u00f3n. Realmente, es un proceso m\u00e1s complicado: Lectura de los ficheros de entrada. Pasar cada linea de forma separada al mapeador. El mapeador parsea los colores (claves) de cada fichero y produce un nuevo fichero para cada color con el n\u00famero de ocurrencias encontradas (valor), es decir, mapea una clave (color) con un valor (n\u00famero de ocurrencias). Para facilitar la agregaci\u00f3n, se ordenan las claves. La fase de reducci\u00f3n suma las ocurrencias de cada color y genera un fichero por clave con el total de cada color. Las claves se unen en un \u00fanico fichero de salida. No es oro todo lo que reluce Hadoop facilita el trabajo con grandes vol\u00famenes de datos, pero montar un cluster funcional no es una cosa trivial. Existen gestores de clusters que hacen las cosas un poco menos incom\u00f3das (como son YARN o Apache Mesos), aunque la tendencia es utilizar una soluci\u00f3n cloud que nos evita toda la instalaci\u00f3n y configuraci\u00f3n. Tal como comentamos al inicio, uno de los puntos d\u00e9biles de Hadoop es el trabajo con algoritmos iterativos, los cuales son fundamentales en la parte de IA. La soluci\u00f3n es el uso del framework Spark, que mejora el rendimiento por una orden de magnitud. Referencias \u00b6 aaa","title":"1.- Hadoop"},{"location":"apuntes/bdaplicado01.html#hadoop","text":"Las nuevas tecnolog\u00edas como Hadoop y Spark facilitan el trabajo y la gesti\u00f3n de un cluster de ordenadores. Hadoop puede escalar hasta miles de ordenadores creando un cluster con un almacenamiento con un orden de petabytes de informaci\u00f3n. Estas tecnolog\u00edas son las que realmente catalizan el Big Data . Apache Hadoop ( http://hadoop.apache.org/ ) es un framework que facilita el trabajo con un cluster de ordenadores. Sus caracter\u00edsticas son: Confiable: crea m\u00faltiples copias de los datos de manera autom\u00e1tica y, en caso de fallo, vuelve a desplegar la l\u00f3gica de procesamiento. Tolerante a fallos: tras detectar un fallo aplica una recuperaci\u00f3n autom\u00e1tica. Escalable: los datos y su procesamiento se distribuyen sobre un cluster de ordenadores (escalado horizontal) Portable: se puede instalar en todo tipos de hardware y sistemas operativos.","title":"Hadoop"},{"location":"apuntes/bdaplicado01.html#componentes","text":"El n\u00facleo se compone de: un sistema de ficheros distribuidos ( HDFS ). un gestor de recursos para el manejo del cluster ( YARN ) un sistema para ejecutar programas distribuidos a gran escala ( MapReduce ) Estos elementos permiten trabajar de casi la misma forma que si tuvi\u00e9ramos un sistema de fichero locales en nuestro ordenador personal, pero realmente los datos est\u00e1n repartidos entre miles de servidores. Sobre este conjunto de herramientas existe un ecosistema \"infinito\" con tecnolog\u00edas que facilitan el acceso, gesti\u00f3n y extensi\u00f3n del propio Hadoop.","title":"Componentes"},{"location":"apuntes/bdaplicado01.html#mapreduce","text":"Es el algoritmo que utiliza Hadoop para paralelizar las tareas. Un algoritmo MapReduce divide los datos, los procesa en paralelo, los reordena, combina y agrega de vuelta los resultados. Sin embargo, este algoritmo no casa bien con el an\u00e1lisis interactivo o programas iterativos, ya que persiste los datos en disco entre cada uno de los pasos del mismo, lo que con grandes datasets conlleva una penalizaci\u00f3n en el rendimiento. El siguiente gr\u00e1fico muestra un ejemplo de una empresa de juguete que fabrica juguetes de colores. Cuando un cliente compra un juguete desde la p\u00e1gina web, el pedido se almacena como un fichero en Hadoop con los colores de los juguetes adquiridos. Para averiguar cuantas unidades de cada color ha de preparar la f\u00e1brica, se emplea un algoritmo MapReduce para contar los colores: Como sugiere el nombre, el proceso se divide principalmente en dos fases: Fase de mapeo ( Map ) \u2014 Los documentos se parten en pares de clave/valor. Hasta que no se reduzca, podemos tener muchos duplicados. Fase de reducci\u00f3n ( Reduce ) \u2014 Es en cierta medida similar a un \"group by\" de SQL. Las ocurrencias similares se agrupan, y dependiendo de la funci\u00f3n de reducci\u00f3n, se puede crear un resultado diferente. En nuestro ejemplo queremos contar los colores, y eso es lo que devuelve nuestra funci\u00f3n. Realmente, es un proceso m\u00e1s complicado: Lectura de los ficheros de entrada. Pasar cada linea de forma separada al mapeador. El mapeador parsea los colores (claves) de cada fichero y produce un nuevo fichero para cada color con el n\u00famero de ocurrencias encontradas (valor), es decir, mapea una clave (color) con un valor (n\u00famero de ocurrencias). Para facilitar la agregaci\u00f3n, se ordenan las claves. La fase de reducci\u00f3n suma las ocurrencias de cada color y genera un fichero por clave con el total de cada color. Las claves se unen en un \u00fanico fichero de salida. No es oro todo lo que reluce Hadoop facilita el trabajo con grandes vol\u00famenes de datos, pero montar un cluster funcional no es una cosa trivial. Existen gestores de clusters que hacen las cosas un poco menos incom\u00f3das (como son YARN o Apache Mesos), aunque la tendencia es utilizar una soluci\u00f3n cloud que nos evita toda la instalaci\u00f3n y configuraci\u00f3n. Tal como comentamos al inicio, uno de los puntos d\u00e9biles de Hadoop es el trabajo con algoritmos iterativos, los cuales son fundamentales en la parte de IA. La soluci\u00f3n es el uso del framework Spark, que mejora el rendimiento por una orden de magnitud.","title":"MapReduce"},{"location":"apuntes/bdaplicado01.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado02.html","text":"HDFS \u00b6 Al almacenar datos en HDFS, una buena pr\u00e1ctica es crear un archivo con las cabeceras y otro con los datos Referencias \u00b6 aaa","title":"2.- HDFS"},{"location":"apuntes/bdaplicado02.html#hdfs","text":"Al almacenar datos en HDFS, una buena pr\u00e1ctica es crear un archivo con las cabeceras y otro con los datos","title":"HDFS"},{"location":"apuntes/bdaplicado02.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado03.html","text":"Hive \u00b6 Referencias \u00b6 aaa","title":"3.- Hive"},{"location":"apuntes/bdaplicado03.html#hive","text":"","title":"Hive"},{"location":"apuntes/bdaplicado03.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado04.html","text":"Flume / Sqoop \u00b6 Referencias \u00b6 aaa","title":"4.- Flume / Sqoop"},{"location":"apuntes/bdaplicado04.html#flume-sqoop","text":"","title":"Flume / Sqoop"},{"location":"apuntes/bdaplicado04.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado05.html","text":"Kafka \u00b6 Referencias \u00b6 aaa","title":"5.- Kafka"},{"location":"apuntes/bdaplicado05.html#kafka","text":"","title":"Kafka"},{"location":"apuntes/bdaplicado05.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado0601.html","text":"Spark \u00b6 Spark es un framework de computaci\u00f3n en cluster similar a MapReduce , pero que en vez de almacenar los datos en un sistema de ficheros distribuidos o utilizar un sistema de gesti\u00f3n de recursos, lo hace en memoria. En el caso de tener la necesidad de almacenar los datos o gestionar los recursos, se apoya en sistemas ya existentes como HDFS , YARN o Apache Mesos . Por lo tanto, Hadoop y Spark son sistemas complementarios. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7. Referencias \u00b6 aaa","title":"6.1.-Trabajando con Spark"},{"location":"apuntes/bdaplicado0601.html#spark","text":"Spark es un framework de computaci\u00f3n en cluster similar a MapReduce , pero que en vez de almacenar los datos en un sistema de ficheros distribuidos o utilizar un sistema de gesti\u00f3n de recursos, lo hace en memoria. En el caso de tener la necesidad de almacenar los datos o gestionar los recursos, se apoya en sistemas ya existentes como HDFS , YARN o Apache Mesos . Por lo tanto, Hadoop y Spark son sistemas complementarios. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7.","title":"Spark"},{"location":"apuntes/bdaplicado0601.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado0602.html","text":"Spark \u00b6 WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7. Referencias \u00b6 aaa","title":"6.2.-Spark RDD"},{"location":"apuntes/bdaplicado0602.html#spark","text":"WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7.","title":"Spark"},{"location":"apuntes/bdaplicado0602.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado0603.html","text":"Spark \u00b6 WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7. Referencias \u00b6 aaa","title":"6.3.-Spark Avanzado"},{"location":"apuntes/bdaplicado0603.html#spark","text":"WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7.","title":"Spark"},{"location":"apuntes/bdaplicado0603.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado0604.html","text":"Spark \u00b6 WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7. Referencias \u00b6 aaa","title":"6.4.-Spark SQL"},{"location":"apuntes/bdaplicado0604.html#spark","text":"WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7.","title":"Spark"},{"location":"apuntes/bdaplicado0604.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado0605.html","text":"Spark \u00b6 WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7. Referencias \u00b6 aaa","title":"6.5.-Spark Streaming I"},{"location":"apuntes/bdaplicado0605.html#spark","text":"WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7.","title":"Spark"},{"location":"apuntes/bdaplicado0605.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/bdaplicado0606.html","text":"Spark \u00b6 WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7. Referencias \u00b6 aaa","title":"6.6.-Spark Streaming II"},{"location":"apuntes/bdaplicado0606.html#spark","text":"WHAT IS SPARK? Spark is a cluster computing framework similar to MapReduce. Spark, however, doesn\u2019t handle the storage of files on the (distributed) file system itself, nor does it handle the resource management. For this it relies on systems such as the Hadoop File System, YARN, or Apache Mesos. Hadoop and Spark are thus complementary systems. For testing and development, you can even run Spark on your local system. HOW DOES SPARK SOLVE THE PROBLEMS OF MAPREDUCE? While we oversimplify things a bit for the sake of clarity, Spark creates a kind of shared RAM memory between the computers of your cluster. This allows the different workers to share variables (and their state) and thus eliminates the need to write the intermediate results to disk. More technically and more correctly if you\u2019re into that: Spark uses Resilient Distributed Datasets (RDD), which are a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a faulttolerant way.1 Because it\u2019s an in-memory system, it avoids costly disk operations. THE DIFFERENT COMPONENTS OF THE SPARK ECOSYSTEM Spark core provides a NoSQL environment well suited for interactive, exploratory analysis. Spark can be run in batch and interactive mode and supports Python. Spark has four other large components, as listed below and depicted in figure 5.5. 1 Spark streaming is a tool for real-time analysis. 2 Spark SQL provides a SQL interface to work with Spark. 3 MLLib is a tool for machine learning inside the Spark framework. 4 GraphX is a graph database for Spark. We\u2019ll go deeper into graph databases in chapter 7.","title":"Spark"},{"location":"apuntes/bdaplicado0606.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/ingesta01.html","text":"Ingesta de Datos \u00b6 Tipos de datos \u00b6 Parquet Referencias \u00b6 aaa","title":"1.- ETL"},{"location":"apuntes/ingesta01.html#ingesta-de-datos","text":"","title":"Ingesta de Datos"},{"location":"apuntes/ingesta01.html#tipos-de-datos","text":"Parquet","title":"Tipos de datos"},{"location":"apuntes/ingesta01.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/ingesta02.html","text":"Ingesta de Datos \u00b6 Tipos de datos \u00b6 Parquet Referencias \u00b6 aaa","title":"2.- ETL con SQL/Python"},{"location":"apuntes/ingesta02.html#ingesta-de-datos","text":"","title":"Ingesta de Datos"},{"location":"apuntes/ingesta02.html#tipos-de-datos","text":"Parquet","title":"Tipos de datos"},{"location":"apuntes/ingesta02.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/ingesta03.html","text":"Ingesta de Datos \u00b6 Tipos de datos \u00b6 Parquet Referencias \u00b6 aaa","title":"3.- Pentaho"},{"location":"apuntes/ingesta03.html#ingesta-de-datos","text":"","title":"Ingesta de Datos"},{"location":"apuntes/ingesta03.html#tipos-de-datos","text":"Parquet","title":"Tipos de datos"},{"location":"apuntes/ingesta03.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/ingesta04.html","text":"Ingesta de Datos \u00b6 Tipos de datos \u00b6 Parquet Referencias \u00b6 aaa","title":"4.- Pentaho multidimensional"},{"location":"apuntes/ingesta04.html#ingesta-de-datos","text":"","title":"Ingesta de Datos"},{"location":"apuntes/ingesta04.html#tipos-de-datos","text":"Parquet","title":"Tipos de datos"},{"location":"apuntes/ingesta04.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/ingesta05.html","text":"Ingesta de Datos \u00b6 Tipos de datos \u00b6 Parquet Referencias \u00b6 aaa","title":"5.- Nifi I"},{"location":"apuntes/ingesta05.html#ingesta-de-datos","text":"","title":"Ingesta de Datos"},{"location":"apuntes/ingesta05.html#tipos-de-datos","text":"Parquet","title":"Tipos de datos"},{"location":"apuntes/ingesta05.html#referencias","text":"aaa","title":"Referencias"},{"location":"apuntes/ingesta06.html","text":"Ingesta de Datos \u00b6 Tipos de datos \u00b6 Parquet Referencias \u00b6 aaa","title":"6.- Nifi II"},{"location":"apuntes/ingesta06.html#ingesta-de-datos","text":"","title":"Ingesta de Datos"},{"location":"apuntes/ingesta06.html#tipos-de-datos","text":"Parquet","title":"Tipos de datos"},{"location":"apuntes/ingesta06.html#referencias","text":"aaa","title":"Referencias"},{"location":"ejercicios/ej-arquitecturas.html","text":"Ejercicios \u00b6 Propuesta de proyecto: Libro Manning \"Introducing Data Science - Big Data, ML and more, usign Python Apartado 5.2 (pg 125) Herramientas: Hadoop + Spark + Hive + PowerBI Descargar csv de internet mediante Python y Panda Meter dentro de HDFS Utilizar Spark para hacer la limpieza Almacenar los datos con SparkSQL en Hive Bibliograf\u00eda \u00b6 En Moodle se publican los apuntes de la asignatura, con ejercicios, explicaciones y ejemplos de todos los conceptos estudiados, tanto en teor\u00eda como en pr\u00e1ctica. Para ampliar algunos conceptos se recomiendan las siguientes referencias: Harold Abelson y Gerald Jay Sussman, Structure and Interpretation of Computer Programs , MIT Press, 1996 Enlace a la edici\u00f3n on-line Signatura en la Biblioteca Polit\u00e9cnica: I.06/ABE/STR Apple, The Swift Programming Language The Racket Guide Lenguajes y Paradigmas de Programaci\u00f3n, curso 2020-21 \u00a9 Departamento Ciencia de la Computaci\u00f3n e Inteligencia Artificial, Universidad de Alicante Domingo Gallardo, Cristina Pomares, Antonio Bot\u00eda, Francisco Mart\u00ednez","title":"Ejercicios"},{"location":"ejercicios/ej-arquitecturas.html#ejercicios","text":"Propuesta de proyecto: Libro Manning \"Introducing Data Science - Big Data, ML and more, usign Python Apartado 5.2 (pg 125) Herramientas: Hadoop + Spark + Hive + PowerBI Descargar csv de internet mediante Python y Panda Meter dentro de HDFS Utilizar Spark para hacer la limpieza Almacenar los datos con SparkSQL en Hive","title":"Ejercicios"},{"location":"ejercicios/ej-arquitecturas.html#bibliografia","text":"En Moodle se publican los apuntes de la asignatura, con ejercicios, explicaciones y ejemplos de todos los conceptos estudiados, tanto en teor\u00eda como en pr\u00e1ctica. Para ampliar algunos conceptos se recomiendan las siguientes referencias: Harold Abelson y Gerald Jay Sussman, Structure and Interpretation of Computer Programs , MIT Press, 1996 Enlace a la edici\u00f3n on-line Signatura en la Biblioteca Polit\u00e9cnica: I.06/ABE/STR Apple, The Swift Programming Language The Racket Guide Lenguajes y Paradigmas de Programaci\u00f3n, curso 2020-21 \u00a9 Departamento Ciencia de la Computaci\u00f3n e Inteligencia Artificial, Universidad de Alicante Domingo Gallardo, Cristina Pomares, Antonio Bot\u00eda, Francisco Mart\u00ednez","title":"Bibliograf\u00eda"},{"location":"ejercicios/ej-bdaplicado.html","text":"Ejercicios \u00b6 Propuesta de proyecto: Libro Manning \"Introducing Data Science - Big Data, ML and more, usign Python Apartado 5.2 (pg 125) Herramientas: Hadoop + Spark + Hive + PowerBI Descargar csv de internet mediante Python y Panda Meter dentro de HDFS Utilizar Spark para hacer la limpieza Almacenar los datos con SparkSQL en Hive Bibliograf\u00eda \u00b6 En Moodle se publican los apuntes de la asignatura, con ejercicios, explicaciones y ejemplos de todos los conceptos estudiados, tanto en teor\u00eda como en pr\u00e1ctica. Para ampliar algunos conceptos se recomiendan las siguientes referencias: Harold Abelson y Gerald Jay Sussman, Structure and Interpretation of Computer Programs , MIT Press, 1996 Enlace a la edici\u00f3n on-line Signatura en la Biblioteca Polit\u00e9cnica: I.06/ABE/STR Apple, The Swift Programming Language The Racket Guide Lenguajes y Paradigmas de Programaci\u00f3n, curso 2020-21 \u00a9 Departamento Ciencia de la Computaci\u00f3n e Inteligencia Artificial, Universidad de Alicante Domingo Gallardo, Cristina Pomares, Antonio Bot\u00eda, Francisco Mart\u00ednez","title":"Ejercicios"},{"location":"ejercicios/ej-bdaplicado.html#ejercicios","text":"Propuesta de proyecto: Libro Manning \"Introducing Data Science - Big Data, ML and more, usign Python Apartado 5.2 (pg 125) Herramientas: Hadoop + Spark + Hive + PowerBI Descargar csv de internet mediante Python y Panda Meter dentro de HDFS Utilizar Spark para hacer la limpieza Almacenar los datos con SparkSQL en Hive","title":"Ejercicios"},{"location":"ejercicios/ej-bdaplicado.html#bibliografia","text":"En Moodle se publican los apuntes de la asignatura, con ejercicios, explicaciones y ejemplos de todos los conceptos estudiados, tanto en teor\u00eda como en pr\u00e1ctica. Para ampliar algunos conceptos se recomiendan las siguientes referencias: Harold Abelson y Gerald Jay Sussman, Structure and Interpretation of Computer Programs , MIT Press, 1996 Enlace a la edici\u00f3n on-line Signatura en la Biblioteca Polit\u00e9cnica: I.06/ABE/STR Apple, The Swift Programming Language The Racket Guide Lenguajes y Paradigmas de Programaci\u00f3n, curso 2020-21 \u00a9 Departamento Ciencia de la Computaci\u00f3n e Inteligencia Artificial, Universidad de Alicante Domingo Gallardo, Cristina Pomares, Antonio Bot\u00eda, Francisco Mart\u00ednez","title":"Bibliograf\u00eda"},{"location":"ejercicios/ej-ingesta.html","text":"Ejercicios \u00b6 Propuesta de proyecto: Libro Manning \"Introducing Data Science - Big Data, ML and more, usign Python Apartado 5.2 (pg 125) Herramientas: Hadoop + Spark + Hive + PowerBI Descargar csv de internet mediante Python y Panda Meter dentro de HDFS Utilizar Spark para hacer la limpieza Almacenar los datos con SparkSQL en Hive Bibliograf\u00eda \u00b6 En Moodle se publican los apuntes de la asignatura, con ejercicios, explicaciones y ejemplos de todos los conceptos estudiados, tanto en teor\u00eda como en pr\u00e1ctica. Para ampliar algunos conceptos se recomiendan las siguientes referencias: Harold Abelson y Gerald Jay Sussman, Structure and Interpretation of Computer Programs , MIT Press, 1996 Enlace a la edici\u00f3n on-line Signatura en la Biblioteca Polit\u00e9cnica: I.06/ABE/STR Apple, The Swift Programming Language The Racket Guide Lenguajes y Paradigmas de Programaci\u00f3n, curso 2020-21 \u00a9 Departamento Ciencia de la Computaci\u00f3n e Inteligencia Artificial, Universidad de Alicante Domingo Gallardo, Cristina Pomares, Antonio Bot\u00eda, Francisco Mart\u00ednez","title":"Ejercicios"},{"location":"ejercicios/ej-ingesta.html#ejercicios","text":"Propuesta de proyecto: Libro Manning \"Introducing Data Science - Big Data, ML and more, usign Python Apartado 5.2 (pg 125) Herramientas: Hadoop + Spark + Hive + PowerBI Descargar csv de internet mediante Python y Panda Meter dentro de HDFS Utilizar Spark para hacer la limpieza Almacenar los datos con SparkSQL en Hive","title":"Ejercicios"},{"location":"ejercicios/ej-ingesta.html#bibliografia","text":"En Moodle se publican los apuntes de la asignatura, con ejercicios, explicaciones y ejemplos de todos los conceptos estudiados, tanto en teor\u00eda como en pr\u00e1ctica. Para ampliar algunos conceptos se recomiendan las siguientes referencias: Harold Abelson y Gerald Jay Sussman, Structure and Interpretation of Computer Programs , MIT Press, 1996 Enlace a la edici\u00f3n on-line Signatura en la Biblioteca Polit\u00e9cnica: I.06/ABE/STR Apple, The Swift Programming Language The Racket Guide Lenguajes y Paradigmas de Programaci\u00f3n, curso 2020-21 \u00a9 Departamento Ciencia de la Computaci\u00f3n e Inteligencia Artificial, Universidad de Alicante Domingo Gallardo, Cristina Pomares, Antonio Bot\u00eda, Francisco Mart\u00ednez","title":"Bibliograf\u00eda"}]}