
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://aitor-medrano.github.io/bigdata2122/apuntes/bdaplicado05kafka.html">
      
      <link rel="icon" href="../imagenes/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.7">
    
    
      
        <title>Kafka - Inteligencia Artificial y Big Data</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.cd566b2a.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.e6a45f82.min.css">
        
          
          
          <meta name="theme-color" content="#02a6f2">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-MV889H0W63"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-MV889H0W63",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MV889H0W63"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="light-blue" data-md-color-accent="teal">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#kafka" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-header__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Inteligencia Artificial y Big Data
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Kafka
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Búsqueda" placeholder="Búsqueda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando búsqueda
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-nav__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    Inteligencia Artificial y Big Data
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Inicio
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" data-md-state="indeterminate" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Arquitecturas Big Data
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Arquitecturas Big Data" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Arquitecturas Big Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube01.html" class="md-nav__link">
        1.- Cloud Computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube02aws.html" class="md-nav__link">
        2.- AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube03computacion.html" class="md-nav__link">
        3.- Computación
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube04almacenamiento.html" class="md-nav__link">
        4.- Almacenamiento
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube05datos.html" class="md-nav__link">
        5.- Datos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="arquitecturas01.html" class="md-nav__link">
        6.- Arquitecturas
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Ingesta de Datos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Ingesta de Datos" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Ingesta de Datos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta01.html" class="md-nav__link">
        1.- ETL
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta02pentaho.html" class="md-nav__link">
        2.- Pentaho DI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta03nifi1.html" class="md-nav__link">
        3.- Nifi I
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta04nifi2.html" class="md-nav__link">
        4.- Nifi II
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta05python.html" class="md-nav__link">
        5.- Python y AWS
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" data-md-state="indeterminate" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Big Data Aplicado
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Big Data Aplicado" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Big Data Aplicado
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado01hadoop.html" class="md-nav__link">
        1.- Hadoop
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduccion" class="md-nav__link">
    Introducción
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#publicador-suscriptor" class="md-nav__link">
    Publicador / Suscriptor
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#elementos" class="md-nav__link">
    Elementos
  </a>
  
    <nav class="md-nav" aria-label="Elementos">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#topic-y-particiones" class="md-nav__link">
    Topic y Particiones
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#brokers" class="md-nav__link">
    Brokers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#factor-de-replicacion" class="md-nav__link">
    Factor de replicación
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#productores" class="md-nav__link">
    Productores
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consumidores" class="md-nav__link">
    Consumidores
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descubrimiento-de-brokers" class="md-nav__link">
    Descubrimiento de brokers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zookeeper" class="md-nav__link">
    Zookeeper
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hola-kafka" class="md-nav__link">
    Hola Kafka
  </a>
  
    <nav class="md-nav" aria-label="Hola Kafka">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creando-un-topic" class="md-nav__link">
    Creando un topic
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#produciendo-mensajes" class="md-nav__link">
    Produciendo mensajes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consumiendo-mensajes" class="md-nav__link">
    Consumiendo mensajes
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kafka-cli" class="md-nav__link">
    Kafka CLI
  </a>
  
    <nav class="md-nav" aria-label="Kafka CLI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creando-un-cluster" class="md-nav__link">
    Creando un cluster
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kafka-y-python" class="md-nav__link">
    Kafka y Python
  </a>
  
    <nav class="md-nav" aria-label="Kafka y Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kafkaconsumer" class="md-nav__link">
    KafkaConsumer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kafkaproducer" class="md-nav__link">
    KafkaProducer
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#de-twitter-a-elasticsearch-con-python" class="md-nav__link">
    De Twitter a Elasticsearch con Python
  </a>
  
    <nav class="md-nav" aria-label="De Twitter a Elasticsearch con Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tweepy" class="md-nav__link">
    Tweepy
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#de-twitter-a-elasticsearch-con-nifi" class="md-nav__link">
    De Twitter a Elasticsearch con Nifi
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kafka-connect" class="md-nav__link">
    Kafka Connect
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kafka-streams" class="md-nav__link">
    Kafka Streams
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    Referencias
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

<h1 id="kafka">Kafka<a class="headerlink" href="#kafka" title="Permanent link">&para;</a></h1>
<!--
https://enmilocalfunciona.io/aprendiendo-apache-kafka-parte-3-conceptos-basicos-extra/

https://www.theninjacto.xyz/Instalacion-Configuracion-Kafka-Manager/

https://medium.com/big-data-engineering/hello-kafka-world-the-complete-guide-to-kafka-with-docker-and-python-f788e2588cfc
-->

<h2 id="introduccion">Introducción<a class="headerlink" href="#introduccion" title="Permanent link">&para;</a></h2>
<p><a href="https://kafka.apache.org/">Apache Kafka</a> es, en pocas palabras, un <em>middleware</em> de mensajería entre sistemas heterogéneos, el cual, mediante un sistema de colas (<em>topics</em>, para ser concreto) facilita la comunicación asíncrona, desacoplando los flujos de datos de los sistemas que los producen o consumen. Funciona como un <em>broker</em> de mensajes, encargado de enrutar los mensajes entre los clientes de un modo muy rápido.</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-middleware.png">
    <figcaption>Kafka como middleware/broker de mensajes</figcaption>
</figure>

<p>En concreto, se trata de una plataforma <em>open source</em> <strong>distribuida</strong> de <strong>transmisión de eventos/mensajes</strong> en tiempo real con almacenamiento duradero y que proporciona de base un alto rendimiento (capaz de manejar billones de peticiones al día, con una latencia inferior a 10ms), tolerancia a fallos, disponibilidad y escalabilidad horizontal (mediante cientos de nodos).</p>
<p>Más del <a href="https://kafka.apache.org/powered-by">80% de las 100 compañías</a> más importantes de EEUU utilizan <em>Kafka</em>: <em>Uber</em>, <em>Twitter</em>, <em>Netflix</em>, <em>Spotify</em>, <em>Blizzard</em>, <em>LinkedIn</em>, <em>Spotify</em>, y <em>PayPal</em> procesan cada día sus mensajes con <em>Kafka</em>.</p>
<p>Como sistema de mensajes, sigue un modelo publicador-suscriptor. Su arquitectura tiene dos directivas claras:</p>
<ul>
<li>No bloquear los productores (para poder gestionar la <a href="https://youtu.be/K3axU2b0dDk"><em>back pressure</em></a>, la cual sucede cuando un publicador produce más elementos de los que un suscriptor puede consumir).</li>
<li>Aislar los productores y los consumidores, de manera que los productores y los consumidores no se conocen.</li>
</ul>
<p>A día de hoy, <em>Apache Kafka</em> se utiliza, además de como un sistema de mensajería, para ingestar datos, realizar procesado de datos en streaming y analítica de datos en tiempo real, así como en arquitectura de microservicios y sistemas IOT.</p>
<h2 id="publicador-suscriptor">Publicador / Suscriptor<a class="headerlink" href="#publicador-suscriptor" title="Permanent link">&para;</a></h2>
<p>Antes de entrar en detalle sobre Kafka, hay que conocer el modelo publicador/suscriptor. Este patrón también se conoce como <em>publish / subscribe</em> o <em>productor / consumidor</em>.</p>
<!--
Hay tres elementos que hay que tener realmente claros:

* Publicador (publisher / remitente / emisor / productor): genera un dato y lo coloca en un *topic*.
* topic (tema):
* subcribers:

Existe un elemento "publisher" (publicador ) que al generar un dato (message / mensaje / record / registro) no lo dirige o referencia específicamente a un "subscriber" (receptor / subscriptor / suscriptor) en concreto, es decir, no lo envía de forma directa a la "dirección" del subscriber.

A partir de estos, existen otros elementos más complejos que ofrecen diferentes configuraciones:

tradicional: Cada suscriptor está asociado a uno o varios topic en concreto. Existen muchas variaciones:
Cada suscriptor está escuchando 1 topic propio.
Cada suscriptor está escuchando X topics independientes.
Cada suscriptor está escuchando X topics independientes y Y topics compartido.
Grupos de consumo: Los suscriptores se pueden agrupar por grupo, este grupo está escuchando un topic y sólo un miembro del grupo tendrá la capacidad de atender el mensaje.
Radio Difusión: Todos los suscriptores que están escuchando el topic reciben el mensaje (cada suscriptor es responsable de interpretar el mensaje de forma independiente).

Para ello se dispone de listas de temas/topics publicados específicos y un conjunto de suscriptores, el productor trata de clasificar el mensaje en base a una tipología, lo pone en la lista de un tema específico y el receptor se suscribe a la listas para recibir ese tipo de mensajes.

Publicación y suscripción de flujos de registros (Bastante similar a una cola de mensajes o un sistema de mensajería).
Almacenar flujos de registros tolerante a fallos (Sistema de Buffer con un periodo de retención de mensajes).
Procesar flujos de registros a medida que ocurren.

Es una plataforma para la transmisión de eventos
Implementa un sistema distribuido formado Servidores y Clientes que se comunican a través de TCP.
Servidores: Importan y exportan datos continuamente como flujos de eventos.
Clientes: Permiten escribir aplicaciones distribuidas y microservicios que leen, escriben y procesan flujos de eventos en paralelo.

Evento: registra el hecho de que algo ha sucedido.
Tiene una clave, un valor y una marca
Los eventos se organizan de forma duradera en temas (similar a una carpeta de archivos)
Los temas están divididos, distribuidos en varios depósitos. Los eventos con la misma clave, se escriben en la misma partición.
Productores: aplicaciones clientes que publican (escriben) eventos en Kafka.
Consumidores: los que leen estos eventos.

-->

<!--

https://kafka.apache.org/quickstart

https://learning.oreilly.com/library/view/apache-kafka-quick/9781788997829/b09bb193-31af-4825-acd8-dc6e9ccd78b5.xhtml
-->

<h2 id="elementos">Elementos<a class="headerlink" href="#elementos" title="Permanent link">&para;</a></h2>
<h3 id="topic-y-particiones">Topic y Particiones<a class="headerlink" href="#topic-y-particiones" title="Permanent link">&para;</a></h3>
<p>Un <em>topic</em> (¿tema?) es un flujo particular de datos, similar a una tabla de una base de datos (sin las restricciones).</p>
<p>Podemos crear tantos <em>topics</em> como queramos y cada uno de ellos tendrá un nombre unívoco.</p>
<p>Un <em>topic</em> se divide en particiones, las cuales se numeran, siendo la primera la 0. Al crear un <em>topic</em> hemos de indicar la cantidad de particiones inicial, la cual podemos modificar <em>a posteriori</em>.</p>
<p>Cada partición está ordenada, de manera que cada mensaje dentro de una partición tendrá un identificador incremental, llamado <em>offset</em> (desplazamiento).</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-topic-partitions.png">
    <figcaption>Offset dentro de las particiones de un topic</figcaption>
</figure>

<p>Como podemos observar en la imagen, cada partición tiene sus propios <em>offset</em> (el <em>offset</em> 3 de la partición 0 no representa el mismo dato que el <em>offset</em> 3 de la partición 1).</p>
<p>Habíamos comentado que las particiones están ordenadas, pero el orden sólo se garantiza dentro de una partición (no entre particiones), es decir, el mensaje 7 de la partición 0 puede haber llegado antes, a la vez, o después que el mensaje 5 de la partición 1.</p>
<p>Los datos de una partición tiene un tiempo de vida limitado, el cual por defecto es de una semana. Además, una vez que los datos se escriben en una partición, no se pueden modificar (las mensajes son immutables).</p>
<p>Finalmente, por defecto, los datos se asignan de manera aleatoria a una partición. Sin embargo, existe la posibilidad de indicar una clave de particionado.</p>
<h3 id="brokers">Brokers<a class="headerlink" href="#brokers" title="Permanent link">&para;</a></h3>
<p>Un clúster de <em>Kafka</em> está compuesto de múltiples nodos conocidos como <em>Brokers</em>, donde cada <em>broker</em> es un servidor de <em>Kafka</em>. Cada <em>broker</em> se identifica con un id, el cual debe ser un número entero.</p>
<p>Cada <em>broker</em> contiene un conjunto de particiones, de manera que un <em>broker</em> contiene parte de los datos, nunca los datos completos ya que Kafka es un sistema distribuido. Al conectarse a un broker del cluster (<em>bootstrap broker</em>), automáticamente nos conectaremos al cluster entero.</p>
<p>Para comenzar se recomienda una arquitectura de 3 brokers, aunque algunos clústers lo forman cerca de un centenar de <em>brokers</em>.</p>
<p>Por ejemplo, el siguiente gráfico muestra el <em>topic A</em> dividido en tres particiones, cada una de ellas residiendo en un broker diferente (no hay ninguna relación entre el número de la partición y el nombre del broker), y el <em>topic B</em> dividido en dos particiones:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-3brokers.png">
    <figcaption>Ejemplo de 3 brokers</figcaption>
</figure>

<p>En el caso de haber introducido un nuevo <em>topic</em> con 4 particiones, uno de los brokers contendría dos particiones.</p>
<h3 id="factor-de-replicacion">Factor de replicación<a class="headerlink" href="#factor-de-replicacion" title="Permanent link">&para;</a></h3>
<p>Para soportar la tolerancia a fallos, los <em>topics</em> deben tener un factor de replicación mayor que uno (normalmente se configura entre 2 y 3).</p>
<p>En la siguiente imagen podemos ver como tenemos 3 brokers, y un <em>topic A</em> con dos particiones y una factor de replicación de 2, de manera que cada partición crea un replica de si misma:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-replication-factor.png">
    <figcaption>Divisiones de un broker en particiones</figcaption>
</figure>

<p>Si se cayera el <em>broker 102</em>, Kafka podría devolver los datos al estar disponibles en los nodos 101 y 103.</p>
<h4 id="replica-lider">Réplica líder<a class="headerlink" href="#replica-lider" title="Permanent link">&para;</a></h4>
<p>Acabamos de ver que cada broker tiene múltiples particiones, y cada partición tiene múltiples réplicas, de manera que si se cae un nodo/broker, Kafka puede utilizar otro <em>broker</em> para servir los datos.</p>
<p>En cualquier instante, una determinada partición tendrá una única réplica que será la líder, y esta réplica líder será la única que pueda recibir y servir los datos de una partición. La réplica líder es importante porque todas las lecturas y escrituras siempre van a esta réplica. El resto de brokers sincronizarán sus datos. En resume, cada partición tendrá un líder y múltiples ISR (<em>in-sync replica</em>).</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-replicas.png">
    <figcaption>Réplicas de una partición</figcaption>
</figure>

<p>Si se cayera el <em>Broker 101</em> , entonces la partición 0 del <em>Broker 102</em> se convertiría en la líder. Y cuando vuelva a funcionar el <em>Broker 101</em>, intentará volver a ser la partición líder.</p>
<h3 id="productores">Productores<a class="headerlink" href="#productores" title="Permanent link">&para;</a></h3>
<p>Los productores escriben datos en los <em>topics</em>, sabiendo automáticamente a que <em>broker</em> y partición deben escribir.
En el caso de un fallo de un broker, los productores automáticamente se recuperan y se comunican con el broker adecuado.</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-producers.png">
    <figcaption>La carga se balancea entre los brokers</figcaption>
</figure>

<p>Si el productor envía los datos sin una clave determinada, Kafka realiza una algoritmo de <em>Round Robin</em>, de manera que cada mensaje se va alternando entre los diferentes brokers.</p>
<p>Podemos configurar los productores para que reciban un ACK de las escrituras de los datos con los siguientes valores:</p>
<ul>
<li><code>ack=0</code>: El productor no espera la confirmación (posible pérdida de datos).</li>
<li><code>ack=1</code>: El productor espera la confirmación del líder (limitación de la pérdida de datos).</li>
<li><code>ack=all</code>: El productores espera la confirmación del líder y de todas las réplicas (sin pérdida de datos).</li>
</ul>
<h4 id="clave-de-mensaje">Clave de mensaje<a class="headerlink" href="#clave-de-mensaje" title="Permanent link">&para;</a></h4>
<p>Los productores pueden enviar una clave con el mensaje (de tipo cadena, numérico, etc...). Cuando la clave no se envía, ya hemos comentado que los datos se envían mediante <em>Round Robin</em> (primero <em>Broker 101</em>, luego el 102, el 103, etc... y vuelta al 101).</p>
<p>Si se envía la clave, todos los mensajes con la misma clave siempre irán a la misma partición. Por lo tanto, enviaremos una clave cuando necesitemos ordenar los mensajes por un campo específico (por ejemplo, el identificador de una operación).</p>
<h3 id="consumidores">Consumidores<a class="headerlink" href="#consumidores" title="Permanent link">&para;</a></h3>
<p>Los consumidores obtiene los datos de los <em>topics</em> y las particiones, y saben de qué broker deben leer los datos. Igual que los productores, en el caso de un fallo de un broker, los consumidores automáticamente se recuperan y se comunican con el broker adecuado.</p>
<p>Los datos se leen en orden dentro de cada partición, de manera que el consumidor no podrá leer, por ejemplo, los datos del offset 6 hasta que no haya leído los del offset 5. Además, un consumidor puede leer de varias particiones (se realiza en paralelo), pero el orden sólo se respeta dentro de cada partición, no entre particiones:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-consumers.png">
    <figcaption>Los consumidores leen en orden dentro de cada partición</figcaption>
</figure>

<h4 id="grupo-de-consumidores">Grupo de consumidores<a class="headerlink" href="#grupo-de-consumidores" title="Permanent link">&para;</a></h4>
<p>Un consumidor puede pertenecer a un grupo de consumidores, de manera que cada uno de los consumidores del grupo obtendrán una parte de los datos, es decir, una partición de un <em>topic</em>.</p>
<p>Por ejemplo, tenemos una aplicación compuesta de dos consumidores, formando un grupo de consumidores. El consumidor 1 lo hará de dos particiones, y el consumidor 2 lo hará de la tercera partición. También tenemos otra aplicación compuesta de tres consumidores, de manera que cada consumidor lo hará de cada una de las particiones. Finalmente, tenemos un tercer grupo de consumidores formado por un único consumidor que leerá las tres particiones. En conclusión, cada grupo de consumidores funciona como un único consumidor de manera que accede a todas las particiones de un <em>topic</em>.</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-consumer-group-2.png">
    <figcaption>Grupos de consumidores</figcaption>
</figure>

<div class="admonition info">
<p class="admonition-title">Coordinando los consumidores</p>
<p>Los consumidores, por sí solos, no saben con que partición se deben comunicar. Para ello, se utiliza un <em>GroupCoordinator</em> y un <em>Consumer Coordinator</em> para asignar los consumidores a cada partición. Esta gestión la realiza Kafka.</p>
</div>
<p>Cabe destacar que los diferentes grupos de consumidores reciben el mismo dato de cada partición, es decir, el consumidor 1 del grupos 1 y el consumidor 1 del grupo 2 reciben la información que había en la partición 0. Este caso de uso es muy útil cuando tenemos dos aplicaciones que queremos que reciban los mismos datos (por ejemplo, uno encargado de realizar <em>machine learning</em> y otro analítica de datos).</p>
<p>En el caso de tener más consumidores que particiones, algunos consumidores no realizarán nada. Este caso de uso es atípico, ya que lo recomendable es tener tantos consumidores como el mayor número de particiones existentes.</p>
<h4 id="offsets-de-consumidor">Offsets de Consumidor<a class="headerlink" href="#offsets-de-consumidor" title="Permanent link">&para;</a></h4>
<p>Kafka almacena los <em>offsets</em> por el que va leyendo un grupo de consumidores, a modo de <em>checkpoint</em>, en un topic llamado <code>__consumer_offsets</code>.</p>
<p>Cuando un consumidor de un grupo ha procesado los datos que ha leído de Kafka, realizará un <em>commit</em> de sus <em>offsets</em>. Si el consumidor se cae, podrá volver a leer los mensajes desde el último <em>offset</em> sobre el que se realizó <em>commit</em>.</p>
<p>Por ejemplo, supongamos que tenemos un consumidor el cual ha hecho un <em>commit</em> tras el <em>offset</em> 4262. Tras el <em>commit</em> seguimos leyendo los siguientes mensajes: 4263, 4264, 4265 y de repente el consumidor se cae sin haber hecho <em>commit</em> de esos mensajes. Cuando el consumidor vuelva a funcionar, volverá a leer los mensajes desde el 4263, asegurándose que no se ha quedado ningún mensaje sin procesar.</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-consumer-offsets.png">
    <figcaption>Offsets de consumidor</figcaption>
</figure>

<p>El <em>commit</em> de los mensajes está muy relacionado con la semántica de la entrega. Los consumidores eligen cuando realizar el commit de los <em>offsets</em>:</p>
<ul>
<li><em>As most once</em>: se realiza el commit del mensaje tan pronto como se recibe el mensaje. Si falla su procesamiento, el mensaje se perderá (y no se volverá a leer).</li>
<li><em>At least once</em> (opción más equilibrada): El commit se realiza una vez procesador el mensaje. Este enfoque  puede resultar en un procesado duplicado de los mensajes, por lo que hemos de asegurarnos que son idempotentes (el volver a procesar un mensaje no tendrá un impacto en el sistema)</li>
<li><em>Exactly once</em>: sólo se puede conseguir utilizando flujos de trabajo de Kafka con Kafka mediante el API de Kafka Streams. Si necesitamos la interacción de Kafka con un sistema externo, como una base de datos, se recomienda utilizar un consumidor idempotente que nos asegura que no habrá duplicados en la base de datos.</li>
</ul>
<h3 id="descubrimiento-de-brokers">Descubrimiento de brokers<a class="headerlink" href="#descubrimiento-de-brokers" title="Permanent link">&para;</a></h3>
<p>Cada <em>broker</em> de <em>Kafka</em> es un <em>bootstrap server</em>, lo que significa que dicho servidor contiene un listado con todos los nodos del clúster, de manera que al conectarnos a un broker, automáticamente nos conectaremos al clúster entero.</p>
<p>Mediante esta configuración, cada broker conoce todos los brokers, <em>topics</em> y particiones (metadatos del clúster).</p>
<p>Así pues, cuando un cliente se conecta a un <em>broker</em>, también realiza una petición de los metadatos, y obtiene un listado con todos los <em>brokers</em>. Tras ello, ya puede conectarse a cualquiera de los <em>brokers</em> que necesite:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-broker-discovery.png">
    <figcaption>Descubrimiento de brokers</figcaption>
</figure>

<h3 id="zookeeper">Zookeeper<a class="headerlink" href="#zookeeper" title="Permanent link">&para;</a></h3>
<p>En la primera sesión de <em>Hadoop</em>, ya vimos que <a href="https://zookeeper.apache.org/">ZooKeeper</a> es un servicio para mantener la configuración, coordinación y aprovisionamiento de aplicaciones distribuidas. No sólo se utiliza en Hadoop, pero es muy útil ya que elimina la complejidad de la gestión distribuida de la plataforma.</p>
<p>En el caso de <em>Kafka</em>, <em>Zookeeper</em>:</p>
<ul>
<li>gestiona los <em>brokers</em> (manteniendo una lista de ellos).</li>
<li>ayuda en la elección de la partición líder</li>
<li>envía notificaciones a Kafka cuando hay algún cambio (por ejemplo, se crea un <em>topic</em>, se cae un broker, se recupera un broker, al eliminar un <em>topic</em>, etc...).</li>
</ul>
<p>Por todo ello, Kafka no puede funcionar sin Zookeeper.</p>
<p>En un entorno real, se instalan un número impar de servidores <em>Zookeeper</em> (3, 5, 7). Para su gestión, <em>Zookeeper</em> define un líder (gestiona las escrituras) y el resto de servidores funcionan como réplicas de lectura.</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/05kafka-zookeeper.png">
    <figcaption>Kafka y Zookeeper</figcaption>
</figure>

<p>Pese a su dependencia, los productores y consumidores no interactúan nunca con Zookeeper, sólo lo hacen con Kafka.</p>
<div class="admonition important">
<p class="admonition-title">Kafka garantiza que...</p>
<ul>
<li>Los mensajes se añaden a una partición/<em>topic</em> en el orden en el que se envían</li>
<li>Los consumidores leen los mensajes en el orden en que se almacenaron en la partición/<em>topic</em></li>
<li>Con un factor de replicación N, los productores y consumidores pueden soportar que se caigan N-1 brokers.<ul>
<li>Por ejemplo, con un factor de replicación de 3 (el cual es un valor muy apropiado), podemos tener un nodo detenido para mantenimiento y podemos permitirnos que otro de los nodos se caiga de forma inesperada.</li>
</ul>
</li>
<li>Mientras el número de particiones de un <em>topic</em> permanezca constante (no se hayan creado nuevas particiones), la misma clave implicará que los mensajes vayan a la misma partición.</li>
</ul>
</div>
<!--

In Kafka, there are three types of clusters:

Single node–single broker
Single node–multiple broker
Multiple node–multiple broker

Cluster: This is a set of Kafka brokers.
Zookeeper: This is a cluster coordinator—a tool with different services that are part of the Apache ecosystem.
Broker: This is a Kafka server, also the Kafka server process itself.
Topic: This is a queue (that has log partitions); a broker can run several topics.
Offset: This is an identifier for each message.
Partition: This is an immutable and ordered sequence of records continually appended to a structured commit log.
Producer: This is the program that publishes data to topics.
Consumer: This is the program that processes data from the topics.
Retention period: This is the time to keep messages available for consumption.

In Kafka, there are three (and just three) ways to deliver messages:

Never redelivered: The messages may be lost because, once delivered, they are not sent again.
May be redelivered: The messages are never lost because, if it is not received, the message can be sent again.
Delivered once: The message is delivered exactly once. This is the most difficult form of delivery; since the message is only sent once and never redelivered, it implies that there is zero loss of any message.

The message log can be compacted in two ways:
Coarse-grained: Log compacted by time
Fine-grained: Log compacted by message

-->

<h2 id="hola-kafka">Hola Kafka<a class="headerlink" href="#hola-kafka" title="Permanent link">&para;</a></h2>
<p>Para arrancar Kafka, vamos a utilizar la instalación que tenemos creada en nuestra máquina virtual.</p>
<div class="admonition tip">
<p class="admonition-title">Kafka mediante Docker</p>
<p><em>Bitnami</em> tiene una imagen para trabajar con <em>Docker</em> la cual permite probar todos los ejemplos de esta sesión. Para ello, se recomienda seguir los pasos de la página oficial: <a href="https://hub.docker.com/r/bitnami/kafka/">https://hub.docker.com/r/bitnami/kafka/</a></p>
</div>
<p>El primer paso, una vez dentro de la carpeta de instalación de Kafka (en nuestro caso <code>/opt/kafka_2.13-2.8.1</code>), es arrancar <em>Zookeeper</em> mediante el comando <code>zookeeper-server-start.sh</code>, el cual se encarga de gestionar la comunicación entre los diferentes brokers:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>zookeeper-server-start.sh ./config/zookeeper.properties
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">zookeeper.properties</p>
<p>Del archivo de configuración de Zookeeper conviene destacar dos propiedades:</p>
<ul>
<li><code>clientPort</code>: puerto por defecto (2181)</li>
<li><code>dataDir</code>: indica donde está el directoria de datos de Zookeeper (por defecto es <code>tmp/zookeeper</code>, pero si queremos que dicha carpeta no se elimine es mejor que apunta a una ruta propia, por ejemplo <code>/opt/zookeeper-data</code>)</li>
</ul>
</div>
<p>Para comprobar que Zookeeper está arrancado, podemos ejecutar el comando <code>lsof -i :2181</code>, el cual escanea el puerto 2181 donde está corriendo <em>Zookeeper</em>.</p>
<p>Una vez comprobado, en un nuevo terminal, arrancamos el servidor de Kafka mediante el comando <code>kafka-server-start.sh</code> (de manera que tenemos corriendo a la vez Zookeeper y Kafka):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>kafka-server-start.sh ./config/server.properties
</code></pre></div>
<h3 id="creando-un-topic">Creando un <em>topic</em><a class="headerlink" href="#creando-un-topic" title="Permanent link">&para;</a></h3>
<p>A continuación, en un nuevo terminal, vamos a crear un <em>topic</em> mediante el comando <code>kafka-topics.sh</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>kafka-topics.sh --create --topic iabd-topic --bootstrap-server iabd-virtualbox:9092
</code></pre></div>
<p>Si queremos obtener la descripción del <em>topic</em> creado con la cantidad de particiones le pasamos el parámetro <code>--describe</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>kafka-topics.sh --describe --topic iabd-topic --bootstrap-server iabd-virtualbox:9092
</code></pre></div>
<p>Obteniendo la siguiente información:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>Topic: iabd-topic       TopicId: ogKnRpOFS7mfOhspLcuB4A PartitionCount: 1       ReplicationFactor: 1      Configs: segment.bytes=1073741824
<span class="linenos" data-linenos="2 "></span>        Topic: iabd-topic       Partition: 0    Leader: 0       Replicas: 0     Isr: 0
</code></pre></div>
<h3 id="produciendo-mensajes">Produciendo mensajes<a class="headerlink" href="#produciendo-mensajes" title="Permanent link">&para;</a></h3>
<p>Para enviar un mensaje a un <em>topic</em>, ejecutaremos en un nuevo terminal un productor mediante el comando <code>kafka-console-producer.sh</code>. Por defecto, cada línea que introduzcamos resultará en un envento separado que escribirá un mensaje en el <em>topic</em> (podemos pulsar CTRL+C en cualquier momento para cancelar):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>kafka-console-producer.sh --topic iabd-topic --bootstrap-server iabd-virtualbox:9092
</code></pre></div>
<p>Así pues, escribimos los mensajes que queramos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>&gt;Este es un mensaje
<span class="linenos" data-linenos="2 "></span>&gt;Y este es otro
<span class="linenos" data-linenos="3 "></span>&gt;Y el tercero
</code></pre></div>
<h3 id="consumiendo-mensajes">Consumiendo mensajes<a class="headerlink" href="#consumiendo-mensajes" title="Permanent link">&para;</a></h3>
<p>Y finalmente, en otro terminal, vamos a consumir los mensajes:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>kafka-console-consumer.sh --topic iabd-topic --from-beginning --bootstrap-server iabd-virtualbox:9092
</code></pre></div>
<p>Al ejecutarlo veremos los mensajes que habíamos introducido antes. Si ahora volvemos a escribir en el productor, casi instantáneamente, aparecerá en el consumidor el mismo mensaje.</p>
<p>Tras esto, paramos todos los procesos que se están ejecutando mediante CTRL+C y hemos finalizado nuestro primer contacto con Kafka.</p>
<h2 id="kafka-cli">Kafka CLI<a class="headerlink" href="#kafka-cli" title="Permanent link">&para;</a></h2>
<p>A continuación vamos a repasar los comandos más importantes con los que vamos a interactuar con Kakfa.</p>
<p>Con cada comando que vayamos a interactuar con Kafka, le vamos a pasar como parámetro <code>--bootstrap-server iabd-virtualbox:9092</code> para indicarle donde se encuentra el servicio de <em>Zookeeper</em> (en versiones antiguas de Kafka se indicaría mediante <code>--zookeeper iabd-virtualbox:9092</code>).</p>
<p>Comenzaremos con <code>kafka-topics.sh</code>, el cual nos permite crear, borrar, describir o modificar un <em>topic</em>.</p>
<p>A la hora de crear un <em>topic</em>, además de indicarle donde está zookeeper y el nombre del topic, es recomendable indicar la cantidad de particiones</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>kafka-topics.sh --create --topic iabd-topic --bootstrap-server iabd-virtualbox:9092
</code></pre></div>
<h3 id="creando-un-cluster">Creando un cluster<a class="headerlink" href="#creando-un-cluster" title="Permanent link">&para;</a></h3>
<!--

Kafka Shell
To start it just run the command:
> ./start-kafka-shell.sh <DOCKER_HOST_IP/KAFKA_ADVERTISED_HOST_NAME>
 In my case:
> ./start-kafka-shell.sh 172.17.0.1
Hello Topic
From within the Kafka Shell, run the following to create and describe a topic:
> $KAFKA_HOME/bin/kafka-topics.sh --create --topic test \
--partitions 4 --replication-factor 2 \
--bootstrap-server `broker-list.sh`
> $KAFKA_HOME/bin/kafka-topics.sh --describe --topic test \
--bootstrap-server `broker-list.sh`
Hello Producer
Initialize the producer and write messages to Kafka’s brokers.
> $KAFKA_HOME/bin/kafka-console-producer.sh --topic=test \
--broker-list=`broker-list.sh`
>> Hello World!
>> I'm a Producer writing to 'hello-topic'
Hello Consumer
Initialize the consumer from another Kafka terminal and it will start reading the messages sent by the producer.
> $KAFKA_HOME/bin/kafka-console-consumer.sh --topic=test \
--from-beginning --bootstrap-server `broker-list.sh`

https://learning.oreilly.com/videos/apache-kafka-fundamentals/9780134833682/

TIME TO COMPLETE:
3h 49m

Kafka con Docker:
https://www.theninjacto.xyz/Instalacion-Configuracion-Kafka-Manager/

https://learning.oreilly.com/videos/apache-kafka-a-z/9781801077569/
Apache Kafka A-Z with Hands-On Learning

TIME TO COMPLETE:
9h 36m

Transient Storage

Sencillamente es un servicio de commit log, particionado, replicado y distribuido.

En su arquitectura encontramos que disponemos de un modelo Productor/Consumidor, cuyos mensajes se pueden categorizar en algo llamado topics y que funciona como si fuera un cluster.

Se suele utilizar como gestor de colas.

Se utiliza en la etapa de Almacenamiento de Datos.

-->

<h2 id="kafka-y-python">Kafka y Python<a class="headerlink" href="#kafka-y-python" title="Permanent link">&para;</a></h2>
<h3 id="kafkaconsumer">KafkaConsumer<a class="headerlink" href="#kafkaconsumer" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">kafka</span> <span class="kn">import</span> <span class="n">KafkaConsumer</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">from</span> <span class="nn">json</span> <span class="kn">import</span> <span class="n">loads</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">consumer</span> <span class="o">=</span> <span class="n">KafkaConsumer</span><span class="p">(</span>
<span class="linenos" data-linenos=" 5 "></span>   <span class="s1">&#39;test&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="n">auto_offset_reset</span><span class="o">=</span><span class="s1">&#39;earliest&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos=" 7 "></span>    <span class="n">enable_auto_commit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos" data-linenos=" 8 "></span>    <span class="n">group_id</span><span class="o">=</span><span class="s1">&#39;my-group-1&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos=" 9 "></span>    <span class="n">value_deserializer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">loads</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)),</span>
<span class="linenos" data-linenos="10 "></span>    <span class="n">bootstrap_servers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;172.17.0.1:32783&#39;</span><span class="p">,</span><span class="s1">&#39;172.17.0.1:32782&#39;</span><span class="p">,</span><span class="s1">&#39;172.17.0.1:32781&#39;</span><span class="p">])</span>
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span><span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">consumer</span><span class="p">:</span>
<span class="linenos" data-linenos="13 "></span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</code></pre></div>
<!--
auto_offset_reset: Tells the consumer from where to start reading if it crashes. ‘earliest’ will move to the oldest available message, ‘latest’ will move to the most recent.
enable_auto_commit: If True, the consumer’s offset will be periodically committed in the background
value_deserializer: A method that defines how to deserialize the data. In this case, it will read the data coming in JSON format from the producer.
bootstrap_servers: In my case, is the output of running ‘broker-list.sh’

-->

<h3 id="kafkaproducer">KafkaProducer<a class="headerlink" href="#kafkaproducer" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">kafka</span> <span class="kn">import</span> <span class="n">KafkaProducer</span>
<span class="linenos" data-linenos="2 "></span><span class="kn">from</span> <span class="nn">json</span> <span class="kn">import</span> <span class="n">dumps</span>
<span class="linenos" data-linenos="3 "></span>
<span class="linenos" data-linenos="4 "></span><span class="n">producer</span> <span class="o">=</span> <span class="n">KafkaProducer</span><span class="p">(</span>
<span class="linenos" data-linenos="5 "></span>   <span class="n">value_serializer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">dumps</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">),</span> 
<span class="linenos" data-linenos="6 "></span>   <span class="n">bootstrap_servers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;172.17.0.1:32783&#39;</span><span class="p">,</span><span class="s1">&#39;172.17.0.1:32782&#39;</span><span class="p">,</span><span class="s1">&#39;172.17.0.1:32781&#39;</span><span class="p">])</span>
<span class="linenos" data-linenos="7 "></span>
<span class="linenos" data-linenos="8 "></span><span class="n">producer</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;hello&quot;</span><span class="p">:</span> <span class="s2">&quot;producer&quot;</span><span class="p">})</span>
</code></pre></div>
<h2 id="de-twitter-a-elasticsearch-con-python">De Twitter a Elasticsearch con Python<a class="headerlink" href="#de-twitter-a-elasticsearch-con-python" title="Permanent link">&para;</a></h2>
<p>A continuación vamos a crear un ejemplo completo de flujo de datos mediante Python que nos permita recoger <em>tweets</em> y meterlos dentro de ElasticSearch.</p>
<p>Vamos a suponer que ya disponemos de una cuenta de Twitter y que tenemos las credenciales de acceso, las cuales vamos a almacenar en un fichero denominado <code>credential.py</code>:</p>
<div class="highlight"><span class="filename">credentials.py</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">API_KEY</span> <span class="o">=</span> <span class="s1">&#39;YOUR_API_KEY&#39;</span>
<span class="linenos" data-linenos="2 "></span><span class="n">API_SECRET_KEY</span> <span class="o">=</span> <span class="s1">&#39;YOUR_API_SECRET_KEY&#39;</span>
<span class="linenos" data-linenos="3 "></span><span class="n">ACCESS_TOKEN</span> <span class="o">=</span> <span class="s1">&#39;YOUR_ACCESS_TOKEN&#39;</span>
<span class="linenos" data-linenos="4 "></span><span class="n">ACCESS_TOKEN_SECRET</span> <span class="o">=</span> <span class="s1">&#39;YOUR_ACCESS_TOKEN_SECRET&#39;</span>
</code></pre></div>
<h3 id="tweepy">Tweepy<a class="headerlink" href="#tweepy" title="Permanent link">&para;</a></h3>
<p>Para acceder a Twitter desde Python, la librería por excelencia es <a href="https://www.tweepy.org">Tweepy</a>, la cual instalaremos mediante:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>pip install tweepy
</code></pre></div>
<p>A continuación, vamos a realizar el proceso de autenticación en Tweepy y recoger el timeline de mi usuario:</p>
<div class="highlight"><span class="filename">timeline.py</span><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">credentials</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">import</span> <span class="nn">tweepy</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># Nos autenticamos mediante OAuth</span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">auth</span> <span class="o">=</span> <span class="n">tweepy</span><span class="o">.</span><span class="n">OAuthHandler</span><span class="p">(</span><span class="n">credentials</span><span class="o">.</span><span class="n">API_KEY</span><span class="p">,</span> <span class="n">credentials</span><span class="o">.</span><span class="n">API_SECRET_KEY</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">auth</span><span class="o">.</span><span class="n">set_access_token</span><span class="p">(</span><span class="n">credentials</span><span class="o">.</span><span class="n">ACCESS_TOKEN</span><span class="p">,</span> <span class="n">credentials</span><span class="o">.</span><span class="n">ACCESS_TOKEN_SECRET</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span><span class="n">api</span> <span class="o">=</span> <span class="n">tweepy</span><span class="o">.</span><span class="n">API</span><span class="p">(</span><span class="n">auth</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">miTimeline</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">home_timeline</span><span class="p">()</span>
<span class="linenos" data-linenos="10 "></span><span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">miTimeline</span><span class="p">:</span>
<span class="linenos" data-linenos="11 "></span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">tweet</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">screen_name</span><span class="si">}</span><span class="s1">:</span><span class="se">\n</span><span class="si">{</span><span class="n">tweet</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="s2">&quot;*&quot;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<h2 id="de-twitter-a-elasticsearch-con-nifi">De Twitter a Elasticsearch con Nifi<a class="headerlink" href="#de-twitter-a-elasticsearch-con-nifi" title="Permanent link">&para;</a></h2>
<p>Vamos a realizar un flujo de datos en Nifi para leer datos en streaming desde una <em>topic</em> para luego ingestar los datos en Elasticsearch.</p>
<!--

Ejemplo con Kafka
Split Text + ExtractText + PutKafka
https://www.youtube.com/watch?v=2w14d16wR8Y

Nifi + Kafka
https://www.youtube.com/watch?time_continue=1588&v=nWEna1mE4KY&feature=emb_logo

Mediante Nifi, unir Kafka Connect, Kafka, HDFS

-->

<h2 id="kafka-connect">Kafka Connect<a class="headerlink" href="#kafka-connect" title="Permanent link">&para;</a></h2>
<p>Permite importar/exportar datos desde/hacia Kafka.</p>
<p>Kafka Connect allows you to continuously ingest data from external systems into Kafka, and vice versa. It is thus very easy to integrate existing systems with Kafka. To make this process even easier, there are hundreds of such connectors readily available.</p>
<!--
https://learning.oreilly.com/library/view/modern-big-data/9781787122765/30e977be-ef98-4cc6-a771-d15030ad19c9.xhtml
-->

<h2 id="kafka-streams">Kafka Streams<a class="headerlink" href="#kafka-streams" title="Permanent link">&para;</a></h2>
<p>Permite procesar y transformar datos dentro de Kafka.</p>
<p>Once your data is stored in Kafka as events, you can process the data with the Kafka Streams client library for Java/Scala. It allows you to implement mission-critical real-time applications and microservices, where the input and/or output data is stored in Kafka topics. Kafka Streams combines the simplicity of writing and deploying standard Java and Scala applications on the client side with the benefits of Kafka's server-side cluster technology to make these applications highly scalable, elastic, fault-tolerant, and distributed. The library supports exactly-once processing, stateful operations and aggregations, windowing, joins, processing based on event-time, and much more.</p>
<div class="admonition info">
<p class="admonition-title">Amazon Kinesis</p>
<p><a href="https://aws.amazon.com/es/kinesis/">Amazon Kinesis</a> es un producto similar a Apache Kafa pero dentro del la plataforma AWS, por lo que no es un producto open source como tal. Su principal ventaja es la facilidad de escalabilidad a golpe de click y integración con el resto de servicios que ofrece AWS.
Se trata de una herramienta muy utilizada que permite incorporar datos en tiempo real, como videos, audios, registros de aplicaciones, secuencias de clics de sitios web y datos de sensores IoT para machine learning, analitica de datos en streaming, etc...</p>
</div>
<h2 id="referencias">Referencias<a class="headerlink" href="#referencias" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="https://www.packtpub.com/product/apache-kafka-series-learn-apache-kafka-for-beginners-video/9781789342604">Apache Kafka Series - Learn Apache Kafka for Beginners</a></li>
</ul>
<!--
https://enmilocalfunciona.io/tag/kafka/
https://www.theninjacto.xyz/tags/apache-kafka/

https://youtu.be/yfi-M0vC8SY?t=1098
-->

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Volver al principio
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      2021-2022 Aitor Medrano - Licencia CC BY-NC-SA
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/aitormedrano" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    <a href="mailto:<a.medrano@edu.gva.es>" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M400 32H48C21.49 32 0 53.49 0 80v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V80c0-26.51-21.49-48-48-48zM178.117 262.104C87.429 196.287 88.353 196.121 64 177.167V152c0-13.255 10.745-24 24-24h272c13.255 0 24 10.745 24 24v25.167c-24.371 18.969-23.434 19.124-114.117 84.938-10.5 7.655-31.392 26.12-45.883 25.894-14.503.218-35.367-18.227-45.883-25.895zM384 217.775V360c0 13.255-10.745 24-24 24H88c-13.255 0-24-10.745-24-24V217.775c13.958 10.794 33.329 25.236 95.303 70.214 14.162 10.341 37.975 32.145 64.694 32.01 26.887.134 51.037-22.041 64.72-32.025 61.958-44.965 81.325-59.406 95.283-70.199z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide", "navigation.top", "navigation.expand", "navigation.tracking", "content.code.annotate"], "translations": {"clipboard.copy": "Copiar al portapapeles", "clipboard.copied": "Copiado al portapapeles", "search.config.lang": "es", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "B\u00fasqueda", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.term.missing": "Falta", "select.version.title": "Seleccionar versi\u00f3n"}, "search": "../assets/javascripts/workers/search.22074ed6.min.js"}</script>
    
    
      <script src="../assets/javascripts/bundle.01de222e.min.js"></script>
      
    
  </body>
</html>