
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="canonical" href="https://aitor-medrano.github.io/bigdata2122/apuntes/ingesta01.html">
      
      <link rel="icon" href="../imagenes/favicon.png">
      <meta name="generator" content="mkdocs-1.2.2, mkdocs-material-7.3.3">
    
    
      
        <title>Ingesta de Datos - Inteligencia Artificial y Big Data</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.5143246d.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.3f5d1f46.min.css">
        
          
          
          <meta name="theme-color" content="#02a6f2">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      

  


  

  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-MV889H0W63"),document.addEventListener("DOMContentLoaded",function(){"undefined"!=typeof location$&&location$.subscribe(function(t){gtag("config","G-MV889H0W63",{page_path:t.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MV889H0W63"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="light-blue" data-md-color-accent="teal">
  
    
    <script>function __prefix(e){return new URL("..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#ingesta-de-datos" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-header__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Inteligencia Artificial y Big Data
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Ingesta de Datos
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Búsqueda" placeholder="Búsqueda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando búsqueda
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-nav__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    Inteligencia Artificial y Big Data
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Inicio
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Arquitecturas Big Data
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Arquitecturas Big Data" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Arquitecturas Big Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube01.html" class="md-nav__link">
        1.- Cloud Computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube02aws.html" class="md-nav__link">
        2.- AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube03computacion.html" class="md-nav__link">
        3.- Computación en AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube04almacenamiento.html" class="md-nav__link">
        4.- Almacenamiento en AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube05datos.html" class="md-nav__link">
        5.- Datos en AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="arquitecturas01.html" class="md-nav__link">
        6.- Arquitecturas
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduccion" class="md-nav__link">
    Introducción
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#la-ingesta-por-dentro" class="md-nav__link">
    La ingesta por dentro
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pipeline-de-datos" class="md-nav__link">
    Pipeline de Datos
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#etl" class="md-nav__link">
    ETL
  </a>
  
    <nav class="md-nav" aria-label="ETL">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#extraccion" class="md-nav__link">
    Extracción
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformacion" class="md-nav__link">
    Transformación
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#carga" class="md-nav__link">
    Carga
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#herramientas-etl" class="md-nav__link">
    Herramientas ETL
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#arquitectura-de-ingesta-de-datos" class="md-nav__link">
    Arquitectura de Ingesta de datos
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#herramientas-de-ingesta-de-datos" class="md-nav__link">
    Herramientas de Ingesta de datos
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#consideraciones" class="md-nav__link">
    Consideraciones
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    Referencias
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="ingesta-de-datos">Ingesta de Datos<a class="headerlink" href="#ingesta-de-datos" title="Permanent link">&para;</a></h1>
<h2 id="introduccion">Introducción<a class="headerlink" href="#introduccion" title="Permanent link">&para;</a></h2>
<p>Formalmente, la ingesta de datos es el proceso mediante el cual se introducen datos, de diferentes fuentes, estructura y/o características dentro de otro sistema de almacenamiento o procesamiento de datos. Un <em>pipeline</em> de datos consume datos de un punto de origen, los limpia y los escribe en un nuevo destino.</p>
<p>La ingesta de datos es un proceso muy importante porque la productividad de un equipo va directamente ligada a la calidad del proceso de ingesta de datos. Estos procesos deben ser flexibles y ágiles, ya que una vez puesta en marcha, los analistas y científicos de daots puedan contruir un <em>pipeline</em> de datos para mover los datos a la herramienta con la que trabajen.</p>
<p>Es sin duda, el primer paso que ha de tenerse en cuenta a la hora de diseñar una arquitectura Big Data, para lo cual, hay que tener muy claro, no solamente el tipo y fuente de datos, sino cual es el objetivo final y que se pretende conseguir con ellos. Por lo tanto, en este punto, hay que realizar un análisis detallado, porque es la base para determinar las tecnologías que compondrán nuestra arquitectura Big Data.</p>
<p>Dada la gran cantidad de datos que disponen las empresas, toda la información que generan desde diferentes fuentes se deben integrar en un único lugar, al que actualmente se le conoce como <em>data lake</em> asegurándose que los datos son compatibles entre sí. Gestionar tal volumen de datos puede llegar a ser un procedimiento complejo, normalmente dividido en procesos distintos y de relativamente larga duración.</p>
<h2 id="la-ingesta-por-dentro">La ingesta por dentro<a class="headerlink" href="#la-ingesta-por-dentro" title="Permanent link">&para;</a></h2>
<p>La ingesta extrae los datos desde la fuente donde se crean o almacenan originalmente y los carga en un destino o zona temporal. Un <em>pipeline</em> de datos sencillo puede que aplica uno más transformaciones ligeras para enriquecer o filtrar los datos antes de escribirlos en un destino, almacen de datos o cola de mensajería. Se pueden añadir nuevos <em>pipelines</em> para transformaciones más complejas como <em>joins</em>, agregacaiones u ordenaciones para analítica de datos, aplicaciones o sistema de informes.</p>
<figure style="align: center;">
    <img src="../imagenes/etl/01dataIngestion.png">
    <figcaption>Ingesta de datos</figcaption>
</figure>

<p>Las fuentes más comunes desde las que se obtienen los datos son:</p>
<ul>
<li>Servicios de mensajería como Apache Kafka</li>
<li>Bases de datos relaciones, las cuales se acceden, por ejemplo, JDBC</li>
<li>Servicios REST que vuelven los datos en formato JSON</li>
<li>Servicios de almacenamiento distribuido como HDFS o S3.</li>
</ul>
<p>Los destinos donde se almacenan los datos son:</p>
<ul>
<li>Servicios de mensajería como Apache Kafka</li>
<li>Bases de datos relaciones</li>
<li>Bases de datos NoSQL</li>
<li>Servicios de almacenamiento distribuido como HDFS o S3.</li>
<li>Plataformas de datos como Snowflake o Databricks.</li>
</ul>
<h2 id="pipeline-de-datos">Pipeline de Datos<a class="headerlink" href="#pipeline-de-datos" title="Permanent link">&para;</a></h2>
<p>Un <em>pipeline</em> es una construcción lógica que representa un proceso dividido en fases. Los pipelines de datos se caracterizan por definir el conjunto de pasos o fases y las tecnologías involucradas en un proceso de movimiento o procesamiento de datos.</p>
<p>Las pipelines de datos son necesarios ya que no debemos analizar los datos en los mismos sistemas donde se crean. El proceso de analítica es costoso computacionalmente, por lo que se separa para evitar perjudicar el rendimiento del servicio. De esta forma, tenemos sistemas OLTP (como un CRM), encargados de capturar y crear datos, y sistemas OLAP (como un <em>Data Warehouse</em>), encargados de analizar los datos.</p>
<p>Los movimientos de datos entre estos sistemas involucran varias fases. Por ejemplo:</p>
<ol>
<li>
<p>Recogemos los datos y los enviamos a un topic de Apache Kafka. Kafka actúa aquí como un buffer para el siguiente paso.</p>
<p><figure style="float: right;">
    <img src="../imagenes/etl/01pipeline.jpeg">
    <figcaption>Ejemplo de pipeline - aprenderbigdata.com</figcaption>
</figure></p>
</li>
<li>
<p>Mediante una tecnología de procesamiento, que puede ser streaming o batch, leemos los datos del buffer. Por ejemplo, mediante <em>Spark</em> realizmaos la analítica sobre estos datos.</p>
</li>
<li>Almacenamos el resultado en una base de datos NoSQL como <em>Amazon DynamoDB</em> o un sistema de almacenamiento distribuidos como <em>Amazon S3</em>.</li>
</ol>
<p>Aunque a menudo se intercambian los términos de <em>pipeline</em> de datos y ETL no significan lo mismo. Las ETLs son un caso particular de pipeline de datos que involucran las fases de extracción, transformación y carga de datos. Las pipelines de datos son cualquier proceso que involucre el movimiento de datos entre sistemas.</p>
<h2 id="etl">ETL<a class="headerlink" href="#etl" title="Permanent link">&para;</a></h2>
<p>https://www.talend.com/es/resources/what-is-etl/</p>
<p>https://www.informatica.com/resources/articles/what-is-etl.html</p>
<p>https://www.informatica.com/blogs/etl-vs-elt-whats-the-difference.html</p>
<p>Los procesos ETL, siglas de extracción, transformación y carga (<em>load</em>), permiten a las organizaciones recopilar en un único lugar todos los datos de los que pueden disponer. Ya hemos comentado que estos datos provienen de diversas fuentes, por lo que es necesario acceder a ellos, y formatearlos para poder ser capaces de integrarlos. Además, es muy recomendable asegurar la calidad de los datos y su veracidad, para así evitar la creación de errores en los datos.</p>
<p>Una vez los datos están unificados en un <em>data lake</em>, otro tipo de herramientas de análisis permitirán su estudio para apoyar procesos de negocio.</p>
<p>Dada la gran variedad de posibilidades existentes para representar la realidad en un dato, junto con la gran cantidad de datos almacenados en las diferentes fuentes de origen, los procesos ETL consumen una gran cantidad de los recursos asignados a un proyecto.</p>
<h3 id="extraccion">Extracción<a class="headerlink" href="#extraccion" title="Permanent link">&para;</a></h3>
<p>Esta fase de un proceso ETL es la encargada de recopilar los datos de los sistemas originales y transportarlos al sistema donde se almacenarán, de manera general suele tratarse de un entorno de Data Warehouse o almacén de datos. Los formatos de las fuentes de datos pueden encontrarse en diferentes formatos, desde ficheros planos hasta bases de datos relacionales entre otros formatos distintos.
Una parte de la extracción es la de analizar que los datos sean los que se esperaban, verificando que siguen el formato que se esperaba. En caso contrario, esos datos se rechazan.</p>
<p>La primera característica deseable de un proceso de extracción es que debe ser un proceso rápido, ligero, causar el menor impacto posible, ser trasparente para los sistemas operacionales e independiente de las infraestructuras.</p>
<p>La segunda característica es que debe reducir al mínimo el impacto que se generase en el sistema origen de la información. No se puede poner en riesgo el sistema original, generalmente operacional, ni perder ni modificar sus datos; ya que si colapsase esto podría afectar el uso normal del sistema y generar pérdidas a nivel operacional.</p>
<p>Así pues, la extracción convierte los datos a un formato preparado para iniciar el proceso de transformación</p>
<h3 id="transformacion">Transformación<a class="headerlink" href="#transformacion" title="Permanent link">&para;</a></h3>
<p>En esta fase se espera realizar los cambios necesarios en los datos de manera que estos tengan el formato y contenido esperado.</p>
<p>En concreto, la transformación puede comprender:</p>
<ul>
<li>Cambios de codificación</li>
<li>Eliminar datos duplicados</li>
<li>Cruzar diferentes fuentes de datos para obtener una fuente diferente</li>
<li>Agregar información en función de alguna variable</li>
<li>Tomar parte de los datos para cargarlos</li>
<li>Transformar información para generar códigos, claves, identificadores…</li>
<li>Generar información</li>
<li>Estructurar mejor la información</li>
<li>Generar indicadores que faciliten el procesamiento y entendimiento</li>
</ul>
<p>Respecto a sus características, debe transformar los datos para mejorarlos, incrementar su calidad, integrarlos con otros sistemas, normalizarlos, eliminar duplicidades o ambigüedades. Además, no debe crear información, duplicar, eliminar información relevante, ser errónea o impredecible.</p>
<p>Una vez transformados los datos, ya estarán listos para su carga.</p>
<h3 id="carga">Carga<a class="headerlink" href="#carga" title="Permanent link">&para;</a></h3>
<p>Fase encargada de almacenar los datos en el destino, un Data Warehouse o en cualquier tipo de base de datos. Por tanto la fase de carga interactúa de manera directa con el sistema destino, y debe adaptarse al mismo con el fin de cargar los datos de manera satisfactoria.</p>
<p>La carga ha de realizarse buscando minimizar el tiempo de la transacción</p>
<p>Cada BBDD puede tener un sistema ideal de carga basado en:</p>
<ul>
<li>SQL (Oracle, SQL Server, Redshift, Postgres, Teradata, Greenplum, …)</li>
<li>Ficheros (Postgres, Redshift)</li>
<li>Cargadores Propios (HDFS, Teradata, Greenplum)</li>
</ul>
<p>Se pueden realizar acciones para mejorar estos procesos:</p>
<ul>
<li>Gestiones de índices</li>
<li>Gestión de claves de distribución y particionado</li>
<li>Tamaño de las transacciones y commit’s</li>
</ul>
<p>https://www.informatica.com/blogs/etl-vs-elt-whats-the-difference.html</p>
<p>https://www.franciscojavierpulido.com/2013/11/paradigmas-bigdata-el-procesamiento.html</p>
<h3 id="herramientas-etl">Herramientas ETL<a class="headerlink" href="#herramientas-etl" title="Permanent link">&para;</a></h3>
<p>Las caracteristicas de las herramientas ETL son:</p>
<ul>
<li>
<p>Permiten conectividad con diferentes sistemas y tipos de datos</p>
<ul>
<li>Excel, BBDD Transaccionales, XML, Access, Teradata, HDFS, Hive, CRM</li>
<li>APIs de Aplicaciones de terceros, Logs…</li>
</ul>
</li>
<li>
<p>Permiten la planificación y ejecución de lógica</p>
<ul>
<li>Planificación por Batch</li>
<li>Planificación por eventos</li>
<li>Planificación en tiempo real</li>
</ul>
</li>
<li>
<p>Capacidad para transformar los datos</p>
<ul>
<li>Transformaciones Simples: Tipos de datos, cadenas, codificaciones, cálculos simples</li>
<li>Transformaciones Intermedias: Agregaciones, lookups,  </li>
<li>Transformaciones Complejas: Algoritmos de IA, Segmentación, Integración de código de terceros, Integración con otros lenguajes</li>
</ul>
</li>
<li>
<p>Metadatos y gestión de errores</p>
<ul>
<li>Permiten tener información del funcionamiento de todo el proceso</li>
<li>Permiten el control de errores y establecer politicas al respecto</li>
</ul>
</li>
</ul>
<p>Las soluciones más empleadas son:</p>
<ul>
<li><a href="https://www.hitachivantara.com/en-us/products/data-management-analytics/lumada-data-integration.html">Pentaho Data Integration (PDI)</a></li>
<li><a href="https://www.oracle.com/es/middleware/technologies/data-integrator.html">Oracle Data Integrator</a></li>
<li><a href="https://www.talend.com/products/talend-open-studio/">Talend Open Studio</a></li>
<li><a href="https://www.mulesoft.com">Mulesoft</a></li>
<li><a href="https://www.informatica.com/products/data-integration.html">Informatica Data Integration</a></li>
</ul>
<figure style="align: center;">
    <img src="../imagenes/etl/herramientasETL.png">
    <figcaption>Herramientas ETL</figcaption>
</figure>

<h2 id="arquitectura-de-ingesta-de-datos">Arquitectura de Ingesta de datos<a class="headerlink" href="#arquitectura-de-ingesta-de-datos" title="Permanent link">&para;</a></h2>
<p>https://ezdatamunch.com/what-is-data-ingestion/</p>
<h2 id="herramientas-de-ingesta-de-datos">Herramientas de Ingesta de datos<a class="headerlink" href="#herramientas-de-ingesta-de-datos" title="Permanent link">&para;</a></h2>
<p>Las herramientas de ingesta de datos para ecosistemas Big Data se clasifican en los siguientes bloques:</p>
<ul>
<li><em>Apache Nifi</em>: herramienta ETL que se encarga de cargar datos de diferentes fuentes, los pasa por un flujo de procesos para su tratamiento, y los vuelca en otra fuente.</li>
<li><em>Apache Sqoop</em>: transferencia bidireccional de datos entre <em>Hadoop</em> y una bases de datos SQL (datos estructurados)</li>
<li><em>Apache Flume</em>: sistema de ingesta de datos semiestructurados o no estructurados en streaming sobre HDFS o HBase.</li>
</ul>
<p>Por otro lado existen sistemas de mensajería con funciones propias de ingesta, tales como:</p>
<ul>
<li><em>Apache Kafka</em>: sistema de intermediación de mensajes basado en el modelo publicador/suscriptor.</li>
<li><em>RabbitMQ</em>: sistema colas de mensajes (MQ) que actúa de middleware entre productores y consumidores.</li>
<li><em>Amazon Kinesis</em>: homólogo de Kafka para la infraestructura Amazon Web Services.</li>
<li><em>Microsoft Azure Event Hubs</em>: homólogo de Kafka para la infraestructura Microsoft Azure.</li>
<li><em>Google Pub/Sub</em>: homólogo de Kafka para la infraestructura Google Cloud.</li>
</ul>
<p>This stage of the data processing pipeline has some overlap with the Collection stage. Data can be collected by or ingested into AWS services in various ways. The following two managed AWS services—which can be used for ingestion—are included in this course.</p>
<p>AWS Glue (Enlaces a un sitio externo.): AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy for customers to prepare and load their data for analytics. ETL jobs can be created with a few clicks in the AWS Management Console. AWS Glue can discover data and store the inferred schema in the AWS Glue Data Catalog, which can then be available for ETL. AWS Glue can also act as a remote metadata store for various AWS services like Amazon Athena, AWS Data Pipeline, etc.
AWS Data Pipeline (Enlaces a un sitio externo.): Data Pipeline is a managed service that can be used to move data between various data sources in the AWS Cloud, like Amazon S3, Amazon RDS, DynamoDB, Amazon Redshift, and Amazon EMR. It can reduce the complexities of handling data pipelines, and reliably move data from source to destination in a cost-effective way.</p>
<h2 id="consideraciones">Consideraciones<a class="headerlink" href="#consideraciones" title="Permanent link">&para;</a></h2>
<p>A la hora de analizar cual sería la tecnología y arquitectura adecuada para realizar la ingesta de datos en un sistema Big Data, hemos de tener en cuenta los siguientes factores:</p>
<ul>
<li>Origen y formato de los datos<ul>
<li>¿Cual va a ser el origen u orígenes de los datos?</li>
<li>¿Provienen de sistemas externos o internos?</li>
<li>¿Serán datos estructurados o datos sin estructura?</li>
<li>¿Cuál es el volumen de los datos? Volumen diario, y plantear como sería la primera carga de datos.</li>
<li>¿Existe la posibilidad de que más adelante se incorporen nuevas fuentes de datos?</li>
</ul>
</li>
<li>Latencia/Disponibilidad<ul>
<li>Ventana temporal que debe pasar desde que los datos se ingestan hasta que puedan ser utilizables, desde horas/dias (mediante procesos <em>batch) o ser </em>real-time<em> (mediante </em>streaming*)</li>
</ul>
</li>
<li>Actualizaciones<ul>
<li>¿Las fuentes origen se modifican habitualmente?</li>
<li>¿Podemos almacenar toda la información y guardar un histórico de cambios?  * ¿Modificamos la información que tenemos? ¿mediante <em>updates</em>, o <em>deletes +insert</em>?</li>
</ul>
</li>
<li>Transformaciones<ul>
<li>¿Son necesarias durante la ingesta?</li>
<li>¿Aportan latencia al sistema? ¿Afecta al rendimiento?</li>
<li>¿Tiene consecuencias que la información sea transformada y no sea la original?</li>
</ul>
</li>
<li>Destino de los datos<ul>
<li>¿Será necesario enviar los datos a más de un destino, por ejemplo, S3 y Cassandra?</li>
<li>¿Cómo se van a utilizar los datos en el destino? ¿cómo serán las consultas? ¿es necesario particionar los datos? ¿serán búsquedas aleatorias o no? ¿Utilizaremos <em>Hive</em> / <em>Pig</em> / <em>Cassandra</em>?</li>
<li>¿Qué procesos de transformación de datos se van a realizar una vez ingestados los datos?</li>
<li>¿Cual es la frecuencia y actualización de los datos origen?</li>
</ul>
</li>
<li>Estudio de los datos<ul>
<li>Calidad de los datos ¿son fiables? ¿existen duplicados?</li>
<li>Seguridad de los datos. Si tenemos datos sensibles o confidenciales, ¿los enmascaramos o decidimos no realizar su ingesta?</li>
</ul>
</li>
</ul>
<h2 id="referencias">Referencias<a class="headerlink" href="#referencias" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="https://www.futurespace.es/ingesta-es-mas-que-una-mudanza-de-datos/">Ingesta, es más que una mudanza de datos</a></li>
<li><a href="https://www.talend.com/es/resources/what-is-etl/">¿Qué es ETL?</a></li>
<li><a href="https://docs.aws.amazon.com/whitepapers/latest/building-data-lakes/building-data-lake-aws.html?did=wp_card&amp;trk=wp_card">Building Big Data Storage Solutions (Data Lakes) for Maximum Flexibility</a></li>
</ul>
<p>17 Enero</p>
<p>https://www.xenonstack.com/blog/big-data-ingestion
https://streamsets.com/learn/data-ingestion/
https://ezdatamunch.com/what-is-data-ingestion/</p>
<p>https://streamsets.com/learn/etl-or-elt/</p>
<p>https://aprenderbigdata.com/pipeline-de-datos/</p>
<p>https://www.xenonstack.com/blog/big-data-ingestion
https://www.xenonstack.com/blog/data-pipeline</p>
                
              
              
                


              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Volver al principio
          </a>
        
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            2021-2022 Aitor Medrano - Licencia CC BY-NC-SA
          </div>
        
        
          Made with
          <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
            Material for MkDocs
          </a>
        
        
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://twitter.com/aitormedrano" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
      <a href="mailto:<a.medrano@edu.gva.es>" target="_blank" rel="noopener" title="" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M400 32H48C21.49 32 0 53.49 0 80v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V80c0-26.51-21.49-48-48-48zM178.117 262.104C87.429 196.287 88.353 196.121 64 177.167V152c0-13.255 10.745-24 24-24h272c13.255 0 24 10.745 24 24v25.167c-24.371 18.969-23.434 19.124-114.117 84.938-10.5 7.655-31.392 26.12-45.883 25.894-14.503.218-35.367-18.227-45.883-25.895zM384 217.775V360c0 13.255-10.745 24-24 24H88c-13.255 0-24-10.745-24-24V217.775c13.958 10.794 33.329 25.236 95.303 70.214 14.162 10.341 37.975 32.145 64.694 32.01 26.887.134 51.037-22.041 64.72-32.025 61.958-44.965 81.325-59.406 95.283-70.199z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide", "navigation.top"], "translations": {"clipboard.copy": "Copiar al portapapeles", "clipboard.copied": "Copiado al portapapeles", "search.config.lang": "es", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "B\u00fasqueda", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.term.missing": "Falta", "select.version.title": "Seleccionar versi\u00f3n"}, "search": "../assets/javascripts/workers/search.8397ff9e.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f89c2efe.min.js"></script>
      
    
  </body>
</html>