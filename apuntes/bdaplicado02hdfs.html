
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Funcionamiento de HDFS, estudiando los procesos de lectura y escritura, los comandos de administraci칩n y el uso de Snapshots. Almacenamiento de datos en formatos Avro y Parquet mediante Python.">
      
      
      
        <link rel="canonical" href="https://aitor-medrano.github.io/bigdata2122/apuntes/bdaplicado02hdfs.html">
      
      <link rel="icon" href="../imagenes/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.14">
    
    
      
        <title>HDFS, acceso y gesti칩n. HDFS y Python. Formatos de datos Avro y Parquet. - Inteligencia Artificial y Big Data</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.3de6f41f.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cc9b2e1e.min.css">
        
          
          
          <meta name="theme-color" content="#02a6f2">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-MV889H0W63"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-MV889H0W63",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MV889H0W63"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="light-blue" data-md-color-accent="teal">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#hdfs" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-header__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Inteligencia Artificial y Big Data
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              HDFS, acceso y gesti칩n. HDFS y Python. Formatos de datos Avro y Parquet.
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="B칰squeda" placeholder="B칰squeda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando b칰squeda
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navegaci칩n" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-nav__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    Inteligencia Artificial y Big Data
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Inicio
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" data-md-state="indeterminate" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Arquitecturas Big Data
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Arquitecturas Big Data" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Arquitecturas Big Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube01.html" class="md-nav__link">
        1.- Cloud Computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube02aws.html" class="md-nav__link">
        2.- AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube03computacion.html" class="md-nav__link">
        3.- Computaci칩n
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube04almacenamiento.html" class="md-nav__link">
        4.- Almacenamiento
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube05datos.html" class="md-nav__link">
        5.- Datos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="arquitecturas01.html" class="md-nav__link">
        6.- Arquitecturas
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Ingesta de Datos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Ingesta de Datos" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Ingesta de Datos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta01.html" class="md-nav__link">
        1.- ETL
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta02pentaho.html" class="md-nav__link">
        2.- Pentaho DI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta03nifi1.html" class="md-nav__link">
        3.- Nifi I
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta04nifi2.html" class="md-nav__link">
        4.- Nifi II
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta05python.html" class="md-nav__link">
        5.- Python y AWS
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Big Data Aplicado
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Big Data Aplicado" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Big Data Aplicado
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado01hadoop.html" class="md-nav__link">
        1.- Hadoop
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          2.- HDFS
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="bdaplicado02hdfs.html" class="md-nav__link md-nav__link--active">
        2.- HDFS
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#funcionamiento-de-hdfs" class="md-nav__link">
    Funcionamiento de HDFS
  </a>
  
    <nav class="md-nav" aria-label="Funcionamiento de HDFS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#procesos-de-lectura" class="md-nav__link">
    Procesos de lectura
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#proceso-de-escritura" class="md-nav__link">
    Proceso de escritura
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hdfs-por-dentro" class="md-nav__link">
    HDFS por dentro
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabajando-con-hdfs" class="md-nav__link">
    Trabajando con HDFS
  </a>
  
    <nav class="md-nav" aria-label="Trabajando con HDFS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bloques" class="md-nav__link">
    Bloques
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#administracion" class="md-nav__link">
    Administraci칩n
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#snapshots" class="md-nav__link">
    Snapshots
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hdfs-ui" class="md-nav__link">
    HDFS UI
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hdfs-y-python" class="md-nav__link">
    HDFS y Python
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formatos-de-datos" class="md-nav__link">
    Formatos de datos
  </a>
  
    <nav class="md-nav" aria-label="Formatos de datos">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#filas-vs-columnas" class="md-nav__link">
    Filas vs Columnas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avro" class="md-nav__link">
    Avro
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parquet" class="md-nav__link">
    Parquet
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparando-tamanos" class="md-nav__link">
    Comparando tama침os
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hue" class="md-nav__link">
    Hue
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    Referencias
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#actividades" class="md-nav__link">
    Actividades
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado03flume.html" class="md-nav__link">
        3.- Sqoop / Flume
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado04hive.html" class="md-nav__link">
        4.- Hive
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado05kafka.html" class="md-nav__link">
        5.- Kafka
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" data-md-state="indeterminate" type="checkbox" id="__nav_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Anal칤tica de Datos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Anal칤tica de Datos" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Anal칤tica de Datos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="spark01rdd.html" class="md-nav__link">
        1.- Spark
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="spark02dataframe.html" class="md-nav__link">
        2.- Spark SQL
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="spark03streaming.html" class="md-nav__link">
        3.- Spark Streaming
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#funcionamiento-de-hdfs" class="md-nav__link">
    Funcionamiento de HDFS
  </a>
  
    <nav class="md-nav" aria-label="Funcionamiento de HDFS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#procesos-de-lectura" class="md-nav__link">
    Procesos de lectura
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#proceso-de-escritura" class="md-nav__link">
    Proceso de escritura
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hdfs-por-dentro" class="md-nav__link">
    HDFS por dentro
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabajando-con-hdfs" class="md-nav__link">
    Trabajando con HDFS
  </a>
  
    <nav class="md-nav" aria-label="Trabajando con HDFS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bloques" class="md-nav__link">
    Bloques
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#administracion" class="md-nav__link">
    Administraci칩n
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#snapshots" class="md-nav__link">
    Snapshots
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hdfs-ui" class="md-nav__link">
    HDFS UI
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hdfs-y-python" class="md-nav__link">
    HDFS y Python
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formatos-de-datos" class="md-nav__link">
    Formatos de datos
  </a>
  
    <nav class="md-nav" aria-label="Formatos de datos">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#filas-vs-columnas" class="md-nav__link">
    Filas vs Columnas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avro" class="md-nav__link">
    Avro
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parquet" class="md-nav__link">
    Parquet
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparando-tamanos" class="md-nav__link">
    Comparando tama침os
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hue" class="md-nav__link">
    Hue
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    Referencias
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#actividades" class="md-nav__link">
    Actividades
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="hdfs">HDFS<a class="headerlink" href="#hdfs" title="Permanent link">&para;</a></h1>
<h2 id="funcionamiento-de-hdfs">Funcionamiento de HDFS<a class="headerlink" href="#funcionamiento-de-hdfs" title="Permanent link">&para;</a></h2>
<p>En la sesi칩n anterior hemos estudiado los diferentes componentes que forman parte de HDFS: <em>namenode</em> y <em>datanodes</em>. En esta sesi칩n veremos los procesos de lectura y escritura, aprenderemos a interactuar con HDFS mediante comandos, el uso de instant치neas y practicaremos con los formatos de datos m치s empleados en <em>Hadoop</em>, como son <em>Avro</em> y <em>Parquet</em>.</p>
<h3 id="procesos-de-lectura">Procesos de lectura<a class="headerlink" href="#procesos-de-lectura" title="Permanent link">&para;</a></h3>
<p>Vamos a entender como fluyen los datos en un proceso de lectura entre el cliente y HDFS a partir de la siguiente imagen:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02hdfs-read.png">
    <figcaption>Proceso de lectura</figcaption>
</figure>

<ol>
<li>El cliente abre el fichero que quiere leer mediante el m칠todo <code>open()</code> del sistema de archivos distribuido.</li>
<li>칄ste llama al <em>namenode</em> mediante una RPC (llamada a procedimiento remoto) el cual le indica la localizaci칩n del primer bloque del fichero. Para cada bloque, el <em>namenode</em> devuelve la direcci칩n de los <em>datanodes</em> que tienen una copia de ese bloque. Adem치s, los <em>datanodes</em> se ordenan respecto a su proximidad con el cliente (depende de la topolog칤a de la red y despliegue en <em>datacenter/rack/nodo</em>). Si el cliente en s칤 es un <em>datanode</em>, la lectura la realizar치 desde su propio sistema local.</li>
<li>El sistema de ficheros distribuido devuelve al cliente un <em>FSDataInputStream</em> (un flujo de entrada que soporta la b칰squeda de ficheros), sobre el cual se invoca la lectura mediante el m칠todo <code>read()</code>. Este flujo, que contiene las direcciones de los <em>datanodes</em> para los primeros bloques del fichero, conecta con el <em>datanode</em> m치s cercano para la lectura del primer bloque.</li>
<li>Los datos se leen desde el <em>datanode</em> con llamadas al m칠todo <code>read()</code>. Cuando se haya le칤do el bloque completo, el flujo de entrada cerrar치 la conexi칩n con el <em>datanode</em> actual y buscar치 el mejor <em>datanode</em> para el siguiente bloque.</li>
<li>Se repite el paso anterior (siempre de manera transparente para el cliente, el cual solo est치 leyendo datos desde un flujo de datos continuo).</li>
<li>Cuando el cliente finaliza la lectura, cierra la conexi칩n con el flujo de datos.</li>
</ol>
<p>Durante la lectura, si el flujo encuentra un error al comunicarse con un <em>datanode</em> (o un error de <em>checksum</em>), intentar치 el proceso con el siguiente nodo m치s cercano (adem치s, recordar치 los nodos que han fallado para no realizar reintentos en futuros bloques y/o informar치 de los bloque corruptos al <em>namenode</em>)</p>
<div class="admonition importante">
<p class="admonition-title">Namenode sin datos</p>
<p>Recordad que los datos nunca pasan por el <em>namenode</em>. El cliente que realiza la conexi칩n con HDFS es el que hace las operaciones de lectura/escritura directamente con los <em>datanodes</em>.
Este dise침o permite que HDFS escale de manera adecuada, ya que el tr치fico de los clientes se esparce por todos los <em>datanodes</em> de nuestro cl칰ster.</p>
</div>
<h3 id="proceso-de-escritura">Proceso de escritura<a class="headerlink" href="#proceso-de-escritura" title="Permanent link">&para;</a></h3>
<p>El proceso de escritura en HDFS sigue un planteamiento similar. Vamos a analizar la creaci칩n, escritura y cierre de un archivo con la siguiente imagen:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02hdfs-write.png">
    <figcaption>Proceso de escritura</figcaption>
</figure>

<ol>
<li>El cliente crea el fichero mediante la llamada al m칠todo <code>create()</code> del <em>DistributedFileSystem</em>.</li>
<li>Este realiza una llamada RPC al <em>namenode</em> para crear el fichero en el sistema de ficheros del <em>namenode</em>, sin ning칰n bloque asociado a 칠l. El <em>namenode</em> realiza varias comprobaciones para asegurar que el fichero no existe previamente y que el usuario tiene los permisos necesarios para su creaci칩n. Tras ello, el <em>namenode</em> determina la forma en que va a dividir los datos en bloques y qu칠 <em>datanodes</em> utilizar치 para almacenar los bloques.</li>
<li>El <em>DistributedFileSystem</em> devuelve un <em>FSDataOutputStream</em>  el cual gestiona la comunicaci칩n con los datanodes y el <em>namenode</em> para que el cliente comience a escribir los datos de cada bloque en el <em>namenode</em> apropiado.</li>
<li>Conforme el cliente escribe los datos, el flujo obtiene del <em>namenode</em> una lista de datanodes candidatos para almacenar las r칠plicas. La lista de nodos forman un <em>pipeline</em>, de manera que si el factor de replicaci칩n es 3, habr치 3 nodos en el <em>pipeline</em>. El flujo env칤a los paquete al primer datanode del pipeline, el cual almacena cada paquete y los reenv칤a al segundo datanode del <em>pipeline</em>. Y as칤 sucesivamente con el resto de nodos del pipeline.</li>
<li>Cuando todos los nodos han confirmado la recepci칩n y almacenamiento de los paquetes, env칤a un paquete de confirmaci칩n al flujo.</li>
<li>Cuando el cliente finaliza con la escritura de los datos, cierra el flujo mediante el m칠todo <code>close()</code> el cual libera los paquetes restantes al pipeline de datanodes y queda a la espera de recibir las confirmaciones. Una vez confirmado, le indica al <em>namenode</em> que la escritura se ha completado, informando de los bloques finales que conforman el fichero (puede que hayan cambiado respecto al paso 2 si ha habido alg칰n error de escritura).</li>
</ol>
<h3 id="hdfs-por-dentro">HDFS por dentro<a class="headerlink" href="#hdfs-por-dentro" title="Permanent link">&para;</a></h3>
<p>HDFS utiliza de un conjunto de ficheros que gestionan los cambios que se producen en el cl칰ster.</p>
<p>Primero entramos en <code>$HADOOP_HOME/etc/hadoop</code> y averiguamos la carpeta de datos que tenemos configurada en <code>hdfs-site.xml</code> para el <em>namenode</em>:</p>
<div class="highlight"><span class="filename">hdfs-site.xml</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos="2 "></span>    <span class="nt">&lt;name&gt;</span>dfs.name.dir<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos="3 "></span>    <span class="nt">&lt;value&gt;</span>file:///opt/hadoop-data/hdfs/namenode<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos="4 "></span><span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>Desde nuestro sistema de archivos, accedemos a dicha carpeta y vemos que existe una carpeta <code>current</code> que contendr치 un conjunto de ficheros cuyos prefijos son:</p>
<ul>
<li><code>edits_000NNN</code>: hist칩rico de cambios que se van produciendo.</li>
<li><code>edits_inprogress_NNN</code>: cambios actuales en memoria que no se han persistido.</li>
<li><code>fsimagen_000NNN</code>: <em>snapshot</em> en el tiempo del sistema de ficheros.</li>
</ul>
<figure align="center">
    <img src="../imagenes/hadoop/02hdfsPorDentro.png">
    <figcaption>HDFS por dentro</figcaption>
</figure>

<p>Al arrancar HDFS se carga en memoria el 칰ltimo fichero <code>fsimage</code> disponible junto con los <code>edits</code> que no han sido procesados. Mediante el <em>secondary namenode</em>, cuando se llena un bloque, se ir치n sincronizando los cambios que se producen en <code>edits_inprogress</code> creando un nuevo <code>fsimage</code> y un nuevo <code>edits</code>.</p>
<p>As칤 pues, cada vez que se reinicie el <em>namenode</em>, se realizar치 el <em>merge</em> de los archivos <code>fsimage</code> y <code>edits log</code>.</p>
<h2 id="trabajando-con-hdfs">Trabajando con HDFS<a class="headerlink" href="#trabajando-con-hdfs" title="Permanent link">&para;</a></h2>
<p>Para interactuar con el almacenamiento desde un terminal, se utiliza el comando <code>hdfs</code>. Este comando admite un segundo par치metro con diferentes opciones.</p>
<p>Antes la duda, es recomendable consultar la <a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">documentaci칩n oficial</a></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs comando
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">hadoop fs</p>
<p><figure style="float: left; padding-right: 20px">
    <img src="../imagenes/hadoop/02hdfsdfs.png" width="250">
    <figcaption>HDFS DFS</figcaption>
</figure></p>
<p><code>hadoop fs</code> se relaciona con un sistema de archivos gen칠rico que puede apuntar a cualquier sistema de archivos como local, HDFS, FTP, S3, etc. En versiones anteriores se utilizaba el comando <code>hadoop dfs</code> para acceder a HDFS, pero ya quedado obsoleto en favor de <code>hdfs dfs</code>.</p>
</div>
<p>En el caso concreto de interactuar con el sistema de ficheros de Hadoop se utiliza el comando <code>dfs</code>, el cual requiere de otro argumento (empezando con un gui칩n) el cual ser치 uno de los comandos Linux para interactuar con el shell. Pod칠is consultar la lista de comandos en la <a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html">documentaci칩n oficial</a>.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -comandosLinux
</code></pre></div>
<p>Por ejemplo, para mostrar todos los archivos que tenemos en el ra칤z har칤amos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -ls
</code></pre></div>
<p>Los comandos m치s utilizados son:</p>
<ul>
<li><code>put</code>: Coloca un archivo dentro de HDFS</li>
<li><code>get</code>: Recupera un archivo de HDFS y lo lleva a nuestro sistema <em>host</em>.</li>
<li><code>cat</code> / <code>text</code> / <code>head</code> / <code>tail</code>: Visualiza el contenido de un archivo.</li>
<li><code>mkdir</code> / <code>rmdir</code>: Crea / borra una carpeta.</li>
<li><code>count</code>: Cuenta el n칰mero de elementos (n칰mero de carpetas, ficheros, tama침o y ruta).</li>
<li><code>cp</code> / <code>mv</code> / <code>rm</code>: Copia / mueve-renombra / elimina un archivo.</li>
</ul>
<div class="admonition question">
<p class="admonition-title">Autoevaluaci칩n</p>
<p>쯉abes qu칠 realiza cada uno de los siguientes comandos?</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -mkdir /user/iabd/datos
<span class="linenos" data-linenos="2 "></span>hdfs dfs -put ejemplo.txt /user/iabd/datos/
<span class="linenos" data-linenos="3 "></span>hdfs dfs -put ejemplo.txt /user/iabd/datos/ejemploRenombrado.txt
<span class="linenos" data-linenos="4 "></span>hdfs dfs -ls datos
<span class="linenos" data-linenos="5 "></span>hdfs dfs -count datos
<span class="linenos" data-linenos="6 "></span>hdfs dfs -mv datos/ejemploRenombrado.txt /user/iabd/datos/otroNombre.json
<span class="linenos" data-linenos="7 "></span>hdfs dfs -get /datos/otroNombre.json /tmp
</code></pre></div>
</div>
<h3 id="bloques">Bloques<a class="headerlink" href="#bloques" title="Permanent link">&para;</a></h3>
<p>A continuaci칩n vamos a ver c칩mo trabaja internamente HDFS con los bloques. Para el siguiente ejemplo, vamos a trabajar con un archivo que ocupe m치s de un bloque, como puede ser <a href="https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv">El registro de taxis amarillos de Nueva York - Enero 2020</a>.</p>
<p>Comenzaremos creando un directorio dentro de HDFS llamado <code>prueba-hdfs</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -mkdir /user/iabd/prueba-hdfs
</code></pre></div>
<p>Una vez creado subimos el archivo con los taxis:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -put yellow_tripdata_2020-01.csv  /user/iabd/prueba-hdfs
</code></pre></div>
<p>Con el fichero subido nos vamos al interfaz gr치fico de Hadoop (<a href="http://iabd-virtualbox:9870/explorer.html#/">http://iabd-virtualbox:9870/explorer.html#/</a>), localizamos el archivo y obtenemos el <em>Block Pool ID</em> del <em>block information</em>:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02hdfs-blockid.png">
    <figcaption>Identificador de bloque</figcaption>
</figure>

<p>Si desplegamos el combo de <em>block information</em>, podremos ver c칩mo ha partido el archivo CSV en 5 bloques (566 MB que ocupa el fichero CSV / 128 del tama침o del bloque).</p>
<p>As칤 pues, con el c칩digo del <em>Block Pool Id</em>, podemos confirmar que debe existir el directorio <code>current</code> del <em>datanode</em> donde almacena la informaci칩n nuestro servidor (en `/opt/hadoop-data/):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>ls /opt/hadoop-data/hdfs/datanode/current/BP-481169443-127.0.1.1-1639217848073/current
</code></pre></div>
<p>Dentro de este subdirectorio existe otro <code>finalized</code>, donde <em>Hadoop</em> ir치 creando una estructura de subdirectorios <code>subdir</code> donde albergar치 los bloques de datos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>ls /opt/hadoop-data/hdfs/datanode/current/BP-481169443-127.0.1.1-1639217848073/current/finalized/subdir0
</code></pre></div>
<p>Una vez en este nivel, vamos a buscar el archivo que coincide con el <em>block id</em> poni칠ndole como prefijo <code>blk_</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>find -name blk_1073743451
</code></pre></div>
<p>En mi caso devuelve <code>./subdir6/blk_1073743451</code>. De manera que ya podemos comprobar como el inicio del documento se encuentra en dicho archivo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>head /opt/hadoop-data/hdfs/datanode/current/BP-481169443-127.0.1.1-1639217848073/current/finalized/subdir0/subdir6/blk_1073743451
</code></pre></div>
<h3 id="administracion">Administraci칩n<a class="headerlink" href="#administracion" title="Permanent link">&para;</a></h3>
<p>Algunas de las opciones m치s 칰tiles para administrar HDFS son:</p>
<ul>
<li><code>hdfs dfsadmin -report</code>: Realiza un resumen del sistema HDFS, similar al que aparece en el interfaz web, donde podemos comprobar el estado de los diferentes nodos.</li>
<li><code>hdfs fsck</code>: Comprueba el estado del sistema de ficheros. Si queremos comprobar el estado de un determinado directorio, lo indicamos mediante un segundo par치metro: <code>hdfs fsck /datos/prueba</code></li>
<li><code>hdfs dfsadmin -printTopology</code>: Muestra la topolog칤a, identificando los nodos que tenemos y al rack al que pertenece cada nodo.</li>
<li><code>hdfs dfsadmin -listOpenFiles</code>: Comprueba si hay alg칰n fichero abierto.</li>
<li><code>hdfs dfsadmin -safemode enter</code>: Pone el sistema en modo seguro el cual evita la modificaci칩n de los recursos del sistema de archivos.</li>
</ul>
<h3 id="snapshots"><em>Snapshots</em><a class="headerlink" href="#snapshots" title="Permanent link">&para;</a></h3>
<p>Mediante las <em>snapshots</em> podemos crear una instant치nea que almacena c칩mo est치 en un determinado momento nuestro sistema de ficheros, a modo de copia de seguridad de los datos, para en un futuro poder realizar una recuperaci칩n.</p>
<p>El primer paso es activar el uso de <em>snapshots</em>, mediante el comando de administraci칩n indicando sobre qu칠 carpeta vamos a habilitar su uso:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfsadmin -allowSnapshot /user/iabd/datos
</code></pre></div>
<p>El siguiente paso es crear una <em>snapshot</em>, para ello se indica tanto la carpeta como un nombre para la captura (es un comando que se realiza sobre el sistema de archivos):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -createSnapshot /user/iabd/datos snapshot1
</code></pre></div>
<p>Esta captura se crear치 dentro de una carpeta oculta dentro de la ruta indicada (en nuestro caso crear치 la carpeta  <code>/user/iabd/datos/.snapshot/snapshot1/</code> la cual contendr치 la informaci칩n de la instant치nea).</p>
<p>A continuaci칩n, vamos a borrar uno de los archivo creados anteriormente y comprobar que ya no existe:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -rm /user/iabd/datos/ejemplo.txt
<span class="linenos" data-linenos="2 "></span>hdfs dfs -ls /user/iabd/datos
</code></pre></div>
<p>Para comprobar el funcionamiento de los <em>snapshots</em>, vamos a recuperar el archivo desde la captura creada anteriormente.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -cp <span class="se">\</span>
<span class="linenos" data-linenos="2 "></span>    /user/iabd/datos/.snapshot/snapshot1/ejemplo.txt <span class="se">\</span>
<span class="linenos" data-linenos="3 "></span>    /user/iabd/datos
</code></pre></div>
<p>Si queremos saber que carpetas soportan las instant치neas:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs lsSnapshottableDir
</code></pre></div>
<p>Finalmente, si queremos deshabilitar las <em>snapshots</em> de una determinada carpeta, primero hemos de eliminarlas y luego deshabilitarlas:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -deleteSnapshot /user/iabd/datos snapshot1
<span class="linenos" data-linenos="2 "></span>hdfs dfsadmin -disallowSnapshot /user/iabd/datos
</code></pre></div>
<h3 id="hdfs-ui">HDFS UI<a class="headerlink" href="#hdfs-ui" title="Permanent link">&para;</a></h3>
<p>En la sesi칩n anterior ya vimos que pod칤amos acceder al interfaz gr치fico de Hadoop (<a href="http://iabd-virtualbox:9870/explorer.html#/">http://iabd-virtualbox:9870/explorer.html#/</a>) y navegar por las carpetas de HDFS.</p>
<p>Si intentamos crear una carpeta o eliminar alg칰n archivo recibimos un mensaje del tipo <em>Permission denied: user=dr.who, access=WRITE, inode="/":iabd:supergroup:drwxr-xr-x</em>. Por defecto, los recursos via web los crea el usuario <em>dr.who</em>.</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02hdfs-ui-error.png">
    <figcaption>Error al crear un directorio mediante Hadoop UI</figcaption>
</figure>

<p>Si queremos habilitar los permisos para que desde este IU podamos crear/modificar/eliminar recursos, podemos cambiar permisos a la carpeta:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -mkdir /user/iabd/pruebas
<span class="linenos" data-linenos="2 "></span>hdfs dfs -chmod <span class="m">777</span> /user/iabd/pruebas 
</code></pre></div>
<p>Si ahora accedemos al interfaz, s칤 que podremos trabajar con la carpeta <code>pruebas</code> via web, teniendo en cuenta que las operaciones las realiza el usuario <code>dr.who</code> que pertenece al grupo <code>supergroup</code>.</p>
<p>Otra posibilidad es modificar el archivo de configuraci칩n <code>core-site.xml</code> y a침adir una propiedad para modificar el usuario est치tico:</p>
<div class="highlight"><span class="filename">core-site.xml</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos="2 "></span>    <span class="nt">&lt;name&gt;</span>hadoop.http.staticuser.user<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos="3 "></span>    <span class="nt">&lt;value&gt;</span>iabd<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos="4 "></span><span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>Tras reiniciar <em>Hadoop</em>, ya podremos crear los recursos como el usuario <code>iabd</code>.</p>
<h2 id="hdfs-y-python">HDFS y Python<a class="headerlink" href="#hdfs-y-python" title="Permanent link">&para;</a></h2>
<p>Para el acceso mediante Python a HDFS podemos utilizar la librer칤a HdfsCLI (<a href="https://hdfscli.readthedocs.io/en/latest/">https://hdfscli.readthedocs.io/en/latest/</a>).</p>
<p>Primero hemos de instalarla mediante <code>pip</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>pip install hdfs
</code></pre></div>
<p>Vamos a ver un sencillo ejemplo de lectura y escritura en HDFS:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">hdfs</span> <span class="kn">import</span> <span class="n">InsecureClient</span>
<span class="linenos" data-linenos=" 2 "></span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># Datos de conexi칩n</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">HDFS_HOSTNAME</span> <span class="o">=</span> <span class="s1">&#39;iabd-virtualbox&#39;</span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">HDFSCLI_PORT</span> <span class="o">=</span> <span class="mi">9870</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">HDFSCLI_CONNECTION_STRING</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;http://</span><span class="si">{</span><span class="n">HDFS_HOSTNAME</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">HDFSCLI_PORT</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># En nuestro caso, al no usar Kerberos, creamos una conexi칩n no segura</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">hdfs_client</span> <span class="o">=</span> <span class="n">InsecureClient</span><span class="p">(</span><span class="n">HDFSCLI_CONNECTION_STRING</span><span class="p">)</span>
<span class="linenos" data-linenos="10 "></span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># Leemos el fichero de &#39;El quijote&#39; que tenemos en HDFS</span>
<span class="linenos" data-linenos="12 "></span><span class="n">fichero</span> <span class="o">=</span> <span class="s1">&#39;/user/iabd/el_quijote.txt&#39;</span>
<span class="linenos" data-linenos="13 "></span><span class="k">with</span> <span class="n">hdfs_client</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">fichero</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
<span class="linenos" data-linenos="14 "></span>    <span class="n">texto</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="linenos" data-linenos="15 "></span>
<span class="linenos" data-linenos="16 "></span><span class="nb">print</span><span class="p">(</span><span class="n">texto</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># Creamos una cadena con formato CSV y la almacenamos en HDFS</span>
<span class="linenos" data-linenos="19 "></span><span class="n">datos</span><span class="o">=</span><span class="s2">&quot;nombre,apellidos</span><span class="se">\n</span><span class="s2">Aitor,Medrano</span><span class="se">\n</span><span class="s2">Pedro,Casas&quot;</span>
<span class="linenos" data-linenos="20 "></span><span class="n">hdfs_client</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;/user/iabd/datos.csv&quot;</span><span class="p">,</span> <span class="n">datos</span><span class="p">)</span>
</code></pre></div>
<p>En el mundo real, los formatos de los archivos normalmente ser치n <em>Avro</em> y/o <em>Parquet</em>, y el acceso lo realizaremos en gran medida mediante la librer칤a de <em>Pandas</em>.</p>
<h2 id="formatos-de-datos">Formatos de datos<a class="headerlink" href="#formatos-de-datos" title="Permanent link">&para;</a></h2>
<p>En el primer bloque ya vimos una peque침a introducci칩n a los diferentes <a href="https://manoli-iborra.github.io/bigdata2122/apuntes04.html#formato-de-datos_1">formatos de datos</a>.</p>
<p>Las propiedades que ha de tener un formato de datos son:</p>
<ul>
<li>independiente del lenguaje</li>
<li>expresivo, con soporte para estructuras complejas y anidadas</li>
<li>eficiente, r치pido y reducido</li>
<li>din치mico, de manera que los programas puedan procesar y definir nuevos tipos de datos.</li>
<li>formato de fichero <em>standalone</em> y que permita <strong>dividirlo</strong> y comprimirlo.</li>
</ul>
<p>Para que Hadoop pueda procesar documento, es imprescindible que el formato del fichero permita su divisi칩n en fragmentos (<em>splittable in chunks</em>).</p>
<p>Si los clasificamos respecto al formato de almacenamiento tenemos:</p>
<ul>
<li>texto (m치s lentos, ocupan m치s pero son m치s expresivos y permiten su interoperabilidad): CSV, XML, JSON, etc...</li>
<li>binarios (mejor rendimiento, ocupan menos, menos expresivos): Avro, Parquet, ORC, etc...</li>
</ul>
<p>Si comparamos los formatos m치s empleados a partir de las propiedades descritas tenemos:</p>
<table>
<thead>
<tr>
<th>Caracter칤stica</th>
<th>CSV</th>
<th>XML / JSON</th>
<th>SequenceFile</th>
<th>Avro</th>
</tr>
</thead>
<tbody>
<tr>
<td>Independencia del lenguaje</td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M128 288V64.03c0-17.67-14.33-31.1-32-31.1H32c-17.67 0-32 14.33-32 31.1v223.1c0 17.67 14.33 31.1 32 31.1h64c17.7 1.77 32-12.53 32-30.23zm353.5-58.9a66.276 66.276 0 0 0 1.875-15.64c0-22.7-11.44-43.13-29.28-55.28a65.97 65.97 0 0 0 .64-9.122c0-22.32-11.06-42.6-28.83-54.83-2.437-34.71-31.47-62.2-66.8-62.2h-52.53c-35.94 0-71.55 11.87-100.3 33.41L169.6 92.93c-6.285 4.71-9.596 11.85-9.596 19.13 0 12.76 10.29 24.04 24.03 24.04 5.013 0 10.07-1.565 14.38-4.811l36.66-27.51c20.48-15.34 45.88-23.81 71.5-23.81h52.53c10.45 0 18.97 8.497 18.97 18.95 0 3.5-1.11 4.94-1.11 9.456 0 26.97 29.77 17.91 29.77 40.64 0 9.254-6.392 10.96-6.392 22.25 0 13.97 10.85 21.95 19.58 23.59 8.953 1.671 15.45 9.481 15.45 18.56 0 13.04-11.39 13.37-11.39 28.91 0 12.54 9.702 23.08 22.36 23.94C456.2 266.1 464 275.2 464 284.1c0 10.43-8.516 18.93-18.97 18.93H307.4c-12.44 0-24 10.02-24 23.1 0 4.038 1.02 8.078 3.066 11.72C304.4 371.7 312 403.8 312 411.2c0 8.044-5.984 20.79-22.06 20.79-12.53 0-14.27-.906-24.94-28.07-24.75-62.91-61.74-99.9-80.98-99.9-13.8 0-24.02 11.27-24.02 23.99 0 7.041 3.083 14.02 9.016 18.76C238.1 402 211.4 480 289.9 480c43.9 0 70.1-35 70.1-68.8 0-12.7-5.328-35.21-14.83-59.33h99.86C481.1 351.9 512 321.9 512 284.1c0-22.3-12.1-43.1-30.5-55z"/></svg></span></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
</tr>
<tr>
<td>Expresivo</td>
<td><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M128 288V64.03c0-17.67-14.33-31.1-32-31.1H32c-17.67 0-32 14.33-32 31.1v223.1c0 17.67 14.33 31.1 32 31.1h64c17.7 1.77 32-12.53 32-30.23zm353.5-58.9a66.276 66.276 0 0 0 1.875-15.64c0-22.7-11.44-43.13-29.28-55.28a65.97 65.97 0 0 0 .64-9.122c0-22.32-11.06-42.6-28.83-54.83-2.437-34.71-31.47-62.2-66.8-62.2h-52.53c-35.94 0-71.55 11.87-100.3 33.41L169.6 92.93c-6.285 4.71-9.596 11.85-9.596 19.13 0 12.76 10.29 24.04 24.03 24.04 5.013 0 10.07-1.565 14.38-4.811l36.66-27.51c20.48-15.34 45.88-23.81 71.5-23.81h52.53c10.45 0 18.97 8.497 18.97 18.95 0 3.5-1.11 4.94-1.11 9.456 0 26.97 29.77 17.91 29.77 40.64 0 9.254-6.392 10.96-6.392 22.25 0 13.97 10.85 21.95 19.58 23.59 8.953 1.671 15.45 9.481 15.45 18.56 0 13.04-11.39 13.37-11.39 28.91 0 12.54 9.702 23.08 22.36 23.94C456.2 266.1 464 275.2 464 284.1c0 10.43-8.516 18.93-18.97 18.93H307.4c-12.44 0-24 10.02-24 23.1 0 4.038 1.02 8.078 3.066 11.72C304.4 371.7 312 403.8 312 411.2c0 8.044-5.984 20.79-22.06 20.79-12.53 0-14.27-.906-24.94-28.07-24.75-62.91-61.74-99.9-80.98-99.9-13.8 0-24.02 11.27-24.02 23.99 0 7.041 3.083 14.02 9.016 18.76C238.1 402 211.4 480 289.9 480c43.9 0 70.1-35 70.1-68.8 0-12.7-5.328-35.21-14.83-59.33h99.86C481.1 351.9 512 321.9 512 284.1c0-22.3-12.1-43.1-30.5-55z"/></svg></span></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
</tr>
<tr>
<td>Eficiente</td>
<td><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M128 288V64.03c0-17.67-14.33-31.1-32-31.1H32c-17.67 0-32 14.33-32 31.1v223.1c0 17.67 14.33 31.1 32 31.1h64c17.7 1.77 32-12.53 32-30.23zm353.5-58.9a66.276 66.276 0 0 0 1.875-15.64c0-22.7-11.44-43.13-29.28-55.28a65.97 65.97 0 0 0 .64-9.122c0-22.32-11.06-42.6-28.83-54.83-2.437-34.71-31.47-62.2-66.8-62.2h-52.53c-35.94 0-71.55 11.87-100.3 33.41L169.6 92.93c-6.285 4.71-9.596 11.85-9.596 19.13 0 12.76 10.29 24.04 24.03 24.04 5.013 0 10.07-1.565 14.38-4.811l36.66-27.51c20.48-15.34 45.88-23.81 71.5-23.81h52.53c10.45 0 18.97 8.497 18.97 18.95 0 3.5-1.11 4.94-1.11 9.456 0 26.97 29.77 17.91 29.77 40.64 0 9.254-6.392 10.96-6.392 22.25 0 13.97 10.85 21.95 19.58 23.59 8.953 1.671 15.45 9.481 15.45 18.56 0 13.04-11.39 13.37-11.39 28.91 0 12.54 9.702 23.08 22.36 23.94C456.2 266.1 464 275.2 464 284.1c0 10.43-8.516 18.93-18.97 18.93H307.4c-12.44 0-24 10.02-24 23.1 0 4.038 1.02 8.078 3.066 11.72C304.4 371.7 312 403.8 312 411.2c0 8.044-5.984 20.79-22.06 20.79-12.53 0-14.27-.906-24.94-28.07-24.75-62.91-61.74-99.9-80.98-99.9-13.8 0-24.02 11.27-24.02 23.99 0 7.041 3.083 14.02 9.016 18.76C238.1 402 211.4 480 289.9 480c43.9 0 70.1-35 70.1-68.8 0-12.7-5.328-35.21-14.83-59.33h99.86C481.1 351.9 512 321.9 512 284.1c0-22.3-12.1-43.1-30.5-55z"/></svg></span></td>
<td><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M128 288V64.03c0-17.67-14.33-31.1-32-31.1H32c-17.67 0-32 14.33-32 31.1v223.1c0 17.67 14.33 31.1 32 31.1h64c17.7 1.77 32-12.53 32-30.23zm353.5-58.9a66.276 66.276 0 0 0 1.875-15.64c0-22.7-11.44-43.13-29.28-55.28a65.97 65.97 0 0 0 .64-9.122c0-22.32-11.06-42.6-28.83-54.83-2.437-34.71-31.47-62.2-66.8-62.2h-52.53c-35.94 0-71.55 11.87-100.3 33.41L169.6 92.93c-6.285 4.71-9.596 11.85-9.596 19.13 0 12.76 10.29 24.04 24.03 24.04 5.013 0 10.07-1.565 14.38-4.811l36.66-27.51c20.48-15.34 45.88-23.81 71.5-23.81h52.53c10.45 0 18.97 8.497 18.97 18.95 0 3.5-1.11 4.94-1.11 9.456 0 26.97 29.77 17.91 29.77 40.64 0 9.254-6.392 10.96-6.392 22.25 0 13.97 10.85 21.95 19.58 23.59 8.953 1.671 15.45 9.481 15.45 18.56 0 13.04-11.39 13.37-11.39 28.91 0 12.54 9.702 23.08 22.36 23.94C456.2 266.1 464 275.2 464 284.1c0 10.43-8.516 18.93-18.97 18.93H307.4c-12.44 0-24 10.02-24 23.1 0 4.038 1.02 8.078 3.066 11.72C304.4 371.7 312 403.8 312 411.2c0 8.044-5.984 20.79-22.06 20.79-12.53 0-14.27-.906-24.94-28.07-24.75-62.91-61.74-99.9-80.98-99.9-13.8 0-24.02 11.27-24.02 23.99 0 7.041 3.083 14.02 9.016 18.76C238.1 402 211.4 480 289.9 480c43.9 0 70.1-35 70.1-68.8 0-12.7-5.328-35.21-14.83-59.33h99.86C481.1 351.9 512 321.9 512 284.1c0-22.3-12.1-43.1-30.5-55z"/></svg></span></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
</tr>
<tr>
<td>Din치mico</td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M128 288V64.03c0-17.67-14.33-31.1-32-31.1H32c-17.67 0-32 14.33-32 31.1v223.1c0 17.67 14.33 31.1 32 31.1h64c17.7 1.77 32-12.53 32-30.23zm353.5-58.9a66.276 66.276 0 0 0 1.875-15.64c0-22.7-11.44-43.13-29.28-55.28a65.97 65.97 0 0 0 .64-9.122c0-22.32-11.06-42.6-28.83-54.83-2.437-34.71-31.47-62.2-66.8-62.2h-52.53c-35.94 0-71.55 11.87-100.3 33.41L169.6 92.93c-6.285 4.71-9.596 11.85-9.596 19.13 0 12.76 10.29 24.04 24.03 24.04 5.013 0 10.07-1.565 14.38-4.811l36.66-27.51c20.48-15.34 45.88-23.81 71.5-23.81h52.53c10.45 0 18.97 8.497 18.97 18.95 0 3.5-1.11 4.94-1.11 9.456 0 26.97 29.77 17.91 29.77 40.64 0 9.254-6.392 10.96-6.392 22.25 0 13.97 10.85 21.95 19.58 23.59 8.953 1.671 15.45 9.481 15.45 18.56 0 13.04-11.39 13.37-11.39 28.91 0 12.54 9.702 23.08 22.36 23.94C456.2 266.1 464 275.2 464 284.1c0 10.43-8.516 18.93-18.97 18.93H307.4c-12.44 0-24 10.02-24 23.1 0 4.038 1.02 8.078 3.066 11.72C304.4 371.7 312 403.8 312 411.2c0 8.044-5.984 20.79-22.06 20.79-12.53 0-14.27-.906-24.94-28.07-24.75-62.91-61.74-99.9-80.98-99.9-13.8 0-24.02 11.27-24.02 23.99 0 7.041 3.083 14.02 9.016 18.76C238.1 402 211.4 480 289.9 480c43.9 0 70.1-35 70.1-68.8 0-12.7-5.328-35.21-14.83-59.33h99.86C481.1 351.9 512 321.9 512 284.1c0-22.3-12.1-43.1-30.5-55z"/></svg></span></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
</tr>
<tr>
<td><em>Standalone</em></td>
<td><img alt="仇" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/2754.svg" title=":grey_question:" /></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M128 288V64.03c0-17.67-14.33-31.1-32-31.1H32c-17.67 0-32 14.33-32 31.1v223.1c0 17.67 14.33 31.1 32 31.1h64c17.7 1.77 32-12.53 32-30.23zm353.5-58.9a66.276 66.276 0 0 0 1.875-15.64c0-22.7-11.44-43.13-29.28-55.28a65.97 65.97 0 0 0 .64-9.122c0-22.32-11.06-42.6-28.83-54.83-2.437-34.71-31.47-62.2-66.8-62.2h-52.53c-35.94 0-71.55 11.87-100.3 33.41L169.6 92.93c-6.285 4.71-9.596 11.85-9.596 19.13 0 12.76 10.29 24.04 24.03 24.04 5.013 0 10.07-1.565 14.38-4.811l36.66-27.51c20.48-15.34 45.88-23.81 71.5-23.81h52.53c10.45 0 18.97 8.497 18.97 18.95 0 3.5-1.11 4.94-1.11 9.456 0 26.97 29.77 17.91 29.77 40.64 0 9.254-6.392 10.96-6.392 22.25 0 13.97 10.85 21.95 19.58 23.59 8.953 1.671 15.45 9.481 15.45 18.56 0 13.04-11.39 13.37-11.39 28.91 0 12.54 9.702 23.08 22.36 23.94C456.2 266.1 464 275.2 464 284.1c0 10.43-8.516 18.93-18.97 18.93H307.4c-12.44 0-24 10.02-24 23.1 0 4.038 1.02 8.078 3.066 11.72C304.4 371.7 312 403.8 312 411.2c0 8.044-5.984 20.79-22.06 20.79-12.53 0-14.27-.906-24.94-28.07-24.75-62.91-61.74-99.9-80.98-99.9-13.8 0-24.02 11.27-24.02 23.99 0 7.041 3.083 14.02 9.016 18.76C238.1 402 211.4 480 289.9 480c43.9 0 70.1-35 70.1-68.8 0-12.7-5.328-35.21-14.83-59.33h99.86C481.1 351.9 512 321.9 512 284.1c0-22.3-12.1-43.1-30.5-55z"/></svg></span></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
</tr>
<tr>
<td>Dividible</td>
<td><img alt="仇" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/2754.svg" title=":grey_question:" /></td>
<td><img alt="仇" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/2754.svg" title=":grey_question:" /></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
<td><img alt="游녨" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f44d.svg" title=":thumbsup:" /></td>
</tr>
</tbody>
</table>
<!--
https://www.xenonstack.com/blog/data-serialization-hadoop
-->

<p>Las ventajas de elegir el formato correcto son:</p>
<ul>
<li>Mayor rendimiento en la lectura y/o escritura</li>
<li>Ficheros <em>trozeables</em> (<em>splittables</em>)</li>
<li>Soporte para esquemas que evolucionan</li>
<li>Soporte para compresi칩n de los datos (por ejemplo, mediante <em>Snappy</em>).</li>
</ul>
<h3 id="filas-vs-columnas">Filas vs Columnas<a class="headerlink" href="#filas-vs-columnas" title="Permanent link">&para;</a></h3>
<p>Los formatos con los que estamos m치s familiarizados, como son CSV o JSON, se basan en filas, donde cada registro se almacena en una fila o documento. Estos formatos son m치s lentos en ciertas consultas y su almacenamiento no es 칩ptimo.</p>
<p>En un formato basado en columnas, cada fila almacena toda la informaci칩n de una columna. Al basarse en columnas, ofrece mejor rendimiento para consultas de determinadas columnas y/o agregaciones, y el almacenamiento es m치s 칩ptimo (como todos los datos de una columna son del mismo tipo, la compresi칩n es mayor).</p>
<p>Supongamos que tenemos los siguientes datos:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02formatos-tabla.png" width="500">
    <figcaption>Ejemplo de tabla</figcaption>
</figure>

<p>Dependiendo del almacenamiento en filas o columnas tendr칤amos la siguiente representaci칩n:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02formatos-filacolumna.png">
    <figcaption>Comparaci칩n filas y columnas</figcaption>
</figure>

<p>En un formato columnas los datos del mismo tipo se agrupan, lo que mejor el rendimiento de acceso y reduce el tama침o:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02formatos-column-encoding.png">
    <figcaption>Comparaci칩n filas y columnas</figcaption>
</figure>

<p>El art칤culo <a href="https://blog.openbridge.com/how-to-be-a-hero-with-powerful-parquet-google-and-amazon-f2ae0f35ee04">Apache Parquet: How to be a hero with the open-source columnar data format</a> compara un formato basado en filas, como CSV, con uno basado en columnas como Parquet, en base al tiempo y el coste de su lectura en AWS (por ejemplo, AWS Athena cobra 5$ por cada TB escaneado):</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02formatos-comparativa1.png">
    <figcaption>Comparaci칩n CSV y Parquet</figcaption>
</figure>

<p>En la tabla podemos observar como 1TB de un fichero CSV en texto plano pasa a ocupar s칩lo 130GB mediante Parquet, lo que provoca que las posteriores consultas tarden menos y, en consecuencia, cuesten menos.</p>
<p>En la siguiente tabla comparamos un fichero CSV compuesto de cuatro columnas almacenado en S3 mediante tres formatos:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02formatos-comparativa2.png">
    <figcaption>Comparaci칩n filas y columnas</figcaption>
</figure>

<p>Queda claro que la elecci칩n del formato de los datos y la posibilidad de elegir el formato dependiendo de sus futuros casos de uso puede conllevar un importante ahorro en tiempo y costes.</p>
<h3 id="avro">Avro<a class="headerlink" href="#avro" title="Permanent link">&para;</a></h3>
<figure style="float: right;">
    <img src="../imagenes/hadoop/02avro-logo.png" width="150">
    <figcaption>Logo de Apache Avro</figcaption>
</figure>

<p><a href="https://avro.apache.org/">Apache Avro</a> es un formato de almacenamiento basado en filas para <em>Hadoop</em>, utilizado para la serializaci칩n de datos, ya que es m치s r치pido y ocupa menos espacio que JSON, debido a que la serializaci칩n de los datos se realiza en un formato binario compacto.</p>
<p><em>Avro</em> se basa en esquemas, los cuales se realizan mediante JSON para definir los tipos de datos y protocolos. Cuando los datos <code>.avro</code> son le칤dos siempre est치 presente el esquema con el que han sido escritos.</p>
<h4 id="schema">Schema<a class="headerlink" href="#schema" title="Permanent link">&para;</a></h4>
<p>Los esquemas se componen de tipos primitivos (<code>null</code>, <code>boolean</code>, <code>int</code>, <code>long</code>, <code>float</code>, <code>double</code>, <code>bytes</code>, y <code>string</code>) y compuestos (<code>record</code>, <code>enum</code>, <code>array</code>, <code>map</code>, <code>union</code>, y <code>fixed</code>).</p>
<p>Un ejemplo de esquema podr칤a ser:</p>
<div class="highlight"><span class="filename">empleado.avsc</span><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="p">{</span><span class="w"></span>
<span class="linenos" data-linenos=" 2 "></span><span class="w">   </span><span class="nt">&quot;type&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;record&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos=" 3 "></span><span class="w">   </span><span class="nt">&quot;namespace&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;SeveroOchoa&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos=" 4 "></span><span class="w">   </span><span class="nt">&quot;name&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Empleado&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos=" 5 "></span><span class="w">   </span><span class="nt">&quot;fields&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"></span>
<span class="linenos" data-linenos=" 6 "></span><span class="w">      </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;name&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Nombre&quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;type&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;string&quot;</span><span class="w"> </span><span class="p">},</span><span class="w"></span>
<span class="linenos" data-linenos=" 7 "></span><span class="w">      </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;name&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Altura&quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;type&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;float&quot;</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="linenos" data-linenos=" 8 "></span><span class="w">      </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;name&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Edad&quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;type&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int&quot;</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="linenos" data-linenos=" 9 "></span><span class="w">   </span><span class="p">]</span><span class="w"></span>
<span class="linenos" data-linenos="10 "></span><span class="p">}</span><span class="w"></span>
</code></pre></div>
<h4 id="python">Python<a class="headerlink" href="#python" title="Permanent link">&para;</a></h4>
<p>Para poder serializar y deserializar documentos <em>Avro</em> mediante <em>Python</em>, previamente debemos instalar la librer칤a <code>avro</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>pip install avro-python3
<span class="linenos" data-linenos="2 "></span><span class="c1"># o si utilizamos Anaconda</span>
<span class="linenos" data-linenos="3 "></span>conda install -c conda-forge avro-python3
</code></pre></div>
<p>Vamos a realizar un ejemplo donde primero leemos un esquema de un archivo <em>Avro</em>, y con dicho esquema, escribiremos nuevos datos en un fichero. A continuaci칩n, abrimos el fichero escrito y leemos y mostramos los datos:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">C칩digo Python</label><label for="__tabbed_1_2">Resultado</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">avro</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="linenos" data-linenos=" 3 "></span><span class="kn">import</span> <span class="nn">json</span>
<span class="linenos" data-linenos=" 4 "></span><span class="kn">from</span> <span class="nn">avro.datafile</span> <span class="kn">import</span> <span class="n">DataFileReader</span><span class="p">,</span> <span class="n">DataFileWriter</span>
<span class="linenos" data-linenos=" 5 "></span><span class="kn">from</span> <span class="nn">avro.io</span> <span class="kn">import</span> <span class="n">DatumReader</span><span class="p">,</span> <span class="n">DatumWriter</span>
<span class="linenos" data-linenos=" 6 "></span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># abrimos el fichero en modo binario y leemos el esquema</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">schema</span> <span class="o">=</span> <span class="n">avro</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;empleado.avsc&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># escribimos un fichero a partir del esquema le칤do</span>
<span class="linenos" data-linenos="11 "></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;empleados.avro&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos" data-linenos="12 "></span>    <span class="n">writer</span> <span class="o">=</span> <span class="n">DataFileWriter</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">DatumWriter</span><span class="p">(),</span> <span class="n">schema</span><span class="p">)</span>
<span class="linenos" data-linenos="13 "></span>    <span class="n">writer</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;nombre&quot;</span><span class="p">:</span> <span class="s2">&quot;Carlos&quot;</span><span class="p">,</span> <span class="s2">&quot;altura&quot;</span><span class="p">:</span> <span class="mi">180</span><span class="p">,</span> <span class="s2">&quot;edad&quot;</span><span class="p">:</span> <span class="mi">44</span><span class="p">})</span>
<span class="linenos" data-linenos="14 "></span>    <span class="n">writer</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;nombre&quot;</span><span class="p">:</span> <span class="s2">&quot;Juan&quot;</span><span class="p">,</span> <span class="s2">&quot;altura&quot;</span><span class="p">:</span> <span class="mi">175</span><span class="p">})</span>
<span class="linenos" data-linenos="15 "></span>    <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="linenos" data-linenos="16 "></span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># abrimos el archivo creado, lo leemos y mostramos l칤nea a l칤nea</span>
<span class="linenos" data-linenos="18 "></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;empleados.avro&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos" data-linenos="19 "></span>    <span class="n">reader</span> <span class="o">=</span> <span class="n">DataFileReader</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">DatumReader</span><span class="p">())</span>
<span class="linenos" data-linenos="20 "></span>    <span class="c1"># copiamos los metadatos del fichero le칤do</span>
<span class="linenos" data-linenos="21 "></span>    <span class="n">metadata</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">meta</span><span class="p">)</span>
<span class="linenos" data-linenos="22 "></span>    <span class="c1"># obtenemos el schema del fichero le칤do</span>
<span class="linenos" data-linenos="23 "></span>    <span class="n">schemaFromFile</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;avro.schema&#39;</span><span class="p">])</span>
<span class="linenos" data-linenos="24 "></span>    <span class="c1"># recuperamos los empleados</span>
<span class="linenos" data-linenos="25 "></span>    <span class="n">empleados</span> <span class="o">=</span> <span class="p">[</span><span class="n">empleado</span> <span class="k">for</span> <span class="n">empleado</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">]</span>
<span class="linenos" data-linenos="26 "></span>    <span class="n">reader</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="linenos" data-linenos="27 "></span>
<span class="linenos" data-linenos="28 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Schema de empleado.avsc:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">schema</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="29 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Schema del fichero empleados.avro:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">schemaFromFile</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="30 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Empleados:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">empleados</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="err">Schema</span><span class="w"> </span><span class="err">de</span><span class="w"> </span><span class="err">empleado.avsc</span><span class="p">:</span><span class="w"></span>
<span class="linenos" data-linenos="2 "></span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;record&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;empleado&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;namespace&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;SeveroOchoa&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;fields&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;string&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;nombre&quot;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;altura&quot;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;null&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;int&quot;</span><span class="p">],</span><span class="w"> </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;edad&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;default&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">}]}</span><span class="w"></span>
<span class="linenos" data-linenos="3 "></span><span class="err">Schema</span><span class="w"> </span><span class="err">del</span><span class="w"> </span><span class="kc">f</span><span class="err">ichero</span><span class="w"> </span><span class="err">empleados.avro</span><span class="p">:</span><span class="w"></span>
<span class="linenos" data-linenos="4 "></span><span class="p">{</span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;record&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;empleado&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">mespace&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;SeveroOchoa&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">f</span><span class="err">ields&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;s</span><span class="kc">tr</span><span class="err">i</span><span class="kc">n</span><span class="err">g&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">n</span><span class="err">ombre&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;i</span><span class="kc">nt</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;al</span><span class="kc">tura</span><span class="err">&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="kc">null</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;i</span><span class="kc">nt</span><span class="err">&#39;</span><span class="p">],</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;edad&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;de</span><span class="kc">fault</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">}]}</span><span class="w"></span>
<span class="linenos" data-linenos="5 "></span><span class="err">Empleados</span><span class="p">:</span><span class="w"></span>
<span class="linenos" data-linenos="6 "></span><span class="p">[{</span><span class="err">&#39;</span><span class="kc">n</span><span class="err">ombre&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;Carlos&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;al</span><span class="kc">tura</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="mi">180</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;edad&#39;</span><span class="p">:</span><span class="w"> </span><span class="mi">44</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="kc">n</span><span class="err">ombre&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;Jua</span><span class="kc">n</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;al</span><span class="kc">tura</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="mi">175</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;edad&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">}]</span><span class="w"></span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="fastavro">Fastavro<a class="headerlink" href="#fastavro" title="Permanent link">&para;</a></h4>
<p>Para trabajar con <em>Avro</em> y grandes vol칰menes de datos, se utiliza la librer칤a <em>Fastavro</em> (<a href="https://github.com/fastavro/fastavro">https://github.com/fastavro/fastavro</a>) la cual ofrece un rendimiento mucho mejor (en vez de estar codificada en <em>Python</em> puro, tiene algunos fragmentos realizados mediante <em>Cython</em>).</p>
<p>Primero, hemos de instalar la librer칤a:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>pip install fastavro
<span class="linenos" data-linenos="2 "></span><span class="c1"># o si utilizamos Anaconda</span>
<span class="linenos" data-linenos="3 "></span>conda install -c conda-forge fastavro
</code></pre></div>
<p>Como pod칠is observar a continuaci칩n, hemos repetido el ejemplo y el c칩digo es muy similar:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">C칩digo Python</label><label for="__tabbed_2_2">Resultado</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">fastavro</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="linenos" data-linenos=" 3 "></span><span class="kn">import</span> <span class="nn">json</span>
<span class="linenos" data-linenos=" 4 "></span><span class="kn">from</span> <span class="nn">fastavro</span> <span class="kn">import</span> <span class="n">reader</span>
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># abrimos el fichero en modo binario y leemos el esquema</span>
<span class="linenos" data-linenos=" 7 "></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;empleado.avsc&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos" data-linenos=" 8 "></span>    <span class="n">schemaJSON</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">schemaDict</span> <span class="o">=</span> <span class="n">fastavro</span><span class="o">.</span><span class="n">parse_schema</span><span class="p">(</span><span class="n">schemaJSON</span><span class="p">)</span>
<span class="linenos" data-linenos="10 "></span>
<span class="linenos" data-linenos="11 "></span><span class="n">empleados</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;nombre&quot;</span><span class="p">:</span> <span class="s2">&quot;Carlos&quot;</span><span class="p">,</span> <span class="s2">&quot;altura&quot;</span><span class="p">:</span> <span class="mi">180</span><span class="p">,</span> <span class="s2">&quot;edad&quot;</span><span class="p">:</span> <span class="mi">44</span><span class="p">},</span>
<span class="linenos" data-linenos="12 "></span>            <span class="p">{</span><span class="s2">&quot;nombre&quot;</span><span class="p">:</span> <span class="s2">&quot;Juan&quot;</span><span class="p">,</span> <span class="s2">&quot;altura&quot;</span><span class="p">:</span> <span class="mi">175</span><span class="p">}]</span>
<span class="linenos" data-linenos="13 "></span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># escribimos un fichero a partir del esquema le칤do</span>
<span class="linenos" data-linenos="15 "></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;empleadosf.avro&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos" data-linenos="16 "></span>    <span class="n">fastavro</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">schemaDict</span><span class="p">,</span> <span class="n">empleados</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># abrimos el archivo creado, lo leemos y mostramos l칤nea a l칤nea</span>
<span class="linenos" data-linenos="19 "></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;empleadosf.avro&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos" data-linenos="20 "></span>    <span class="n">reader</span> <span class="o">=</span> <span class="n">fastavro</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="linenos" data-linenos="21 "></span>    <span class="c1"># copiamos los metadatos del fichero le칤do</span>
<span class="linenos" data-linenos="22 "></span>    <span class="n">metadata</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
<span class="linenos" data-linenos="23 "></span>    <span class="c1"># obtenemos el schema del fichero le칤do</span>
<span class="linenos" data-linenos="24 "></span>    <span class="n">schemaReader</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">writer_schema</span><span class="p">)</span>
<span class="linenos" data-linenos="25 "></span>    <span class="n">schemaFromFile</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;avro.schema&#39;</span><span class="p">])</span>
<span class="linenos" data-linenos="26 "></span>    <span class="c1"># recuperamos los empleados</span>
<span class="linenos" data-linenos="27 "></span>    <span class="n">empleados</span> <span class="o">=</span> <span class="p">[</span><span class="n">empleado</span> <span class="k">for</span> <span class="n">empleado</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">]</span>
<span class="linenos" data-linenos="28 "></span>
<span class="linenos" data-linenos="29 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Schema de empleado.avsc:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">schemaDict</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="30 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Schema del fichero empleadosf.avro:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">schemaFromFile</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="31 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Empleados:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">empleados</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="err">Schema</span><span class="w"> </span><span class="err">de</span><span class="w"> </span><span class="err">empleado.avsc</span><span class="p">:</span><span class="w"></span>
<span class="linenos" data-linenos="2 "></span><span class="p">{</span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;record&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;SeveroOchoa.empleado&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">f</span><span class="err">ields&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">n</span><span class="err">ombre&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;s</span><span class="kc">tr</span><span class="err">i</span><span class="kc">n</span><span class="err">g&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;al</span><span class="kc">tura</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;i</span><span class="kc">nt</span><span class="err">&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;de</span><span class="kc">fault</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;edad&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="kc">null</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;i</span><span class="kc">nt</span><span class="err">&#39;</span><span class="p">]}],</span><span class="w"> </span><span class="err">&#39;__</span><span class="kc">fasta</span><span class="err">vro_parsed&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">True</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;__</span><span class="kc">na</span><span class="err">med_schemas&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;SeveroOchoa.empleado&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;record&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;SeveroOchoa.empleado&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">f</span><span class="err">ields&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">n</span><span class="err">ombre&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;s</span><span class="kc">tr</span><span class="err">i</span><span class="kc">n</span><span class="err">g&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;al</span><span class="kc">tura</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;i</span><span class="kc">nt</span><span class="err">&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;de</span><span class="kc">fault</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;edad&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="kc">null</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;i</span><span class="kc">nt</span><span class="err">&#39;</span><span class="p">]}]}}}</span><span class="w"></span>
<span class="linenos" data-linenos="3 "></span><span class="err">Schema</span><span class="w"> </span><span class="err">del</span><span class="w"> </span><span class="kc">f</span><span class="err">ichero</span><span class="w"> </span><span class="err">empleados</span><span class="kc">f</span><span class="err">.avro</span><span class="p">:</span><span class="w"></span>
<span class="linenos" data-linenos="4 "></span><span class="p">{</span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;record&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;SeveroOchoa.empleado&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">f</span><span class="err">ields&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">n</span><span class="err">ombre&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;s</span><span class="kc">tr</span><span class="err">i</span><span class="kc">n</span><span class="err">g&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;al</span><span class="kc">tura</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;i</span><span class="kc">nt</span><span class="err">&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;de</span><span class="kc">fault</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">na</span><span class="err">me&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;edad&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">t</span><span class="err">ype&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="kc">null</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;i</span><span class="kc">nt</span><span class="err">&#39;</span><span class="p">]}]}</span><span class="w"></span>
<span class="linenos" data-linenos="5 "></span><span class="err">Empleados</span><span class="p">:</span><span class="w"></span>
<span class="linenos" data-linenos="6 "></span><span class="p">[{</span><span class="err">&#39;</span><span class="kc">n</span><span class="err">ombre&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;Carlos&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;al</span><span class="kc">tura</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="mi">180</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;edad&#39;</span><span class="p">:</span><span class="w"> </span><span class="mi">44</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="kc">n</span><span class="err">ombre&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;Jua</span><span class="kc">n</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;al</span><span class="kc">tura</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="mi">175</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;edad&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">}]</span><span class="w"></span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="fastavro-y-pandas">Fastavro y Pandas<a class="headerlink" href="#fastavro-y-pandas" title="Permanent link">&para;</a></h4>
<p>Finalmente, vamos a realizar un 칰ltimo ejemplo con las dos librer칤as m치s utilizadas.</p>
<p>Vamos a leer un fichero CSV de <a href="../recursos/pdi/pdi_sales.csv">ventas</a> (que ya utilizamos en las sesiones de Pentaho) mediante Pandas, y tras limpiar los datos y quedarnos 칰nicamente con las ventas de Alemania, almacenaremos el resultado del procesamiento en Avro.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">Acceso Local</label><label for="__tabbed_3_2">Acceso HDFS</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">from</span> <span class="nn">fastavro</span> <span class="kn">import</span> <span class="n">writer</span><span class="p">,</span> <span class="n">parse_schema</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># Leemos el csv mediante pandas</span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;pdi_sales.csv&#39;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;;&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># Limpiamos los datos (strip a los c칩digos postales) y nos quedamos con Alemania</span>
<span class="linenos" data-linenos=" 7 "></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Zip&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Zip&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">filtro</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="o">==</span><span class="s2">&quot;Germany&quot;</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">filtro</span><span class="p">]</span>
<span class="linenos" data-linenos="10 "></span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># 1. Definimos el esquema</span>
<span class="linenos" data-linenos="12 "></span><span class="n">schema</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos" data-linenos="13 "></span>    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Sales&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos="14 "></span>    <span class="s1">&#39;namespace&#39;</span> <span class="p">:</span> <span class="s1">&#39;SeveroOchoa&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos="15 "></span>    <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;record&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos="16 "></span>    <span class="s1">&#39;fields&#39;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos" data-linenos="17 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;ProductID&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;int&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="18 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="19 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Zip&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="20 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Units&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;int&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="21 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Revenue&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;float&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="22 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Country&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">}</span>
<span class="linenos" data-linenos="23 "></span>    <span class="p">]</span>
<span class="linenos" data-linenos="24 "></span><span class="p">}</span>
<span class="linenos" data-linenos="25 "></span><span class="n">schemaParseado</span> <span class="o">=</span> <span class="n">parse_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
<span class="linenos" data-linenos="26 "></span>
<span class="linenos" data-linenos="27 "></span><span class="c1"># 2. Convertimos el dataframe a una lista de diccionarios</span>
<span class="linenos" data-linenos="28 "></span><span class="n">records</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="s1">&#39;records&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="29 "></span>
<span class="linenos" data-linenos="30 "></span><span class="c1"># 3. Persistimos en un fichero avro</span>
<span class="linenos" data-linenos="31 "></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;sales.avro&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos" data-linenos="32 "></span>    <span class="n">writer</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">schemaParseado</span><span class="p">,</span> <span class="n">records</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">from</span> <span class="nn">fastavro</span> <span class="kn">import</span> <span class="n">parse_schema</span>
<span class="linenos" data-linenos=" 3 "></span><span class="kn">from</span> <span class="nn">hdfs</span> <span class="kn">import</span> <span class="n">InsecureClient</span>
<span class="linenos" data-linenos=" 4 "></span><span class="kn">from</span> <span class="nn">hdfs.ext.avro</span> <span class="kn">import</span> <span class="n">AvroWriter</span>
<span class="linenos" data-linenos=" 5 "></span><span class="kn">from</span> <span class="nn">hdfs.ext.dataframe</span> <span class="kn">import</span> <span class="n">write_dataframe</span>
<span class="linenos" data-linenos=" 6 "></span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># 1. Nos conectamos a HDFS</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">HDFS_HOSTNAME</span> <span class="o">=</span> <span class="s1">&#39;iabd-virtualbox&#39;</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">HDFSCLI_PORT</span> <span class="o">=</span> <span class="mi">9870</span>
<span class="linenos" data-linenos="10 "></span><span class="n">HDFSCLI_CONNECTION_STRING</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;http://</span><span class="si">{</span><span class="n">HDFS_HOSTNAME</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">HDFSCLI_PORT</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="linenos" data-linenos="11 "></span><span class="n">hdfs_client</span> <span class="o">=</span> <span class="n">InsecureClient</span><span class="p">(</span><span class="n">HDFSCLI_CONNECTION_STRING</span><span class="p">)</span>
<span class="linenos" data-linenos="12 "></span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># 2. Leemos el dataframe</span>
<span class="linenos" data-linenos="14 "></span><span class="k">with</span> <span class="n">hdfs_client</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s1">&#39;/user/iabd/pdi_sales.csv&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
<span class="linenos" data-linenos="15 "></span>    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">reader</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;;&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="16 "></span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># Limpiamos los datos (strip a los c칩digos postales) y nos quedamos con Alemania</span>
<span class="linenos" data-linenos="18 "></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Zip&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Zip&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
<span class="linenos" data-linenos="19 "></span><span class="n">filtro</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="o">==</span><span class="s2">&quot;Germany&quot;</span>
<span class="linenos" data-linenos="20 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">filtro</span><span class="p">]</span>
<span class="linenos" data-linenos="21 "></span>
<span class="linenos" data-linenos="22 "></span><span class="c1"># 3. Definimos el esquema</span>
<span class="linenos" data-linenos="23 "></span><span class="n">schema</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos" data-linenos="24 "></span>    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Sales&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos="25 "></span>    <span class="s1">&#39;namespace&#39;</span> <span class="p">:</span> <span class="s1">&#39;SeveroOchoa&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos="26 "></span>    <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;record&#39;</span><span class="p">,</span>
<span class="linenos" data-linenos="27 "></span>    <span class="s1">&#39;fields&#39;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos" data-linenos="28 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;ProductID&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;int&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="29 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="30 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Zip&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="31 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Units&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;int&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="32 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Revenue&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;float&#39;</span><span class="p">},</span>
<span class="linenos" data-linenos="33 "></span>        <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Country&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">}</span>
<span class="linenos" data-linenos="34 "></span>    <span class="p">]</span>
<span class="linenos" data-linenos="35 "></span><span class="p">}</span>
<span class="linenos" data-linenos="36 "></span><span class="n">schemaParseado</span> <span class="o">=</span> <span class="n">parse_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
<span class="linenos" data-linenos="37 "></span>
<span class="linenos" data-linenos="38 "></span><span class="c1"># 4a. Persistimos en un fichero avro dentro de HDFS mediante la extension AvroWriter de hdfs</span>
<span class="linenos" data-linenos="39 "></span><span class="k">with</span> <span class="n">AvroWriter</span><span class="p">(</span><span class="n">hdfs_client</span><span class="p">,</span> <span class="s1">&#39;/user/iabd/sales.avro&#39;</span><span class="p">,</span> <span class="n">schemaParseado</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
<span class="linenos" data-linenos="40 "></span>    <span class="n">records</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="s1">&#39;records&#39;</span><span class="p">)</span> <span class="c1"># diccionario</span>
<span class="linenos" data-linenos="41 "></span>    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
<span class="linenos" data-linenos="42 "></span>        <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">record</span><span class="p">)</span>
<span class="linenos" data-linenos="43 "></span>
<span class="linenos" data-linenos="44 "></span><span class="c1"># 4b. O directamente persistimos el dataframe mediante la extension write_dataframe de hdfs</span>
<span class="linenos" data-linenos="45 "></span><span class="n">write_dataframe</span><span class="p">(</span><span class="n">hdfs_client</span><span class="p">,</span> <span class="s1">&#39;/user/iabd/sales2.avro&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>  <span class="c1"># infiere el esquema</span>
<span class="linenos" data-linenos="46 "></span><span class="n">write_dataframe</span><span class="p">(</span><span class="n">hdfs_client</span><span class="p">,</span> <span class="s1">&#39;/user/iabd/sales3.avro&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">schemaParseado</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
<p>Para el acceso HDFS hemos utilizados las extensiones <a href="https://hdfscli.readthedocs.io/en/latest/api.html#module-hdfs.ext.avro">Fastavro</a> y <a href="https://hdfscli.readthedocs.io/en/latest/api.html#module-hdfs.ext.dataframe">Pandas</a> de la librer칤a HDFS del apartado anterior.</p>
<h4 id="comprimiendo-los-datos">Comprimiendo los datos<a class="headerlink" href="#comprimiendo-los-datos" title="Permanent link">&para;</a></h4>
<p>쯏 s칤 comprimimos los datos para ocupen menos espacio en nuestro cl칰ster y por tanto, nos cuesten menos dinero?</p>
<p><em>Fastavro</em> soporta dos tipos de compresi칩n: <em>gzip</em> (mediante el algoritmo <code>deflate</code>) y <code>snappy</code>. <strong>Snappy</strong> es una biblioteca de compresi칩n y descompresi칩n de datos de gran rendimiento que se utiliza con frecuencia en proyectos Big Data, la cual hemos de instalar previamente mediante <code>pip install python-snappy</code>.</p>
<p>Para indicar el tipo de compresi칩n, 칰nicamente hemos de a침adir un par치metros extra con el algoritmo de compresi칩n en la funci칩n/constructor de persistencia:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:3"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><input id="__tabbed_4_3" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">Fastavro y gzip</label><label for="__tabbed_4_2">AvroWriter y snappy</label><label for="__tabbed_4_3">write_dataframe y snappy</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">writer</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">schemaParseado</span><span class="p">,</span> <span class="n">records</span><span class="p">,</span> <span class="s1">&#39;deflate&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">with</span> <span class="n">AvroWriter</span><span class="p">(</span><span class="n">hdfs_client</span><span class="p">,</span> <span class="s1">&#39;/user/iabd/sales.avro&#39;</span><span class="p">,</span> <span class="n">schemaParseado</span><span class="p">,</span> <span class="s1">&#39;snappy&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">write_dataframe</span><span class="p">(</span><span class="n">hdfs_client</span><span class="p">,</span> <span class="s1">&#39;/user/iabd/sales3.avro&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">schemaParseado</span><span class="p">,</span> <span class="n">codec</span><span class="o">=</span><span class="s1">&#39;snappy&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
<div class="admonition info">
<p class="admonition-title">Comparando algoritmos de compresi칩n</p>
<p>Respecto a la compresi칩n, sobre un fichero de 100GB, podemos considerar media si ronda los 50GB y alta si baja a los 40GB.</p>
<table>
<thead>
<tr>
<th>Algoritmo</th>
<th>Velocidad</th>
<th>Compresi칩n</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gzip</td>
<td>Media</td>
<td>Media</td>
</tr>
<tr>
<td>Bzip2</td>
<td>Lenta</td>
<td>Alta</td>
</tr>
<tr>
<td>Snappy</td>
<td>Alta</td>
<td>Media</td>
</tr>
</tbody>
</table>
<p>M치s que un tema de espacio, necesitamos que los procesos sean eficientes y por eso priman los algoritmos que son m치s r치pidos. Si te interesa el tema, es muy interesante el art칤culo <a href="http://comphadoop.weebly.com">Data Compression in Hadoop</a>.</p>
<p>Por ejemplo, si realizamos el ejemplo de <a href="#fastavro-y-pandas">Fast Avro y Pandas</a> con acceso local obtenemos los siguientes tama침os:</p>
<ul>
<li>Sin compresi칩n: 6,9 MiB</li>
<li>Gzip: 1,9 MiB</li>
<li>Snappy: 2,8 MiB</li>
</ul>
</div>
<h3 id="parquet">Parquet<a class="headerlink" href="#parquet" title="Permanent link">&para;</a></h3>
<figure style="float: right;">
    <img src="../imagenes/hadoop/02parquet-logo.png" width="150">
    <figcaption>Logo de Apache Parquet</figcaption>
</figure>

<p><a href="https://parquet.apache.org/">Apache Parquet</a> es un formato de almacenamiento basado en columnas para <em>Hadoop</em>, con soporte para todos los frameworks de procesamiento de datos, as칤 como lenguajes de programaci칩n. De la misma forma que <em>Avro</em>, se trata de un formato de datos auto-descriptivo, de manera que embebe el esquema o estructura de los datos con los propios datos en s칤. Parquet es id칩neo para analizar datasets que contienen muchas columnas.</p>
<figure style="float: right;">
    <img src="../imagenes/hadoop/02parquet-format.gif" width="450">
    <figcaption>Formato de un archivo Parquet</figcaption>
</figure>

<p>Cada fichero Parquet almacena los datos en binario organizados en grupos de filas. Para cada grupo de filas (<em>row group</em>), los valores de los datos se organizan en columnas, lo que facilita la compresi칩n a nivel de columna.</p>
<p>La columna de metadatos de un fichero Parquet se almacena al final del fichero, lo que permite que las escrituras sean r치pidas con una 칰nica pasada. Los metadatos pueden incluir informaci칩n como los tipos de datos, esquemas de codificaci칩n/compresi칩n, estad칤sticas, nombre de los elementos, etc...</p>
<!--
https://www.upsolver.com/blog/apache-parquet-why-use
https://towardsdatascience.com/understanding-apache-parquet-7197ba6462a9
-->

<h4 id="parquet-y-python">Parquet y Python<a class="headerlink" href="#parquet-y-python" title="Permanent link">&para;</a></h4>
<p>Para interactuar con el formato Parquet mediante Python, la librer칤a m치s utilizada es la que ofrece <a href="https://arrow.apache.org/">Apache Arrow</a>, en concreto la librer칤a <a href="https://arrow.apache.org/docs/python/"><em>PyArrow</em></a>.</p>
<p>As칤 pues, la instalamos mediante pip:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>pip install pyarrow
</code></pre></div>
<p><em>Apache Arrow</em> usa un tipo de estructura denominada tabla para almacenar los datos bidimentsional (ser칤a muy similar a un <em>dataframe</em> de <em>Pandas</em>). La documentaci칩n de <em>PyArrow</em> dispone de un <a href="https://arrow.apache.org/cookbook/py/">libro de recetas</a> con ejemplos con c칩digo para los diferentes casos de uso que se nos puedan plantear.</p>
<p>Vamos a simular el mismo ejemplo que hemos realizado previamente mediante <em>Avro</em>, y vamos a crear un fichero en formato <em>JSON</em> con empleados, y tras persistirlo en formato <em>Parquet</em>, lo vamos a recuperar:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:2"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">Empleados en columnas</label><label for="__tabbed_5_2">Empleados en Filas</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><span class="filename">dict-parquet.py</span><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">pq</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># 1.- Definimos el esquema</span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">schema</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">schema</span><span class="p">([</span> <span class="p">(</span><span class="s1">&#39;nombre&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">string</span><span class="p">()),</span>
<span class="linenos" data-linenos=" 6 "></span>                    <span class="p">(</span><span class="s1">&#39;altura&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">int32</span><span class="p">()),</span>
<span class="linenos" data-linenos=" 7 "></span>                    <span class="p">(</span><span class="s1">&#39;edad&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">int32</span><span class="p">())</span>  <span class="p">])</span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># 2.- Almacenamos los empleados por columnas</span>
<span class="linenos" data-linenos="10 "></span><span class="n">empleados</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;nombre&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Carlos&quot;</span><span class="p">,</span> <span class="s2">&quot;Juan&quot;</span><span class="p">],</span>
<span class="linenos" data-linenos="11 "></span>            <span class="s2">&quot;altura&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">180</span><span class="p">,</span> <span class="mi">44</span><span class="p">],</span>
<span class="linenos" data-linenos="12 "></span>            <span class="s2">&quot;edad&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">34</span><span class="p">]}</span>
<span class="linenos" data-linenos="13 "></span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># 3.- Creamos una tabla Arrow y la persistimos mediante Parquet</span>
<span class="linenos" data-linenos="15 "></span><span class="n">tabla</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_pydict</span><span class="p">(</span><span class="n">empleados</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
<span class="linenos" data-linenos="16 "></span><span class="n">pq</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">tabla</span><span class="p">,</span> <span class="s1">&#39;empleados.parquet&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># 4.- Leemos el fichero generado</span>
<span class="linenos" data-linenos="19 "></span><span class="n">table2</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;empleados.parquet&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="20 "></span><span class="n">schemaFromFile</span> <span class="o">=</span> <span class="n">table2</span><span class="o">.</span><span class="n">schema</span>
<span class="linenos" data-linenos="21 "></span>
<span class="linenos" data-linenos="22 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Schema del fichero empleados.parquet:</span><span class="se">\n</span><span class="si">{</span><span class="n">schemaFromFile</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="23 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Tabla de Empleados:</span><span class="se">\n</span><span class="si">{</span><span class="n">table2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p>Para que <em>pyarrow</em> pueda leer los empleados como documentos JSON, a d칤a de hoy s칩lo puede hacerlo leyendo documentos individuales almacenados en fichero:</p>
<p>Por lo tanto, creamos el fichero <code>empleados.json</code> con la siguiente informaci칩n:</p>
<div class="highlight"><span class="filename">empleados.json</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;nombre&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Carlos&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;altura&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">180</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;edad&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">44</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="linenos" data-linenos="2 "></span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;nombre&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Juan&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;altura&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">175</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
</code></pre></div>
<p>De manera que podemos leer los datos JSON y persistirlos en Parquet del siguiente modo:</p>
<div class="highlight"><span class="filename">json-parquet.py</span><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">pq</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
<span class="linenos" data-linenos=" 3 "></span><span class="kn">from</span> <span class="nn">pyarrow</span> <span class="kn">import</span> <span class="n">json</span>
<span class="linenos" data-linenos=" 4 "></span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># 1.- Definimos el esquema</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">schema</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">schema</span><span class="p">([</span> <span class="p">(</span><span class="s1">&#39;nombre&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">string</span><span class="p">()),</span>
<span class="linenos" data-linenos=" 7 "></span>                    <span class="p">(</span><span class="s1">&#39;altura&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">int32</span><span class="p">()),</span>
<span class="linenos" data-linenos=" 8 "></span>                    <span class="p">(</span><span class="s1">&#39;edad&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">int32</span><span class="p">())</span>  <span class="p">])</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># 2.- Leemos los empleados</span>
<span class="linenos" data-linenos="11 "></span><span class="n">tabla</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="s2">&quot;empleados.json&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># 3.- Persistimos la tabla en Parquet</span>
<span class="linenos" data-linenos="13 "></span><span class="n">pq</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">tabla</span><span class="p">,</span> <span class="s1">&#39;empleados-json.parquet&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># 4.- Leemos el fichero generado</span>
<span class="linenos" data-linenos="16 "></span><span class="n">table2</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;empleados-json.parquet&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span><span class="n">schemaFromFile</span> <span class="o">=</span> <span class="n">table2</span><span class="o">.</span><span class="n">schema</span>
<span class="linenos" data-linenos="18 "></span>
<span class="linenos" data-linenos="19 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Schema del fichero empleados-json.parquet:</span><span class="se">\n</span><span class="si">{</span><span class="n">schemaFromFile</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos="20 "></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Tabla de Empleados:</span><span class="se">\n</span><span class="si">{</span><span class="n">table2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
<p>En ambos casos obtendr칤amos algo similar a:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>Schema del fichero empleados.parquet:
<span class="linenos" data-linenos=" 2 "></span>nombre: string
<span class="linenos" data-linenos=" 3 "></span>altura: int32
<span class="linenos" data-linenos=" 4 "></span>edad: int32
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span>Tabla de Empleados:
<span class="linenos" data-linenos=" 7 "></span>pyarrow.Table
<span class="linenos" data-linenos=" 8 "></span>nombre: string
<span class="linenos" data-linenos=" 9 "></span>altura: int32
<span class="linenos" data-linenos="10 "></span>edad: int32
<span class="linenos" data-linenos="11 "></span>----
<span class="linenos" data-linenos="12 "></span>nombre: [[&quot;Carlos&quot;,&quot;Juan&quot;]]
<span class="linenos" data-linenos="13 "></span>altura: [[180,44]]
<span class="linenos" data-linenos="14 "></span>edad: [[null,34]]
</code></pre></div>
<h4 id="parquet-y-pandas">Parquet y Pandas<a class="headerlink" href="#parquet-y-pandas" title="Permanent link">&para;</a></h4>
<p>En el caso del uso de <em>Pandas</em> el c칩digo todav칤a se simplifica m치s. Si reproducimos el mismo ejemplo que hemos realizado con Avro tenemos que los <em>Dataframes</em> ofrecen el m칠todo <code>to_parquet</code> para exportar a un fichero <em>Parquet</em>:</p>
<div class="highlight"><span class="filename">csv-parquet.py</span><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="linenos" data-linenos=" 2 "></span>
<span class="linenos" data-linenos=" 3 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;pdi_sales.csv&#39;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;;&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 4 "></span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Zip&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Zip&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">filtro</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="o">==</span><span class="s2">&quot;Germany&quot;</span>
<span class="linenos" data-linenos=" 7 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">filtro</span><span class="p">]</span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># A partir de un DataFrame, persistimos los datos</span>
<span class="linenos" data-linenos="10 "></span><span class="n">df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s1">&#39;sales.parquet&#39;</span><span class="p">)</span>
</code></pre></div>
<p>Si quisi칠ramos almacenar el archivo directamente en HDFS, necesitamos indicarle a Pandas la direcci칩n del sistema de archivos que tenemos configurado en <code>core-site.xml</code>:</p>
<div class="highlight"><span class="filename">core-site.ml</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos="2 "></span>    <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos="3 "></span>    <span class="nt">&lt;value&gt;</span>hdfs://iabd-virtualbox:9000<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos="4 "></span><span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>As칤 pues, 칰nicamente necesitamos modificar el nombre del archivo donde serializamos los datos a <em>Parquet</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s1">&#39;hdfs://iabd-virtualbox:9000/sales.parquet&#39;</span><span class="p">)</span>
</code></pre></div>
<h3 id="comparando-tamanos">Comparando tama침os<a class="headerlink" href="#comparando-tamanos" title="Permanent link">&para;</a></h3>
<p>Si comparamos los tama침os de los archivos respecto al formato de datos empleado con 칰nicamente las ventas de Alemania tendr칤amos:</p>
<ul>
<li><code>ger_sales.csv</code>: 9,7 MiB</li>
<li><code>ger_sales.avro</code>: 6,9 MiB<ul>
<li><code>ger_sales-gzip.avro</code>: 1,9 MiB</li>
<li><code>ger_sales-snappy.avro</code>:  2,8 MiB</li>
</ul>
</li>
<li><code>ger_sales.parquet</code>: 2,3 MiB<ul>
<li><code>ger_sales-gzip.parquet</code>: 1,6 MiB</li>
<li><code>ger_sales-snappy.parquet</code>: 2,3 MiB</li>
</ul>
</li>
</ul>
<h2 id="hue">Hue<a class="headerlink" href="#hue" title="Permanent link">&para;</a></h2>
<p><a href="https://gethue.com">Hue</a> (<em>Hadoop User Experience</em>) es una interfaz gr치fica de c칩digo abierto basada en web para su uso con <em>Apache Hadoop</em>. <em>Hue</em> act칰a como front-end para las aplicaciones que se ejecutan en el cl칰ster, lo que permite interactuar con las aplicaciones mediante una interfaz m치s amigable que el interfaz de comandos.</p>
<p>En nuestra m치quina virtual ya lo tenemos instalado y configurado para que funcione con HDFS y Hive.</p>
<p>La ruta de instalaci칩n es <code>/opt/hue-4.10.0</code> y desde all칤, arrancaremos Hue:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>./build/env/bin/hue runserver
</code></pre></div>
<p>Tras arrancarlo, nos dirigimos a <code>http://127.0.0.1:8000/</code>y visualizaremos el formulario de entrada, el cual entraremos con el usuario <code>iabd</code> y la contrase침a <code>iabd</code>:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02hue-login.png">
    <figcaption>Login en Hue</figcaption>
</figure>

<p>Una vez dentro, por ejemplo, podemos visualizar e interactuar con HDFS:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/02hue-hdfs.png">
    <figcaption>HDFS en Hue</figcaption>
</figure>

<h2 id="referencias">Referencias<a class="headerlink" href="#referencias" title="Permanent link">&para;</a></h2>
<ul>
<li>Documentaci칩n de <a href="https://hadoop.apache.org/docs/stable/">Apache Hadoop</a>.</li>
<li><a href="https://www.oreilly.com/library/view/hadoop-the-definitive/9780596521974/">Hadoop: The definitive Guide, 4th Ed - de Tom White - O'Reilly</a></li>
<li><a href="https://www.informit.com/articles/article.aspx?p=2755708">HDFS Commands, HDFS Permissions and HDFS Storage</a></li>
<li><a href="https://www.xenonstack.com/blog/data-serialization-hadoop">Introduction to Data Serialization in Apache Hadoop</a></li>
<li><a href="https://www.perfectlyrandom.org/2019/11/29/handling-avro-files-in-python/">Handling Avro files in Python</a></li>
<li><a href="https://wesmckinney.com/blog/python-hdfs-interfaces/">Native Hadoop file system (HDFS) connectivity in Python</a></li>
</ul>
<h2 id="actividades">Actividades<a class="headerlink" href="#actividades" title="Permanent link">&para;</a></h2>
<p>Para los siguientes ejercicios, copia el comando y/o haz una captura de pantalla donde se muestre el resultado de cada acci칩n.</p>
<ol>
<li>
<p>Explica paso a paso  el proceso de lectura (indicando qu칠 bloques y los datanodes empleados) que realiza HDFS si queremos leer el archivo <code>/logs/101213.log</code>:</p>
<p><figure style="align: center;">
    <img src="../imagenes/hadoop/02hdfs-lectura-ejercicio.png">
    <figcaption>Proceso de lectura HDFS</figcaption>
</figure></p>
</li>
<li>
<p>En este ejercicio vamos a practicar los comandos b치sicos de HDFS. Una vez arrancado <em>Hadoop</em>:</p>
<ol>
<li>Crea la carpeta <code>/user/iabd/ejercicios</code>.</li>
<li>Sube el archivo <code>el_quijote.txt</code> a la carpeta creada.</li>
<li>Crea una copia en HDFS y ll치mala <code>el_quijote2.txt</code>.</li>
<li>Recupera el principio del fichero <code>el_quijote2.txt</code>.</li>
<li>Renombra <code>el_quijote2.txt</code> a <code>el_quijote_copia.txt</code>.</li>
<li>Adjunta una captura desde el interfaz web donde se vean ambos archivos.</li>
<li>Vuelve al terminal y elimina la carpeta con los archivos contenidos mediante un 칰nico comando.</li>
</ol>
</li>
<li>
<p>(opcional) Vamos a practicar los comandos de gesti칩n de instant치neas y administraci칩n de HDFS. Para ello:</p>
<ol>
<li>Crea la carpeta <code>/user/iabd/instantaneas</code>.</li>
<li>Habilita las <em>snapshots</em> sobre la carpeta creada.</li>
<li>Sube el archivo <code>el_quijote.txt</code> a la carpeta creada.</li>
<li>Crea una copia en HDFS y ll치mala <code>el_quijote_snapshot.txt</code>.</li>
<li>Crea una instant치nea de la carpeta llamada <code>ss1</code>.</li>
<li>Elimina ambos ficheros del quijote.</li>
<li>Comprueba que la carpeta est치 vac칤a.</li>
<li>Recupera desde <code>ss</code> el archivo <code>el_quijote.txt</code>.</li>
<li>Crea una nueva instant치nea de la carpeta llamada <code>ss2</code>.</li>
<li>Muestra el contenido de la carpeta <code>/user/iabd/instantaneas</code> as칤 como de sus <em>snapshots</em>.</li>
</ol>
</li>
<li>
<p>(opcional) HDFS por dentro</p>
<ol>
<li>Accede al archivo de configuraci칩n <code>hdfs-site.xml</code> y averigua la carpeta donde se almacena el <em>namenode</em>.</li>
<li>Muestra los archivos que contiene la carpeta <code>current</code> dentro del <em>namenode</em></li>
<li>Comprueba el id del archivo <code>VERSION</code>.</li>
<li>En los siguientes pasos vamos a realizar un checkpoint manual para sincronizar el sistema de ficheros. Para ello entramos en modo <em>safe</em> con el comando <code>hdfs dfsadmin -safemode enter</code>, de manera que impedamos que se trabaje con el sistema de ficheros mientras lanzamos el <em>checkpoint</em>.</li>
<li>Comprueba mediante el interfaz gr치fico que el modo seguro est치 activo (<em>Safe mode is ON</em>).</li>
<li>Ahora realiza el checkpoint con el comando <code>hdfs dfsadmin -saveNamespace</code></li>
<li>Vuelve a entrar al modo normal (saliendo del modo seguro mediante <code>hdfs dfsadmin -safemode leave</code>)</li>
<li>Accede a la carpeta del <em>namenode</em> y comprueba que los <em>fsimage</em> del <em>namenode</em> son iguales.</li>
</ol>
</li>
<li>
<p>Mediante <em>Python</em>, carga los datos de los <a href="https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv">taxis</a> que hemos almacenado en HDFS en el apartado de <a href="#bloques">Bloques</a> y crea dentro de <code>/user/iabd/datos</code> los siguientes archivos con el formato adecuado:</p>
<ul>
<li><code>taxis.avro</code>: la fecha (<em>tpep_pickup_datetime</em>), el <em>VendorID</em> y el coste de cada viaje (<em>total_amount</em>)</li>
<li>(opcional) <code>taxis.parquet</code> con los mismos atributos.</li>
</ul>
</li>
</ol>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Volver al principio
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Pie">
      
        
        <a href="bdaplicado01hadoop.html" class="md-footer__link md-footer__link--prev" aria-label="Anterior: 1.- Hadoop" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Anterior
              </span>
              1.- Hadoop
            </div>
          </div>
        </a>
      
      
        
        <a href="bdaplicado03flume.html" class="md-footer__link md-footer__link--next" aria-label="Siguiente: 3.- Sqoop / Flume" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Siguiente
              </span>
              3.- Sqoop / Flume
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      2021-2022 Aitor Medrano - Licencia CC BY-NC-SA
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/aitormedrano" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    <a href="mailto:<a.medrano@edu.gva.es>" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M464 64c26.5 0 48 21.49 48 48 0 15.1-7.1 29.3-19.2 38.4L275.2 313.6a32.1 32.1 0 0 1-38.4 0L19.2 150.4C7.113 141.3 0 127.1 0 112c0-26.51 21.49-48 48-48h416zM217.6 339.2a63.9 63.9 0 0 0 76.8 0L512 176v208c0 35.3-28.7 64-64 64H64c-35.35 0-64-28.7-64-64V176l217.6 163.2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide", "navigation.top", "navigation.expand", "navigation.tracking", "content.code.annotate"], "search": "../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.config.lang": "es", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "B\u00fasqueda", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version.title": "Seleccionar versi\u00f3n"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c2e1ee47.min.js"></script>
      
    
  </body>
</html>