
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://aitor-medrano.github.io/bigdata2122/apuntes/bdaplicado01hadoop.html">
      
      <link rel="icon" href="../imagenes/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.0.2">
    
    
      
        <title>Hadoop - Inteligencia Artificial y Big Data</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.816931ca.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.9204c3b2.min.css">
        
          
          
          <meta name="theme-color" content="#02a6f2">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>function __md_scope(e,t,_){return new URL(_||(t===localStorage?"..":".."),location).pathname+"."+e}function __md_get(e,t=localStorage,_){return JSON.parse(t.getItem(__md_scope(e,t,_)))}function __md_set(e,t,_=localStorage,o){try{_.setItem(__md_scope(e,_,o),JSON.stringify(t))}catch(e){}}</script>
    
      

  


  

  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-MV889H0W63"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-MV889H0W63",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MV889H0W63"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="light-blue" data-md-color-accent="teal">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#hadoop" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-header__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Inteligencia Artificial y Big Data
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Hadoop
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Búsqueda" placeholder="Búsqueda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando búsqueda
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-nav__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    Inteligencia Artificial y Big Data
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Inicio
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Arquitecturas Big Data
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Arquitecturas Big Data" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Arquitecturas Big Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube01.html" class="md-nav__link">
        1.- Cloud Computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube02aws.html" class="md-nav__link">
        2.- AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube03computacion.html" class="md-nav__link">
        3.- Computación
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube04almacenamiento.html" class="md-nav__link">
        4.- Almacenamiento
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube05datos.html" class="md-nav__link">
        5.- Datos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="arquitecturas01.html" class="md-nav__link">
        6.- Arquitecturas
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Ingesta de Datos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Ingesta de Datos" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Ingesta de Datos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta01.html" class="md-nav__link">
        1.- ETL
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#componentes" class="md-nav__link">
    Componentes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mapreduce" class="md-nav__link">
    MapReduce
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hdfs" class="md-nav__link">
    HDFS
  </a>
  
    <nav class="md-nav" aria-label="HDFS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bloques" class="md-nav__link">
    Bloques
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#namenodes" class="md-nav__link">
    Namenodes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datanode" class="md-nav__link">
    Datanode
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#procesos-de-lectura-y-escritura" class="md-nav__link">
    Procesos de lectura y escritura
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trabajando-con-hdfs" class="md-nav__link">
    Trabajando con HDFS
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#yarn" class="md-nav__link">
    YARN
  </a>
  
    <nav class="md-nav" aria-label="YARN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resource-manager" class="md-nav__link">
    Resource Manager
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#node-manager" class="md-nav__link">
    Node Manager
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#application-master" class="md-nav__link">
    Application Master
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#instalacion" class="md-nav__link">
    Instalación
  </a>
  
    <nav class="md-nav" aria-label="Instalación">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configuracion" class="md-nav__link">
    Configuración
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#puesta-en-marcha" class="md-nav__link">
    Puesta en marcha
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ambari" class="md-nav__link">
    Ambari
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    Referencias
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#actividades" class="md-nav__link">
    Actividades
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

<h1 id="hadoop">Hadoop<a class="headerlink" href="#hadoop" title="Permanent link">&para;</a></h1>
<p>Si <em>Big Data</em> es la filosofía de trabajo para grandes volumenes de datos, <em>Apache Hadoop</em> <a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a>) es la tecnología catalizadora. <em>Hadoop</em> puede escalar hasta miles de ordenadores creando un clúster con un almacenamiento del orden de <em>petabytes</em> de información.</p>
<p>Más que un producto, es un proyecto <em>open source</em> que aglutina una serie de herramientas para el procesamiento distribudos de grandes conjuntos de datos a través de clústers de ordenadores utilizando modelos de programación sencillo.</p>
<p>Sus características son:</p>
<ul>
<li>Confiable: crea múltiples copias de los datos de manera automática y, en caso de fallo, vuelve a desplegar la lógica de procesamiento.</li>
<li>Tolerante a fallos: tras detectar un fallo aplica una recuperación automática. En <em>Hadoop</em> los fallos de hardware se tratan como una regla, no como una excepción.</li>
<li>Escalable: los datos y su procesamiento se distribuyen sobre un clúster de ordenadores (escalado horizontal), desde un único servidor a miles de máquinas, cada uno ofreciendo computación y almacenamiento local.</li>
<li>Portable: se puede instalar en todo tipos de <em>hardware</em> y sistemas operativos.</li>
</ul>
<p>Esto lo logra mediante un entorno distribuido de datos y procesos. El procesamiento se realiza en paralelo a través de nodos de datos en un sistema de ficheros distribuidos, donde se distingue entre:</p>
<p>FIXME: hardware hadoop</p>
<ul>
<li>Nodos maestros: normalmente se necesitan 3. Su hardware tiene mayores requisitos.</li>
<li>Nodos esclavos: entre 4 y 10.000. Su hardware es relativamente barato (<em>commodity hardware</em>) mediante servidores X86.</li>
</ul>
<p>En la actualidad se ha impuesto Hadoop v3 (la última versión a día de hoy es la 3.3.1), aunque todavía existe mucho código para Hadoop v2.</p>
<h2 id="componentes">Componentes<a class="headerlink" href="#componentes" title="Permanent link">&para;</a></h2>
<p>El núcleo se compone de:</p>
<ul>
<li>un conjunto de utilidades comunes (<em>Hadoop Common</em>)</li>
<li>un sistema de ficheros distribuidos (<em>Hadoop Distributed File System</em> &lt;--&gt; <em>HDFS</em>).</li>
<li>un gestor de recursos para el manejo del clúster y la planificación de procesos (<em>YARN</em>)</li>
<li>un sistema para procesamiento paralelo de grandes conjuntos de datos (<em>MapReduce</em>)</li>
</ul>
<p>Estos elementos permiten trabajar de casi la misma forma que si tuviéramos un sistema de fichero locales en nuestro ordenador personal, pero realmente los datos están repartidos entre miles de servidores.</p>
<p>Sobre este conjunto de herramientas existe un ecosistema "infinito" con tecnologías que facilitan el acceso, gestión y extensión del propio Hadoop.</p>
<p><img alt="Ecosistema Hadoop" src="../imagenes/31hadoop-ecosystem01.jpg" /></p>
<p>Las más utilizadas son:</p>
<ul>
<li><a href="http://hive.apache.org/index.html">Hive</a>: Permite accede a HDFS como si fuera una Base de datos, ejecutando comandos muy parecido a SQL para recuperar valores (HiveSQL). Simplifica enormemente el desarrollo y la gestión con <em>Hadoop</em>.</li>
<li><a href="http://hbase.apache.org/">HBase</a>: Es el sistema de almacenamiento NoSQL basado con columnas para Hadoop.<ul>
<li>Es de código abierto, distribuida y escalable para el almacenamiento de Big Data.</li>
<li>Escrita en Java e implementa y proporciona capacidades similares sobre Hadoop y HDFS.</li>
<li>El objetivo de este proyecto es el de trabajar con grandes tablas, miles de millones de filas de X millones de columnas, sobre un clúster Hadoop.</li>
</ul>
</li>
<li><a href="https://pig.apache.org/">Pig</a>: Lenguaje de alto de nivel para analizar grandes volúmenes de datos.  Trabaja en paralelo lo que permite gestionar gran cantidad de información. Realmente es un compilador que genera comandos MapReduce, mediante el lenguaje textual denominado <em>Pig Latin</em>.</li>
<li><a href="http://sqoop.apache.org/">Sqoop</a>: Permite transferir gran volumen de datos de manera eficiente entre Hadoop y gestores de datos estructurados.</li>
<li><a href="https://flume.apache.org/">Flume</a>: Servicio distribuido y altamente eficiente para distribuir, agregar y recolectar grandes cantidades de información. Es útil para cargar y mover en Hadoop información textual, como ficheros de logs, bloques de twitter/reddit, etc. Utiliza una arquitectura de tipo streaming con un flujo de datos muy potente y personalizables</li>
<li><a href="https://zookeeper.apache.org/">ZooKeeper</a>: Servicio para mantener la configuración, coordinación y aprovisionamiento de aplicaciones distribuidas. No sólo vale para Hadoop, pero es muy útil en esa arquitectura, eliminando la complejidad de la gestión distribuido de la plataforma.</li>
<li><a href="http://spark.apache.org/">Spark</a>: Es un motor muy eficiente de procesamiento de datos a gran escala. Implementa procesamiento en tiempo real al contrario que MapReduce, lo que provoca que sea más rápido. Para ello, en vez de almacenar los datos en disco, trabaja de forma masiva en memoria. Puede trabajar de forma autónoma, sin necesidad de Hadoop.</li>
<li><a href="https://ambari.apache.org/">Ambari</a> es una herramienta para instalar, configurar, mantener y monitorizar Hadoop.</li>
</ul>
<p>Si queremos empezar a utilizar Hadoop y todo su ecosistema, disponemos de diversas distribuciones con toda la arquitectura, herramientas y configuración ya preparadas. Las más reseñables son:</p>
<ul>
<li><a href="https://aws.amazon.com/es/emr">Amazon Elastic MapReduce (EMR)</a> de AWS.</li>
<li><a href="https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html">CDH</a> de Cloudera</li>
<li><a href="https://azure.microsoft.com/es-es/services/hdinsight/">Azure HDInsight</a> de Microsoft</li>
</ul>
<h2 id="mapreduce">MapReduce<a class="headerlink" href="#mapreduce" title="Permanent link">&para;</a></h2>
<p>Es el algoritmo que utiliza <em>Hadoop</em> para paralelizar las tareas. Un algoritmo MapReduce divide los datos, los procesa en paralelo, los reordena, combina y agrega de vuelta los resultados.</p>
<p>Sin embargo, este algoritmo no casa bien con el análisis interactivo o programas iterativos, ya que persiste los datos en disco entre cada uno de los pasos del mismo, lo que con grandes <em>datasets</em> conlleva una penalización en el rendimiento.</p>
<p>El siguiente gráfico muestra un ejemplo de una empresa de juguete que fabrica juguetes de colores. Cuando un cliente compra un juguete desde la página web, el pedido se almacena como un fichero en <em>Hadoop</em> con los colores de los juguetes adquiridos. Para averiguar cuantas unidades de cada color ha de preparar la fábrica, se emplea un algoritmo MapReduce para contar los colores:</p>
<p><img alt="Ejemplo simplificado MapReduce" src="../imagenes/31map-reduce01.png" /></p>
<p>Como sugiere el nombre, el proceso se divide principalmente en dos fases:</p>
<ul>
<li>Fase de mapeo (<em>Map</em>) — Los documentos se parten en pares de clave/valor. Hasta que no se reduzca, podemos tener muchos duplicados.</li>
<li>Fase de reducción (<em>Reduce</em>) — Es en cierta medida similar a un <em>"group by"</em> de SQL. Las ocurrencias similares se agrupan, y dependiendo de la función de reducción, se puede crear un resultado diferente. En nuestro ejemplo queremos contar los colores, y eso es lo que devuelve nuestra función.</li>
</ul>
<p>Realmente, es un proceso más complicado:</p>
<p><img alt="Ejemplo fase a fase de conteo de colores" src="../imagenes/31map-reduce02.png" /></p>
<ol>
<li>Lectura de los ficheros de entrada.</li>
<li>Pasar cada linea de forma separada al mapeador.</li>
<li>El mapeador parsea los colores (claves) de cada fichero y produce un nuevo fichero para cada color con el número de ocurrencias encontradas (valor), es decir, mapea una clave (color) con un valor (número de ocurrencias).</li>
<li>Para facilitar la agregación, se ordenan las claves.</li>
<li>La fase de reducción suma las ocurrencias de cada color y genera un fichero por clave con el total de cada color.</li>
<li>Las claves se unen en un único fichero de salida.</li>
</ol>
<div class="admonition note">
<p class="admonition-title">No es oro todo lo que reluce</p>
<p>Hadoop facilita el trabajo con grandes volúmenes de datos, pero montar un clúster funcional no es una cosa trivial. Existen gestores de clústers que hacen las cosas un poco menos incómodas (como son <em>Ambari</em> o <em>Apache Mesos</em>), aunque la tendencia es utilizar una solución cloud que nos evita toda la instalación y configuración.</p>
</div>
<p>Tal como comentamos al inicio, uno de los puntos débiles de Hadoop es el trabajo con algoritmos iterativos, los cuales son fundamentales en la parte de IA. La solución es el uso del framework Spark, que mejora el rendimiento por una orden de magnitud.</p>
<h2 id="hdfs">HDFS<a class="headerlink" href="#hdfs" title="Permanent link">&para;</a></h2>
<p>Es la capa de almacenamiento de Hadoop, y como tal, es un sistema de ficheros distribuido y tolerante a fallos que puede almacenar gran cantidad de datos, escalar de forma incrementa y sobrevivir a fallos de hardware sin perder datos.</p>
<p>En un sistema que se reparte entre todos los nodos del clúster de Hadoop, dividiendo los ficheros en bloques (cada bloque por defecto es de 128MB) y almacenando copias duplicadas a través de los nodos. Por defecto se replica en 3 nodos distintos.</p>
<p>FIXME: poner gráfico</p>
<p>Está planteado para escribir los datos una vez y leerlos muchos veces. Las escrituras se pueden realizar a mano, o desde herramientas como <em>Flume</em> y <em>Sqoop</em>, que estudiaremos más adelante.</p>
<p>No ofrece buen rendimiento para:​</p>
<ul>
<li>Accesos de baja latencia​</li>
<li>Ficheros pequeños (a menos que se agrupen)​</li>
<li>Múltiples <em>escritores</em></li>
<li>Modificaciones arbitrarias de ficheros​</li>
</ul>
<h3 id="bloques">Bloques<a class="headerlink" href="#bloques" title="Permanent link">&para;</a></h3>
<p>Un bloque es la cantidad mínima de datos que puede ser leída o escrita.​ El tamaño predeterminado de HDFS son 128 MB, ya que Hadoop está pensado para trabajar con fichero de gran tamaño.​</p>
<p>Todos los ficheros están divididos en bloques.​ Esto quiere decir que si subimos un fichero de 600MB, lo dividirá en 5 bloques de 128MB. Estos bloques se distribuyen por todos los nodos de datos del clúster de Hadoop.</p>
<p>A partir del factor de redundancia, cada bloque se almacena varias veces en máquinas distintas. El valor por defecto es 3.​ Por lo tanto, el archivo de 600MB que teniamos dividido en 5 bloques de 128MB, si lo replicamos tres veces, lo tendremos repartido en 15 bloques entre todos los nodos del clúster.</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/hdfsReplicacion.png" width="500">
    <figcaption>Factor de replicación HDFS</figcaption>
</figure>

<p>En HDFS se distinguen las siguientes máquinas:​</p>
<ul>
<li><em>Namenode</em>: ​Actúa como máster y almacena todos los metadatos necesarios para construir el sistema de ficheros a partir de sus bloques.​ Tiene control sobre donde están todos los bloques.​</li>
<li><em>Datanode</em>:​ Son los esclavos, se limitan a almacenar los bloques que compone cada fichero.​</li>
<li><em>Secondary Namenode</em>:​ Su función principal es tomar puntos de control de los metadatos del sistema de archivos presentes en namenode.​</li>
</ul>
<figure style="align: center;">
    <img src="../imagenes/hadoop/hdfsArquitectura.png" width="500">
    <figcaption>Arquitectura HDFS</figcaption>
</figure>

<h3 id="namenodes">Namenodes<a class="headerlink" href="#namenodes" title="Permanent link">&para;</a></h3>
<p>Existen dos tipos. El principal se conoce como <em>Namenode</em>:</p>
<ul>
<li>Solo existe uno.​</li>
<li>Gestiona el espacio del sistema de ficheros​</li>
<li>Mantiene el árbol del Sistema de ficheros y los metadatos para todos los ficheros y directorios en el árbol.​</li>
<li>Los bloques nunca pasan por el NameNode, se transfieren entre DataNodes o al cliente.​ Es decir, el <em>Namenode</em> no es responsable de almacenar o transferir los datos.</li>
<li>Si se cae, no hay acceso al HDFS​</li>
</ul>
<p>El segundo tipo es el <em>Secondary Namenode</em>:</p>
<ul>
<li>Su función principal es guardar una copia de <em>FsImage</em> y <em>EditLog​</em><ul>
<li><em>FsImage</em>: instantánea de los metadatos del sistema de archivos.​</li>
<li><em>EditLog</em>: registro de transacciones que contiene los registros de cada cambio que se produce en los metadatos del sistema de * archivos.​</li>
</ul>
</li>
<li>No se trata de un nodo de respaldo​</li>
<li>Por lo general se ejecuta en una máquina distinta​</li>
</ul>
<h3 id="datanode">Datanode<a class="headerlink" href="#datanode" title="Permanent link">&para;</a></h3>
<ul>
<li>Más de uno​</li>
<li>Almacena y lee bloques.​</li>
<li>Recuperado por Namenode clientes​</li>
<li>Reportan al Namenode la lista de bloques que están almacenando.​</li>
<li>Pueden ir en distintos discos​</li>
<li>Guarda un checksum del bloque​</li>
<li>Verificación del bloque: lectura​</li>
</ul>
<div class="admonition info">
<p class="admonition-title">HDFS por dentro</p>
<p>HDFS utiliza de un conjunto de ficheros que gestionan los cambios que se producen en el clúster.
Si entramos a la carpeta de datos que tenemos configurada en <code>hdfs-site.xml</code>, tendremos una carpeta <code>current</code> que contendrá un conjunto de ficheros cuyos prefijos son:</p>
<ul>
<li><code>edits_000NNN</code>: histórico de cambios que se van produciendo.</li>
<li><code>edits_inprogress_NNN</code>: cambios actuales en memoria</li>
<li><code>fsimagen_000NNN</code>: <em>snapshot</em> en el tiempo del sistema de ficheros.</li>
</ul>
<p><figure style="float: right; padding-left: 20px">
    <img src="../imagenes/hadoop/hdfsPorDentro.png" width="450">
    <figcaption>HDFS DFS</figcaption>
</figure></p>
<p>Al arrancar HDFS se carga en memoria el último fichero <code>fsimage</code> disponible junto con los <code>edits</code> que no han sido procesados. Mediante el <em>secondary namenode</em>, cuando se llena un bloque, se irán sincronizando los cambios que se producen en <code>edits_inprogress</code> creando un nuevo <code>fsimage</code> y un nuevo <code>edits</code>.</p>
</div>
<h3 id="procesos-de-lectura-y-escritura">Procesos de lectura y escritura<a class="headerlink" href="#procesos-de-lectura-y-escritura" title="Permanent link">&para;</a></h3>
<p>Colocar un archivo en HDFS implica los siguientes pasos:</p>
<ol>
<li>Una aplicación cliente envía una solicitud al <em>namenode</em> que especifica dònde quiere poner el archivo dentro de HDFS.</li>
<li>El <em>namenode</em> determina la forma en que va a dividir los datos en bloques y qué <em>datanodes</em> utilizará para almacenar los bloques. Esta información se devuelve a la aplicación cliente.</li>
<li>La aplicación cliente se comunica directamente con cada <em>datanode</em> escribiendo los bloques informados en el paso anterior.</li>
<li>El <em>datanode</em> replica el bloque de nueva creación a otros 2 datanodes (suponiendo que el factor de replicación sea 3).</li>
<li>Podemos especificar el tamaño del bloque para cada archivo mediante la propiedad <code>dfs.blocksize</code>. Si no se indica un tamaño de bloque a nivel de arhicov, se utiliza el valor global de <code>dfs.blocksize</code> definido en <code>hdfs-site.xml</code>, el cual por defecto es de 128MB.</li>
</ol>
<p>Es importante destacar que los datos nunca pasan por el <em>namenode</em>. El cliente que realiza la carga en HDFS es el que hace las operación de lectura/escritura directamente con los <em>datanodes</em>.</p>
<p>FIXME: revisar, mirar proceso de lectura/escritura del ppt de Teralco</p>
<p>FIXME: mirar video y hacer capturas</p>
<p>https://www.youtube.com/watch?v=e1-yVYXOTMg</p>
<h3 id="trabajando-con-hdfs">Trabajando con HDFS<a class="headerlink" href="#trabajando-con-hdfs" title="Permanent link">&para;</a></h3>
<p>Para interactuar con el almacenamiento desde un terminal, se utiliza el comando <code>hdfs</code>. Este comando admite un segundo parámetro con diferentes opciones.</p>
<p>Antes la duda, es recomendable consultar la <a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">documentación oficial</a></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs comando
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">hadoop fs</p>
<p><figure style="float: left; padding-right: 20px">
    <img src="../imagenes/hadoop/hdfsdfs.png" width="250">
    <figcaption>HDFS DFS</figcaption>
</figure></p>
<p><code>hadoop fs</code> se relaciona con un sistema de archivos genérico que puede apuntar a cualquier sistema de archivos como local, HDFS, FTP, S3, etc. En versiones anteriores se utilizaba el comando <code>hadoop dfs</code>para acceder a HDFS, pero ya quedado obsoleto en favor de <code>hdfs dfs</code>.</p>
</div>
<p>En el caso concreto de interactuar con el sistema de ficheros de Hadoop se utiliza el comando <code>dfs</code>, el cual admite requiere de otro argumento (empezando con un guión) el cual será uno de los comandos Linux para interactuar con el shell. Podéis consultar la lista de comandos en la <a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html">documentación oficial</a>.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -comandosLinux
</code></pre></div>
<p>Por ejemplo, para mostrar todos los archivos que tenemos en el raíz haríamos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -ls
</code></pre></div>
<p>Los comandos más utilizados son:</p>
<ul>
<li><code>put</code>: Coloca un archivo dentro de HDFS</li>
<li><code>get</code>: Recupera un archivo de HDFS y lo lleva a nuestro sistema <em>host</em>.</li>
<li><code>cat</code> / <code>text</code> / <code>tail</code>: Visualiza el contenido de un archivo.</li>
<li><code>mkdir</code> / <code>rmdir</code>: Crea / borra una carpeta.</li>
<li><code>count</code>: Cuenta el número de elementos (número de carpetas, ficheros, tamaño y ruta).</li>
<li><code>cp</code> / <code>mv</code>: Copia / mueve-renombra un archivo.</li>
</ul>
<div class="admonition question">
<p class="admonition-title">Autoevaluación</p>
<p>¿Sabes qué realiza cada uno de los siguientes comandos?</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -mkdir /datos
<span class="linenos" data-linenos="2 "></span>hdfs dfs -put ejemplo.txt /datos/
<span class="linenos" data-linenos="3 "></span>hdfs dfs -put ejemplo.txt /datos/ejemploRenombrado.txt
<span class="linenos" data-linenos="4 "></span>hdfs dfs -ls /datos
<span class="linenos" data-linenos="5 "></span>hdfs dfs -count /datos
<span class="linenos" data-linenos="6 "></span>hdfs dfs -mv /datos/ejemploRenombrado.txt /datos/otroNombre.json
<span class="linenos" data-linenos="7 "></span>hdfs dfs -get /datos/otroNombre.json /tmp
</code></pre></div>
</div>
<p>A continuación vamos a ver como trabajar HDFS con los bloques. Para el siguiente ejemplo, vamos a trabajar con un archivo que ocupe más de un bloque, como puede ser <a href="https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv">El registro de taxis amarillos de Nueva York - Enero 2020</a>.</p>
<p>FIXME: Corregir y revisar</p>
<p>o primero que vamos a hacer es crear un directorio dentro del hdfs llamado temporal
hdfs dfs -mkdir /user/temporal
 Una vez creado subimos el archivo de la carpeta Recurso al directorio de dfs creado en el paso anterior
hdfs dfs -put el_quijote.txt /user/temporal
 Con el fichero subido nos vamos al hdfs UI: localhost:9870 y comprobamos que el Block Pool ID del block information, coincide con el del directorio de datos del datanode, dentro del directorio current:</p>
<p>Dentro de este subdirectorio existe otro current/finalized, donde Hadoop irá creando una estructura de subdirectorios subdir()... donde albergará los bloques de datos. En uno aparecen los datos y en el otro los metadatos
 Creamos un nuevo directorio llamado temporal1 y copiamos el fichero prueba.txt del directorio temporal a temporal1.
 Borramos el directorio temporal
 Ahora vamos a crear un fichero grande. Para ello lanzamos este comando que nos va a generar un fichero de 1G en /tmp, llamado giga_test.dat que estará lleno de ceros.
 Subimos el fichero a un directorio que creamos conveniente hdfs dfs -put /tmp/giga_test.dat /user/prueba
 Una vez subido nos vamos a hdfs UI file browser para ver los bloques que ha creado</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>dd <span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>/tmp/giga_test.dat <span class="nv">bs</span><span class="o">=</span><span class="m">1024</span> <span class="nv">count</span><span class="o">=</span><span class="m">1000000</span>
<span class="linenos" data-linenos=" 2 "></span><span class="sb">````</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>Ahora nos vamos al directorio subdir<span class="o">()</span> de datanode y podremos comprobar todos los bloques
<span class="linenos" data-linenos=" 5 "></span>ls /datos/datanode/current/BP-1410034788-192.168.0.101- <span class="m">1618596221610</span>/current/finalized/subdir0/subdir0
<span class="linenos" data-linenos=" 6 "></span>Bloques acabados desde el <span class="m">20</span> al <span class="m">27</span>
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1">### Administración</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>Algunas de las opciones más utiles para administrar HDFS son:
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span>* <span class="sb">`</span>hdfs dfsadmin -report<span class="sb">`</span>: Realiza un resumen del sistema HDFS, similar al que aparece en el interfaz web.
<span class="linenos" data-linenos="13 "></span>* <span class="sb">`</span>hdfs fsck<span class="sb">`</span>: Comprueba el estado del sistema de ficheros. Si queremos comprobar el estado de un determinado directorio, lo indicamos mediante un segundo parámetro: <span class="sb">`</span>hdfs fsck /datos/prueba<span class="sb">`</span>
<span class="linenos" data-linenos="14 "></span>* <span class="sb">`</span>hdfs dfsadmin -printTopology<span class="sb">`</span>: Muestra la topología que tenemos, identificando los nodos que tenemos y al rack al que pertenece cada nodo
<span class="linenos" data-linenos="15 "></span>* <span class="sb">`</span>hdfs dfsadmin -listOpenFiles<span class="sb">`</span>: Comprueba si hay algún fichero abierto
<span class="linenos" data-linenos="16 "></span>
<span class="linenos" data-linenos="17 "></span><span class="c1">### *Snapshots*</span>
<span class="linenos" data-linenos="18 "></span>
<span class="linenos" data-linenos="19 "></span>Mediante las *snapshots* podemos hacer una foto que indica cómo está en un determinado momento nuestro sistema de ficheros, a modo de copia de seguridad de los datos, para en un futuro poder hacer una recuperación.
<span class="linenos" data-linenos="20 "></span>
<span class="linenos" data-linenos="21 "></span>El primer paso es activar el uso de *snapshots*, mediante el comando de administración, indicando sobre qué carpeta vamos a habilitar su uso:
<span class="linenos" data-linenos="22 "></span>
<span class="linenos" data-linenos="23 "></span><span class="sb">```</span> bash
<span class="linenos" data-linenos="24 "></span>hdfs dfsadmin -allowSnapshot /datos
</code></pre></div>
<p>El siguiente paso es crear una <em>snapshot</em>, para ellos se indica tanto la carpeta como un nombre para la captura (es un comando que se realiza sobre el sistema de archivos):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -createSnapshot /datos /captura1
</code></pre></div>
<p>Esta captura se creará dentro de una carpeta oculta dentro de la ruta indicada (en nuestro caso creará la carpeta  <code>/datos/.snapshot/captura1/</code> la cual contendrá la información de la captura)</p>
<p>A continuación, vamos a borrar uno de los archivo creados anteriormente y comprobar que ya no existe:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -rm /datos/ejemplo.txt
<span class="linenos" data-linenos="2 "></span>hdfs dfs -ls /datos
</code></pre></div>
<p>Para comprobar el funcionamiento de los <em>snapshots</em>, vamos a recuperar el archivo desde la captura creada anteriormente.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>hdfs dfs -cp /datos/.snapshot/captura1/ejemplo.txt /datos
</code></pre></div>
<h2 id="yarn">YARN<a class="headerlink" href="#yarn" title="Permanent link">&para;</a></h2>
<p><em>Yet Another Resource Negotiator</em> es un distribuidor de datos y gestor de recursos distribuidos. Forma parte de Hadoop desde la versión 2, y abstrae la gestión de recursos de los procesos <em>MapReduce</em> lo que implica una asignación de recursos más efectiva.</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/yarnArquitectura.png">
    <figcaption>YARN y Hadoop</figcaption>
</figure>

<p>El objetivo principal de YARN es separar en dos servicios las funcionalidades de gestion de recursos de la monitorización/planificación de tareas.</p>
<p>Se divide en tres componentes principales: un <em>Resource Manager</em>, Node Manager y <em>ApplicationMaster</em>.</p>
<p>La idea es tener un <em>Resource Manager</em> global y un <em>Application Master</em> por aplicación, considerando una aplicación tanto un único <em>job</em> como un conjunto de jobs cíclicos.</p>
<p>El <em>Resource Manager</em> y el <em>Node Manager</em> componen el framework de computación de datos. En concreto, el <em>ResourceManager</em> es la autoridad que orquesta los recursos entre todas las aplicaciones del sistema. A su vez, el <em>NodeManager</em> es un agente que está en cada nodo de datos y es responsable de monitorizar los recursos de cada nodo (CPU, memoria, disco y red) y reportar estos datos al <em>Resource Manager</em>.</p>
<p>El <em>Application Master</em> es una librería específica encargada de negociar los recursos con el <em>ResourceManager</em> y de trabajar con los <em>Node Manager</em> para ejecutar y monitorizar las tareas.</p>
<h3 id="resource-manager"><em>Resource Manager</em><a class="headerlink" href="#resource-manager" title="Permanent link">&para;</a></h3>
<p>A su vez se divide en dos componentes:</p>
<ul>
<li>El <em>Scheduler</em> o planificador es el encargado de gestionar la distribución de los recursos del clúster de YARN. Además, las aplicaciones usan los recursos que el <em>Resource Manager</em> les ha proporcionado en función de sus criterios de planificación. Este planificador no monitoriza el estado de ninguna aplicación ni les ofrece garantías de ejecución, ni recuperación por fallos de la aplicación o el hardware, sólo planifica. Este componente realiza su planificación a partir de los requisitos de recursos necesarios por las aplicaciones (CPU, memoria, disco y red).</li>
<li><em>Applications Manager</em>:  es el componente del <em>Resource Manager</em> responsable de aceptar las peticiones de trabajos, negociar el contenedor en el que ejecutar la <em>Application Master</em> y proporcionar reinicios de los trabajos en caso de que fuera necesario debido a errores.</li>
</ul>
<p>El <em>Resource Manager</em> mantiene un listado de los <em>Node Manager</em> activos y de sus recursos disponibles. Los clientes del sistema pueden enviar una aplicación Yarn soportada para ejecutar al <em>Resource Manager</em>.</p>
<h3 id="node-manager"><em>Node Manager</em><a class="headerlink" href="#node-manager" title="Permanent link">&para;</a></h3>
<p>Gestiona los trabajos con las instrucciones del <em>Resource Manager</em> y proporciona los recursos computacionales necesarios para las aplicaciones en forma de contenedores. Implementa Heartbeats para mantener informado del estado al <em>Resource Manager</em>.</p>
<p>Los contenedores YARN tienen una asignación de recursos (CPU, memoria, disco y red) fija de un host del clúster y el <em>Node Manager</em> es el encargado de monitorizar esta asignación. Mapean las variables de entorno necesarias, las dependencias y los servicios necesarios para crear los procesos.</p>
<h3 id="application-master"><em>Application Master</em><a class="headerlink" href="#application-master" title="Permanent link">&para;</a></h3>
<p>El <em>Application Master</em> es el responsable de negociar los recursos apropiados con el <em>Resource Manager</em> y monitorizar su estado y su progreso. También coordina la ejecución de todas las tareas en las que puede dividirse su aplicación.</p>
<p>Podemos ver la secuencia de trabajo y colaboración de estos componentes en el siguiente gráfico:</p>
<figure style="align: center;">
    <img src="../imagenes/hadoop/yarn_architecture.gif">
    <figcaption>Secuencia de trabajo YARN</figcaption>
</figure>

<ol>
<li>El cliente envía una aplicación YARN.</li>
<li><em>Resource Manager</em> reserva los recursos en un contenedor para su ejecución.</li>
<li>El <em>Application Manager</em> se registra con el <em>Resource Manager</em> y pide los recursos necesarios.</li>
<li>El <em>Application Manager</em> notifica al <em>Node Manager</em> la ejecución de los contenedores. Se ejecuta la aplicación Yarn en el contenedor correspondiente.</li>
<li>El <em>Application Master</em> monitoriza la ejecución y reporta el estado al <em>Resource Manager</em> y al <em>Application Manager</em>.</li>
<li>Al terminar la ejecución, el <em>Application Manager</em> lo notifica al <em>Resource Manager</em>.</li>
</ol>
<p>YARN soporta la reserva de recursos mediante el <a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/ReservationSystem.html"><em>Reservation System</em></a>, un componente que permite a los usuarios especificar un perfil de recurso y restricciones temporales (<em>deadlines</em>) y posteriormente reservar recursos para asegurar la ejecución predecibles de las tareas importantes. Este sistema registra los recursos a lo largo del tiempo, realiza control de admisión para las reservas, e informa dinámicamente al planificador para asegurarse que se produce la reserva.</p>
<p>Para conseguir una alta escalabilidad (del orden de miles de nodos), YARN ofrece el concepto de <a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/Federation.html"><em>Federación</em></a>. Esta funcionalidad permite conectar varios clústeres YARN y hacerlos visibles como un clúster único. De esta forma puede ejecutar trabajos muy pesados y distribuidos.</p>
<div class="admonition info">
<p class="admonition-title">Hadoop v1</p>
<p>MapReduce en hadoop-2.x mantiene la compatibilidad del APU con versiones previas (hadoop-1.x). De esta manera, todo los <em>jobs</em> de <em>MapReduce</em> funcionan perfectamente con YARN sólo recompilando el código.</p>
</div>
<h2 id="instalacion">Instalación<a class="headerlink" href="#instalacion" title="Permanent link">&para;</a></h2>
<p>Para trabajar en este y las siguientes sesión, vamos a trabajar con la máquina virtual que tenemos compartida en Aules. A partir de la OVA de VirtualBox, podrás entrar con el usuario <em>hadoop</em> y la contraseña <em>hadoop</em>.</p>
<p>Si quieres instalar el software del curso, se recomiendo crear una máquina virtual con cualquier distribución Linux.
En mi caso, yo lo he probado en la versión <em>20.04 LTS</em> y la versión 3.2.2 de <em>Hadoop</em>. Puedes seguir las instrucciones del artículo <a href="https://noviello.it/es/como-instalar-y-configurar-hadoop-en-ubuntu-20-04-lts/">Cómo instalar y configurar Hadoop en Ubuntu 20.04 LTS</a>.</p>
<p>Para trabajar en local tenemos montada una solución que se conoce como <em>pseudo-distribuida</em>, porque es al mismo tiempo maestro y esclavo. En el mundo real o si utilizamos una solución cloud tendremos un nodo maestro y múltiples nodos esclavos.</p>
<h3 id="configuracion">Configuración<a class="headerlink" href="#configuracion" title="Permanent link">&para;</a></h3>
<p>Los archivos que vamos a revisar a continuación se encuentran dentro de la carpeta <code>$HADOOP_HOME/etc/hadoop</code>.</p>
<p>El archivo que contiene la configuración general del clúster es el archivo <code>core-site.xml</code>. En él se configura cual será el sistema de fichero, que normalmente será hdfs, indicando el dominio del nodo que será el maestro de datos (<em>namenode</em>) de la arquitectura. Por ejemplo, su contenido será similar al siguiente:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="nt">&lt;configuration&gt;</span>
<span class="linenos" data-linenos="2 "></span>    <span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos="3 "></span>        <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos="4 "></span>        <span class="nt">&lt;value&gt;</span>hdfs://dominioNodoMaestro:9000<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos="5 "></span>    <span class="nt">&lt;/property&gt;</span>
<span class="linenos" data-linenos="6 "></span> <span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>
<p>El siguiente paso es configurar el archivo <code>hdfs-site.xml</code> donde se indica tanto el factor de replicación como donde se almacenan tanto los metadatos (<em>namenode</em>) como los datos en sí (<em>datanode</em>):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="nt">&lt;configuration&gt;</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos=" 3 "></span>        <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos=" 4 "></span>        <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="nt">&lt;/property&gt;</span>
<span class="linenos" data-linenos=" 6 "></span>
<span class="linenos" data-linenos=" 7 "></span>    <span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos=" 8 "></span>        <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos=" 9 "></span>        <span class="nt">&lt;value&gt;</span>/carpetaData/hdfs/namenode<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos="10 "></span>    <span class="nt">&lt;/property&gt;</span>
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span>    <span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos="13 "></span>        <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos="14 "></span>        <span class="nt">&lt;value&gt;</span>/carpetaData/hdfs/datanode<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos="15 "></span>    <span class="nt">&lt;/property&gt;</span>
<span class="linenos" data-linenos="16 "></span><span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>
<div class="admonition caution">
<p class="admonition-title">Recuerda</p>
<p>Si tuviésemos un clúster, en el nodo maestro solo configuraríamos la ruta del <em>namenode</em> y en cada uno de los nodos esclavos, únicamente la ruta del <em>datanode</em>.</p>
</div>
<p>Para configurar YARN, primero editaremos el archivo <code>yarn-site.xml</code> para indicar quien va a ser el nodo maestro, así como el manejador y la gestión para hacer el <em>MapReduce</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="nt">&lt;configuration&gt;</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos=" 3 "></span>        <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos=" 4 "></span>        <span class="nt">&lt;value&gt;</span>dominioNodoMaestro<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="nt">&lt;/property&gt;</span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos=" 7 "></span>        <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos=" 8 "></span>        <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos=" 9 "></span>    <span class="nt">&lt;/property&gt;</span>
<span class="linenos" data-linenos="10 "></span>    <span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos="11 "></span>        <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services.mapreduce_shuffle.class<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos="12 "></span>        <span class="nt">&lt;value&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos="13 "></span>    <span class="nt">&lt;/property&gt;</span>
<span class="linenos" data-linenos="14 "></span><span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>
<p>Y finalmente el archivo <code>mapred-site.xml</code> para indicar que utilice YARN como framework <em>MapReduce</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="nt">&lt;configuration&gt;</span>
<span class="linenos" data-linenos="2 "></span>    <span class="nt">&lt;property&gt;</span>
<span class="linenos" data-linenos="3 "></span>        <span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
<span class="linenos" data-linenos="4 "></span>        <span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
<span class="linenos" data-linenos="5 "></span>    <span class="nt">&lt;/property&gt;</span>
<span class="linenos" data-linenos="6 "></span><span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>
<h2 id="puesta-en-marcha">Puesta en marcha<a class="headerlink" href="#puesta-en-marcha" title="Permanent link">&para;</a></h2>
<figure style="float: right; width: 300px">
    <img src="../imagenes/hadoop/start-dfs.png">
    <figcaption>Arrancando HDFS</figcaption>
</figure>

<p>Para arrancar Hadoop, hemos de ejecutar el comando <code>startdfs.sh</code>. Al finalizar, veremos que ha arrancado el <em>namenode</em>, los <em>datanodes</em>, y el <em>secondary namenode</em>.</p>
<p>Si en cualquier momento queremos comprobar el estado de los servicios y procesos en ejecución, tenemos el comando <code>jps</code>.</p>
<p>Si accedemos a <code>http://localhost:9870/</code> podremos acceder a una interfaz web.</p>
<figure style="align: center">
    <img src="../imagenes/hadoop/hadoop-web.png">
    <figcaption>Interfaz Web de Hadoop</figcaption>
</figure>

<figure style="float: right; width: 300px">
    <img src="../imagenes/hadoop/start-yarn.png">
    <figcaption>Arrancando YARN</figcaption>
</figure>

<p>Para arrancar YARN utilizaremos el comando <code>start-yarn.sh</code> para arrancar el <em>Resource Manager</em> y el <em>Node Manager</em>:</p>
<p>Y a su vez, YARN también ofrece un interfaz web para obtener información como las métricas del clúster. Nos conectaremos con el nombre del nodo principal y el puerto <code>8088</code>. En nuestro caso lo hemos realizado a <code>http://hadoop-virtualbox:8088</code> obtienendo la siguiente página:</p>
<figure style="align: center">
    <img src="../imagenes/hadoop/yarn-web.png">
    <figcaption>Interfaz Web de YARN</figcaption>
</figure>

<h2 id="ambari">Ambari<a class="headerlink" href="#ambari" title="Permanent link">&para;</a></h2>
<p><a href="https://ambari.apache.org">Ambari</a> es un producto que simplifica la gestión de Hadoop y permite configurar, instalar y monitorizar un cluster Hadoop.</p>
<p>La instalación que tenemos no nos sirve, ya que Ambari crea un nueva instalación tanto de Hadoop y YARN. Para su instalación desde cero, es recomendable seguir las indicaciones de su <a href="https://cwiki.apache.org/confluence/display/AMBARI/Installation+Guide+for+Ambari+2.7.5">página oficial</a>.</p>
<p>Nosotros vamos a resumir los pasos recomendados. Para instalar en Ubuntu el servidor Amabari únicamente deberíamos ejecutar el siguiente comando (también va a instalar PostgreSQL donde almacenará todos los metadados sobre la configuración de Ambari):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>apt-get install ./ambari-server*.deb   <span class="c1"># Instalará también PostgreSQL</span>
</code></pre></div>
<p>Una vez instalado, solo queda configurarlo (como usuario con permisos <em>root</em>):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>ambari-server setup
</code></pre></div>
<p>Y finalmente arrancarlo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>ambari-server start
</code></pre></div>
<p>Ahora tocaría instalar los agentes en cada uno de los nodos, así como configurarlo. Como vamos a trabajar con un modelo pseudodistribuido, en nuestro caso no vamos a hacer ese paso.</p>
<p>Finalmente, accederemos al interfaz gráfico con el usuario <code>admin/admin</code> y acceder http://localhost:8080.</p>
<p>FIXME: captura</p>
<p>Al crear un cluster, Ambari se basa en los stacks de HortonWorks HDP para realizar la instalación de Hadoop.</p>
<p>FIXME: captura</p>
<p>Revisar nodos</p>
<p>Instalar SSH en usuario root</p>
<h2 id="referencias">Referencias<a class="headerlink" href="#referencias" title="Permanent link">&para;</a></h2>
<ul>
<li>Documentación de <a href="https://hadoop.apache.org/docs/stable/">Apache Hadoop</a></li>
<li>Artículo de <a href="https://empresas.blogthinkbig.com/hadoop-por-dentro-ii-hdfs-y-mapreduce/">Hadoop por dentro</a></li>
<li><a href="https://www.tutorialspoint.com/hadoop/index.htm">Tutorial de Hadoop</a> de Tutorialspoint</li>
</ul>
<h2 id="actividades">Actividades<a class="headerlink" href="#actividades" title="Permanent link">&para;</a></h2>
<p>Para los siguientes ejercicios, copia el comando y/o haz una captura de pantalla donde se muestre el resutlado de cada acción</p>
<ol>
<li>Comandos HDFS<ol>
<li>Crear carpeta, meter 2 archivos, duplicar, renombrar y sacar
FIXME: escribir</li>
</ol>
</li>
<li>HDFS por dentro<ol>
<li>Accede al archivo de configuración <code>hdfs-site.xml</code> y averigua la carpeta donde se almacena el <em>namenode</em>.</li>
<li>Muestra los archivos que contiene la carpeta <code>current</code> dentro del namenode</li>
<li>Comprueba el id del archivo <code>VERSION</code>.</li>
<li>Realiza un checkpoint manual para sincronizar el sistema de ficheros. Para ello entramos en modo <em>safe</em> con el comando <code>hdfs dfsadmin -safemode enter</code>, de manera que impedamos que se trabaje con el sistema de ficheros mientras lanzamos el <em>checkpoint</em>.</li>
<li>Comprueba mediante el interfaz gráfico que el modo seguro está activo.</li>
<li>Realiza un checkpoint</li>
<li>Vuelve a entrar al modo normal</li>
<li>Comprueba que los <em>fimage</em> del <em>namenode</em> son iguales.</li>
</ol>
</li>
<li>HDFS / Administración<ol>
<li>Ejecutar todos los comandos del apartado haciendo capturas. Sobre el contenido creado en el ejercicio 1, crear una snapshot, borrar un archivo, y recuperarlo de la snapshot
FIXME: escribir</li>
</ol>
</li>
<li>(opcional) Crea una instalación desde cero en una nueva máquina virtual siguiendo las intrucciones del artículo recomendado en el apartado de <a href="#configuracion">Configuracion</a>. Arranca Hadoop, muestra los procesos y accede al interfaz gráfico.</li>
<li>(opcional) Crea una instalación desde cero mediante Ambari. Tras acceder al interfaz gráfico, crea un cluster llamado <code>cluster2122</code>. Instala Hadoop y accede al interfaz gráfico.</li>
</ol>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Volver al principio
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      2021-2022 Aitor Medrano - Licencia CC BY-NC-SA
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/aitormedrano" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    <a href="mailto:<a.medrano@edu.gva.es>" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M400 32H48C21.49 32 0 53.49 0 80v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V80c0-26.51-21.49-48-48-48zM178.117 262.104C87.429 196.287 88.353 196.121 64 177.167V152c0-13.255 10.745-24 24-24h272c13.255 0 24 10.745 24 24v25.167c-24.371 18.969-23.434 19.124-114.117 84.938-10.5 7.655-31.392 26.12-45.883 25.894-14.503.218-35.367-18.227-45.883-25.895zM384 217.775V360c0 13.255-10.745 24-24 24H88c-13.255 0-24-10.745-24-24V217.775c13.958 10.794 33.329 25.236 95.303 70.214 14.162 10.341 37.975 32.145 64.694 32.01 26.887.134 51.037-22.041 64.72-32.025 61.958-44.965 81.325-59.406 95.283-70.199z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide", "navigation.top", "navigation.tracking", "content.code.annotate"], "translations": {"clipboard.copy": "Copiar al portapapeles", "clipboard.copied": "Copiado al portapapeles", "search.config.lang": "es", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "B\u00fasqueda", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.term.missing": "Falta", "select.version.title": "Seleccionar versi\u00f3n"}, "search": "../assets/javascripts/workers/search.01824240.min.js"}</script>
    
    
      <script src="../assets/javascripts/bundle.ff0eccb3.min.js"></script>
      
    
  </body>
</html>