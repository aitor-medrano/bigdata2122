
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Analítica de datos con Spark DataFrames y Spark SQL. Agregaciones con Spark DataFrames, joins y uso de Pandas para la generación de gráficos. Creación de vistas en Spark SQL. Empleo de funciones y creación de UDF en Spark. Uso de Databricks Community Edition, acceso a archivos y creación de cuadros de mandos.">
      
      
      
        <link rel="canonical" href="https://aitor-medrano.github.io/bigdata2122/apuntes/spark02dataframe.html">
      
      <link rel="icon" href="../imagenes/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.8">
    
    
      
        <title>Analítica de datos con Spark DataFrames / SQL - Inteligencia Artificial y Big Data</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.644de097.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.e6a45f82.min.css">
        
          
          
          <meta name="theme-color" content="#02a6f2">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-MV889H0W63"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-MV889H0W63",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MV889H0W63"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="light-blue" data-md-color-accent="teal">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#spark-dataframes-sql" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-header__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Inteligencia Artificial y Big Data
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Analítica de datos con Spark DataFrames / SQL
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Búsqueda" placeholder="Búsqueda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando búsqueda
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-nav__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    Inteligencia Artificial y Big Data
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Inicio
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" data-md-state="indeterminate" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Arquitecturas Big Data
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Arquitecturas Big Data" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Arquitecturas Big Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube01.html" class="md-nav__link">
        1.- Cloud Computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube02aws.html" class="md-nav__link">
        2.- AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube03computacion.html" class="md-nav__link">
        3.- Computación
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube04almacenamiento.html" class="md-nav__link">
        4.- Almacenamiento
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube05datos.html" class="md-nav__link">
        5.- Datos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="arquitecturas01.html" class="md-nav__link">
        6.- Arquitecturas
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Ingesta de Datos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Ingesta de Datos" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Ingesta de Datos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta01.html" class="md-nav__link">
        1.- ETL
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta02pentaho.html" class="md-nav__link">
        2.- Pentaho DI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta03nifi1.html" class="md-nav__link">
        3.- Nifi I
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta04nifi2.html" class="md-nav__link">
        4.- Nifi II
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta05python.html" class="md-nav__link">
        5.- Python y AWS
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" data-md-state="indeterminate" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Big Data Aplicado
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Big Data Aplicado" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Big Data Aplicado
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado01hadoop.html" class="md-nav__link">
        1.- Hadoop
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado02hdfs.html" class="md-nav__link">
        2.- HDFS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado03flume.html" class="md-nav__link">
        3.- Sqoop / Flume
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado04hive.html" class="md-nav__link">
        4.- Hive
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado05kafka.html" class="md-nav__link">
        5.- Kafka
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Analítica de Datos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Analítica de Datos" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Analítica de Datos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="spark01rdd.html" class="md-nav__link">
        1.- Spark
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          2.- Spark SQL
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="spark02dataframe.html" class="md-nav__link md-nav__link--active">
        2.- Spark SQL
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dataframes" class="md-nav__link">
    DataFrames
  </a>
  
    <nav class="md-nav" aria-label="DataFrames">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creando-dataframes" class="md-nav__link">
    Creando Dataframes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mostrando-los-datos" class="md-nav__link">
    Mostrando los datos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cargando-diferentes-formatos" class="md-nav__link">
    Cargando diferentes formatos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprimiendo-los-datos" class="md-nav__link">
    Comprimiendo los datos
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#datos-y-esquemas" class="md-nav__link">
    Datos y Esquemas
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataframe-api" class="md-nav__link">
    DataFrame API
  </a>
  
    <nav class="md-nav" aria-label="DataFrame API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#proyectando" class="md-nav__link">
    Proyectando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trabajando-con-columnas" class="md-nav__link">
    Trabajando con columnas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#filtrando" class="md-nav__link">
    Filtrando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ordenando" class="md-nav__link">
    Ordenando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anadiendo-filas" class="md-nav__link">
    Añadiendo filas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cogiendo-muestras" class="md-nav__link">
    Cogiendo muestras
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabajando-con-datos-sucios" class="md-nav__link">
    Trabajando con datos sucios
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#usando-sql" class="md-nav__link">
    Usando SQL
  </a>
  
    <nav class="md-nav" aria-label="Usando SQL">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vistas-temporales" class="md-nav__link">
    Vistas temporales
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vistas-globales" class="md-nav__link">
    Vistas globales
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tablas" class="md-nav__link">
    Tablas
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabajando-con-databricks" class="md-nav__link">
    Trabajando con Databricks
  </a>
  
    <nav class="md-nav" aria-label="Trabajando con Databricks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#datos-visuales" class="md-nav__link">
    Datos visuales
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuadro-de-mandos" class="md-nav__link">
    Cuadro de mandos
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#agregaciones" class="md-nav__link">
    Agregaciones
  </a>
  
    <nav class="md-nav" aria-label="Agregaciones">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contando" class="md-nav__link">
    Contando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calculando" class="md-nav__link">
    Calculando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agrupando" class="md-nav__link">
    Agrupando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agrupando-colecciones" class="md-nav__link">
    Agrupando colecciones
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tablas-pivote" class="md-nav__link">
    Tablas pivote
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#joins" class="md-nav__link">
    Joins
  </a>
  
    <nav class="md-nav" aria-label="Joins">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mediante-sql" class="md-nav__link">
    Mediante SQL
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mediante-python" class="md-nav__link">
    Mediante Python
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#funciones" class="md-nav__link">
    Funciones
  </a>
  
    <nav class="md-nav" aria-label="Funciones">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fechas" class="md-nav__link">
    Fechas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cadenas" class="md-nav__link">
    Cadenas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#colecciones" class="md-nav__link">
    Colecciones
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#json" class="md-nav__link">
    JSON
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#udf" class="md-nav__link">
    UDF
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#persistencia" class="md-nav__link">
    Persistencia
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataframes-y-pandas" class="md-nav__link">
    DataFrames y Pandas
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    Referencias
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#actividades" class="md-nav__link">
    Actividades
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="spark03streaming.html" class="md-nav__link">
        3.- Spark Streaming
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dataframes" class="md-nav__link">
    DataFrames
  </a>
  
    <nav class="md-nav" aria-label="DataFrames">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creando-dataframes" class="md-nav__link">
    Creando Dataframes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mostrando-los-datos" class="md-nav__link">
    Mostrando los datos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cargando-diferentes-formatos" class="md-nav__link">
    Cargando diferentes formatos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprimiendo-los-datos" class="md-nav__link">
    Comprimiendo los datos
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#datos-y-esquemas" class="md-nav__link">
    Datos y Esquemas
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataframe-api" class="md-nav__link">
    DataFrame API
  </a>
  
    <nav class="md-nav" aria-label="DataFrame API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#proyectando" class="md-nav__link">
    Proyectando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trabajando-con-columnas" class="md-nav__link">
    Trabajando con columnas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#filtrando" class="md-nav__link">
    Filtrando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ordenando" class="md-nav__link">
    Ordenando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anadiendo-filas" class="md-nav__link">
    Añadiendo filas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cogiendo-muestras" class="md-nav__link">
    Cogiendo muestras
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabajando-con-datos-sucios" class="md-nav__link">
    Trabajando con datos sucios
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#usando-sql" class="md-nav__link">
    Usando SQL
  </a>
  
    <nav class="md-nav" aria-label="Usando SQL">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vistas-temporales" class="md-nav__link">
    Vistas temporales
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vistas-globales" class="md-nav__link">
    Vistas globales
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tablas" class="md-nav__link">
    Tablas
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabajando-con-databricks" class="md-nav__link">
    Trabajando con Databricks
  </a>
  
    <nav class="md-nav" aria-label="Trabajando con Databricks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#datos-visuales" class="md-nav__link">
    Datos visuales
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuadro-de-mandos" class="md-nav__link">
    Cuadro de mandos
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#agregaciones" class="md-nav__link">
    Agregaciones
  </a>
  
    <nav class="md-nav" aria-label="Agregaciones">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contando" class="md-nav__link">
    Contando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calculando" class="md-nav__link">
    Calculando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agrupando" class="md-nav__link">
    Agrupando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agrupando-colecciones" class="md-nav__link">
    Agrupando colecciones
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tablas-pivote" class="md-nav__link">
    Tablas pivote
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#joins" class="md-nav__link">
    Joins
  </a>
  
    <nav class="md-nav" aria-label="Joins">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mediante-sql" class="md-nav__link">
    Mediante SQL
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mediante-python" class="md-nav__link">
    Mediante Python
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#funciones" class="md-nav__link">
    Funciones
  </a>
  
    <nav class="md-nav" aria-label="Funciones">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fechas" class="md-nav__link">
    Fechas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cadenas" class="md-nav__link">
    Cadenas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#colecciones" class="md-nav__link">
    Colecciones
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#json" class="md-nav__link">
    JSON
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#udf" class="md-nav__link">
    UDF
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#persistencia" class="md-nav__link">
    Persistencia
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataframes-y-pandas" class="md-nav__link">
    DataFrames y Pandas
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    Referencias
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#actividades" class="md-nav__link">
    Actividades
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="spark-dataframes-sql">Spark DataFrames / SQL<a class="headerlink" href="#spark-dataframes-sql" title="Permanent link">&para;</a></h1>
<p>En la sesión anterior hemos introducido Spark y el uso de RDD para interactuar con los datos. Tal como comentamos, los RDD permiten trabajar a bajo nivel, siendo más cómodo y eficiente hacer uso de <em>DataFrames</em> y el lenguaje SQL.</p>
<h2 id="dataframes">DataFrames<a class="headerlink" href="#dataframes" title="Permanent link">&para;</a></h2>
<p>Un <em>DataFrame</em> es una estructura equivalente a una tabla de base de datos relacional, con un motor bien optimizado para el trabajo en un clúster. Los datos se almacenan en filas y columnas y ofrece un conjunto de operaciones para manipular los datos.</p>
<p>El trabajo con <em>DataFrames</em> es más sencillo y eficiente que el procesamiento con RDD, por eso su uso es predominante en los nuevos desarrollos con <em>Spark</em>.</p>
<p>A continuación veremos cómo podemos obtener y persistir <em>DataFrames</em> desde diferentes fuentes y formatos de datos</p>
<h3 id="creando-dataframes">Creando Dataframes<a class="headerlink" href="#creando-dataframes" title="Permanent link">&para;</a></h3>
<p>El caso más básico es crear un <em>DataFrame</em> a partir de una <em>SparkSession</em> pasándole un RDD:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span> <span class="c1"># SparkSession de forma programativa</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># Creamos un RDD</span>
<span class="linenos" data-linenos="5 "></span><span class="n">datos</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;Aitor&quot;</span><span class="p">,</span> <span class="mi">182</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;Pedro&quot;</span><span class="p">,</span> <span class="mi">178</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;Marina&quot;</span><span class="p">,</span> <span class="mi">161</span><span class="p">)]</span>
<span class="linenos" data-linenos="6 "></span><span class="n">rdd</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">datos</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># Creamos un DataFrame y mostramos su esquema</span>
<span class="linenos" data-linenos="8 "></span><span class="n">dfRDD</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>
<span class="linenos" data-linenos="9 "></span><span class="n">dfRDD</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<p>Y obtenemos un resumen del esquema del <em>DataFrame</em>, donde para cada columna se indica el nombre, el tipo y si admite valores nulos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>root
<span class="linenos" data-linenos="2 "></span> |-- _1: string (nullable = true)
<span class="linenos" data-linenos="3 "></span> |-- _2: long (nullable = true)
</code></pre></div>
<p>Podemos ver como los nombres de las columnas son <code>_1</code> y <code>_2</code>. Para asignarle un nombre adecuado podemos pasarle una lista con los nombres a la hora de crear el <em>DataFrame</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">columnas</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;nombre&quot;</span><span class="p">,</span><span class="s2">&quot;altura&quot;</span><span class="p">]</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfRDD</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="n">columnas</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfRDD</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<p>Y ahora obtenemos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>root
<span class="linenos" data-linenos="2 "></span> |-- nombre: string (nullable = true)
<span class="linenos" data-linenos="3 "></span> |-- altura: long (nullable = true)
</code></pre></div>
<p>Si queremos mostrar sus datos, haremos uso del método <code>show</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>df.show<span class="o">()</span>
</code></pre></div>
<p>Obteniendo una vista de los datos en forma de tabla:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>+------+------+
<span class="linenos" data-linenos="2 "></span>|nombre|altura|
<span class="linenos" data-linenos="3 "></span>+------+------+
<span class="linenos" data-linenos="4 "></span>| Aitor|   182|
<span class="linenos" data-linenos="5 "></span>| Pedro|   178|
<span class="linenos" data-linenos="6 "></span>|Marina|   161|
<span class="linenos" data-linenos="7 "></span>+------+------+
</code></pre></div>
<p>También podemos crear un <em>DataFrame</em> directamente desde una <em>SparkSession</em> sin crear un RDD previamente:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="c1"># También podemos crear un DF desde SparkSession</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfDesdeDatos</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">datos</span><span class="p">)</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="o">*</span><span class="n">columnas</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfDesdeDatos</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<h3 id="mostrando-los-datos">Mostrando los datos<a class="headerlink" href="#mostrando-los-datos" title="Permanent link">&para;</a></h3>
<p>Para los siguientes apartados, supongamos que queremos almacenar ciertos datos de clientes, como son su nombre y apellidos, ciudad y sueldo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">clientes</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos="2 "></span>    <span class="p">(</span><span class="s2">&quot;Aitor&quot;</span><span class="p">,</span> <span class="s2">&quot;Medrano&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">3000</span><span class="p">),</span>
<span class="linenos" data-linenos="3 "></span>    <span class="p">(</span><span class="s2">&quot;Pedro&quot;</span><span class="p">,</span> <span class="s2">&quot;Casas&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">4000</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>    <span class="p">(</span><span class="s2">&quot;Laura&quot;</span><span class="p">,</span> <span class="s2">&quot;García&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">5000</span><span class="p">),</span> 
<span class="linenos" data-linenos="5 "></span>    <span class="p">(</span><span class="s2">&quot;Miguel&quot;</span><span class="p">,</span> <span class="s2">&quot;Ruiz&quot;</span><span class="p">,</span> <span class="s2">&quot;Torrellano&quot;</span><span class="p">,</span> <span class="mi">6000</span><span class="p">),</span>
<span class="linenos" data-linenos="6 "></span>    <span class="p">(</span><span class="s2">&quot;Isabel&quot;</span><span class="p">,</span> <span class="s2">&quot;Guillén&quot;</span><span class="p">,</span> <span class="s2">&quot;Alicante&quot;</span><span class="p">,</span> <span class="mi">7000</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="p">]</span>
<span class="linenos" data-linenos="8 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clientes</span><span class="p">)</span>
</code></pre></div>
<p>Para mostrar los datos, ya hemos visto que podemos utilizar el método <code>show</code>, al cual le podemos indicar o no la cantidad de registros a recuperar, así como si queremos que los datos se trunquen o no, o si los queremos mostrar en vertical:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +------+---------+------+------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |nombre|apellidos|ciudad|sueldo|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +------+---------+------+------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># | Aitor|  Medrano| Elche|  3000|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># | Pedro|    Casas| Elche|  4000|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># +------+---------+------+------+</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># only showing top 2 rows</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |nombre|apellidos|ciudad    |sueldo|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |Aitor |Medrano  |Elche     |3000  |</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |Pedro |Casas    |Elche     |4000  |</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |Laura |García   |Elche     |5000  |</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |Miguel|Ruiz     |Torrellano|6000  |</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># |Isabel|Guillén  |Alicante  |7000  |</span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="19 "></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">vertical</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos" data-linenos="20 "></span><span class="c1"># -RECORD 0------------</span>
<span class="linenos" data-linenos="21 "></span><span class="c1">#  nombre    | Aitor   </span>
<span class="linenos" data-linenos="22 "></span><span class="c1">#  apellidos | Medrano </span>
<span class="linenos" data-linenos="23 "></span><span class="c1">#  ciudad    | Elche   </span>
<span class="linenos" data-linenos="24 "></span><span class="c1">#  sueldo    | 3000    </span>
<span class="linenos" data-linenos="25 "></span><span class="c1"># -RECORD 1------------</span>
<span class="linenos" data-linenos="26 "></span><span class="c1">#  nombre    | Pedro   </span>
<span class="linenos" data-linenos="27 "></span><span class="c1">#  apellidos | Casas   </span>
<span class="linenos" data-linenos="28 "></span><span class="c1">#  ciudad    | Elche   </span>
<span class="linenos" data-linenos="29 "></span><span class="c1">#  sueldo    | 4000    </span>
<span class="linenos" data-linenos="30 "></span><span class="c1"># -RECORD 2------------</span>
<span class="linenos" data-linenos="31 "></span><span class="c1">#  nombre    | Laura   </span>
<span class="linenos" data-linenos="32 "></span><span class="c1">#  apellidos | García  </span>
<span class="linenos" data-linenos="33 "></span><span class="c1">#  ciudad    | Elche   </span>
<span class="linenos" data-linenos="34 "></span><span class="c1">#  sueldo    | 5000    </span>
<span class="linenos" data-linenos="35 "></span><span class="c1"># only showing top 3 rows</span>
</code></pre></div>
<p>Si sólo queremos recuperar unos pocos datos, podemos hacer uso de <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.head.html">head</a> o <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.first.html">first</a> los cuales devuelven objetos <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Row.html">Row</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000)</span>
<span class="linenos" data-linenos="5 "></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># [Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000),</span>
<span class="linenos" data-linenos="7 "></span><span class="c1">#  Row(nombre=&#39;Pedro&#39;, apellidos=&#39;Casas&#39;, ciudad=&#39;Elche&#39;, sueldo=4000),</span>
<span class="linenos" data-linenos="8 "></span><span class="c1">#  Row(nombre=&#39;Laura&#39;, apellidos=&#39;García&#39;, ciudad=&#39;Elche&#39;, sueldo=5000)]</span>
</code></pre></div>
<p>Si queremos obtener un valor en concreto, una vez recuperada una fila, podemos acceder a sus columnas:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">nom1</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>           <span class="c1"># &#39;Aitor&#39;</span>
<span class="linenos" data-linenos="2 "></span><span class="n">nom2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="s2">&quot;nombre&quot;</span><span class="p">]</span>    <span class="c1"># &#39;Aitor&#39;</span>
</code></pre></div>
<p>También podemos obtener un sumario de los datos (igual que con <em>Pandas</em>) mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.describe.html">describe</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +-------+------+---------+----------+------------------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |summary|nombre|apellidos|    ciudad|            sueldo|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +-------+------+---------+----------+------------------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |  count|     5|        5|         5|                 5|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |   mean|  null|     null|      null|            5000.0|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | stddev|  null|     null|      null|1581.1388300841897|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |    min| Aitor|    Casas|  Alicante|              3000|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |    max| Pedro|     Ruiz|Torrellano|              7000|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+------+---------+----------+------------------+</span>
</code></pre></div>
<p>Si únicamente nos interesa saber cuantas filas tiene nuestro <em>DataFrame</em>, podemos hacer uso de <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.count.html">count</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># 5</span>
</code></pre></div>
<p>Por último, como un <em>DataFrame</em> por debajo es un RDD, podemos usar <code>collect</code> y <code>take</code> conforme necesitemos y recuperar objetos de tipo <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Row.html">Row</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># [Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000),</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1">#  Row(nombre=&#39;Pedro&#39;, apellidos=&#39;Casas&#39;, ciudad=&#39;Elche&#39;, sueldo=4000),</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1">#  Row(nombre=&#39;Laura&#39;, apellidos=&#39;García&#39;, ciudad=&#39;Elche&#39;, sueldo=5000),</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1">#  Row(nombre=&#39;Miguel&#39;, apellidos=&#39;Ruiz&#39;, ciudad=&#39;Torrellano&#39;, sueldo=6000),</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1">#  Row(nombre=&#39;Isabel&#39;, apellidos=&#39;Guillén&#39;, ciudad=&#39;Alicante&#39;, sueldo=7000)]</span>
<span class="linenos" data-linenos=" 7 "></span><span class="n">df</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># [Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000),</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1">#  Row(nombre=&#39;Pedro&#39;, apellidos=&#39;Casas&#39;, ciudad=&#39;Elche&#39;, sueldo=4000)]</span>
<span class="linenos" data-linenos="10 "></span><span class="n">nom</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>        <span class="c1"># &#39;Aitor&#39;</span>
</code></pre></div>
<h3 id="cargando-diferentes-formatos">Cargando diferentes formatos<a class="headerlink" href="#cargando-diferentes-formatos" title="Permanent link">&para;</a></h3>
<p>Lo más usual es cargar los datos desde una archivo externo. Para ello, mediante el API de <em>DataFrameReader</em> cargaremos los datos directamente en un <em>Dataframe</em> mediante diferentes métodos dependiendo del formato (admite tanto el nombre de un recurso como una ruta de una carpeta).</p>
<p>Para cada formato, existe un método corto que se llama como el formato en sí, y un método general que finaliza en con el método <code>load</code>, siempre dentro de <code>spark.read</code>:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:4"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><input id="__tabbed_1_4" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">CSV</label><label for="__tabbed_1_2">TXT</label><label for="__tabbed_1_3">JSON</label><label for="__tabbed_1_4">Parquet</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos/*.csv&quot;</span><span class="p">)</span>   <span class="c1"># Una carpeta entera</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span> <span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="5 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">sep</span><span class="o">=</span><span class="s2">&quot;;&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;pdi_sales.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span> 
<span class="linenos" data-linenos="8 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-csv.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfTXT</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># cada fichero se lee entero como un registro</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfTXT</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;wholetext&quot;</span><span class="p">,</span> <span class="n">true</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s2">&quot;datos/&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span>
<span class="linenos" data-linenos="5 "></span><span class="n">dfTXT</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-text.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfJSON</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfJSON</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-json.html">documentación oficial</a></p>
<div class="admonition caution">
<p class="admonition-title">DataFrames desde JSON</p>
<p><em>Spark</em> espera que cada documento JSON ocupe una única línea. Si cada documento ocupa más de una línea, se lo indicamos mediante la opción <code>multiline</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;multiline&quot;</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfParquet</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;datos.parquet&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfParquet</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;datos.parquet&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html">documentación oficial</a></p>
</div>
</div>
</div>
<p>Si lo que queremos es persistir los datos, en vez de <code>read</code>, utilizaremos <code>write</code> y si usamos la forma general usaremos el método <code>save</code>:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:4"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><input id="__tabbed_2_4" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">CSV</label><label for="__tabbed_2_2">TXT</label><label for="__tabbed_2_3">JSON</label><label for="__tabbed_2_4">Parquet</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfCSV</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfCSV</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfCSV</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-csv.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfTXT</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfTXT</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;lineSep&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfTXT</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-text.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfJSON</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfJSON</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-json.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfParquet</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;datos.parquet&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfParquet</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.parquet&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html">documentación oficial</a></p>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Un único archivo de salida</p>
<p>Por cada partición, Spark generará un archivo de salida. Recuerda que podemos <a href="spark01rdd.html#modificando-las-particiones">reducir el número de particiones</a> mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.coalesce.html">coalesce</a> o <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.repartition.html">repartition</a>.</p>
</div>
<p>Una vez vista la sintaxis, vamos a ver un ejemplo completo de lectura de un archivo CSV (el archivo <a href="../recursos/pdi/pdi_sales.csv"><code>pdi_sales.csv</code></a> que hemos utilizado durante todo el curso) que está almacenado en HDFS y que tras leerlo, lo guardamos como JSON de nuevo en HDFS:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos=" 2 "></span>
<span class="linenos" data-linenos=" 3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;s8a-dataframe-csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="linenos" data-linenos=" 4 "></span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># Lectura de CSV con el ; como separador de columnas y con encabezado</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;delimiter&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;hdfs://iabd-virtualbox:9000/user/iabd/pdi_sales.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># df.printSchema()</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span><span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;hdfs://iabd-virtualbox:9000/user/iabd/pdi_sales_json&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Es conveniente destacar que para acceder a HDFS, únicamente hemos de indicar la URL del recurso con el prefijo <code>hdfs://</code> más el host del <em>namenode</em>.</p>
<h3 id="comprimiendo-los-datos">Comprimiendo los datos<a class="headerlink" href="#comprimiendo-los-datos" title="Permanent link">&para;</a></h3>
<p>Para configurar el algoritmo de compresión, si los datos está en Parquet o Avro, a nivel de la sesión de Spark, podemos realizar su configuración:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">spark</span><span class="o">.</span><span class="n">setConf</span><span class="p">(</span><span class="s2">&quot;spark.sql.parquet.compression.codec&quot;</span><span class="p">,</span><span class="s2">&quot;snappy&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">spark</span><span class="o">.</span><span class="n">setConf</span><span class="p">(</span><span class="s2">&quot;spark.sql.parquet.compression.codec&quot;</span><span class="p">,</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span><span class="o">.</span><span class="n">setConf</span><span class="p">(</span><span class="s2">&quot;spark.sql.avro.compression.codec&quot;</span><span class="p">,</span><span class="s2">&quot;snappy&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Si sólo queremos hacerlo para una operación en particular, para cada lectura/escritura le añadimos <code>.option("compression", "algoritmo")</code>. Por ejemplo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfVentas</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;compression&quot;</span><span class="p">,</span> <span class="s2">&quot;snappy&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;delimiter&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;pdi_sales.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfClientes</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;compression&quot;</span><span class="p">,</span> <span class="s2">&quot;snappy&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;clientes.parquet&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfVentas</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;compression&quot;</span><span class="p">,</span> <span class="s2">&quot;snappy&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;avro&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;ventas.avro&quot;</span><span class="p">)</span>
</code></pre></div>
<h2 id="datos-y-esquemas">Datos y Esquemas<a class="headerlink" href="#datos-y-esquemas" title="Permanent link">&para;</a></h2>
<p>El esquema completo de un <em>DataFrame</em> se modela mediante un <code>StructType</code>, el cual contiene una colección de objetos <code>StructField</code>.
Así pues, cada columna de un <em>DataFrame</em> de <em>Spark</em> se modela mediante un objeto <code>StructField</code> indicando su nombre, tipo y gestión de los nulos.</p>
<p>Hemos visto que al crear un <em>DataFrame</em> desde un archivo externo, podemos inferir el esquema. Si queremos crear un <em>DataFrame</em> desde un esquema propio utilizaremos los tipos <code>StructType</code>, <code>StructField</code>, así como <code>StringType</code>, <code>IntegerType</code> o el tipo necesario para cada columna. Para ello, primero hemos de importarlos (como puedes observar, estas clases pertenecen a las librerías SQL de <em>PySpark</em>):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">IntegerType</span>
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">Tipos</p>
<p>Además de cadenas y enteros, flotantes (<code>FloatType</code>) o dobles (<code>DoubleType</code>), tenemos tipos booleanos (<code>BooleanType</code>), de fecha (DateType y TimestampType), así como tipos complejos como <code>ArrayType</code>, <code>MapType</code> y <code>StructType</code>.
Para más información, consultar la <a href="https://spark.apache.org/docs/latest/sql-ref-datatypes.html">documentación oficial</a>.</p>
</div>
<p>Volvamos al ejemplo anterior donde tenemos ciertos datos de clientes, como son su nombre y apellidos, ciudad y sueldo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">clientes</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos="2 "></span>    <span class="p">(</span><span class="s2">&quot;Aitor&quot;</span><span class="p">,</span> <span class="s2">&quot;Medrano&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">3000</span><span class="p">),</span>
<span class="linenos" data-linenos="3 "></span>    <span class="p">(</span><span class="s2">&quot;Pedro&quot;</span><span class="p">,</span> <span class="s2">&quot;Casas&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">4000</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>    <span class="p">(</span><span class="s2">&quot;Laura&quot;</span><span class="p">,</span> <span class="s2">&quot;García&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">5000</span><span class="p">),</span> 
<span class="linenos" data-linenos="5 "></span>    <span class="p">(</span><span class="s2">&quot;Miguel&quot;</span><span class="p">,</span> <span class="s2">&quot;Ruiz&quot;</span><span class="p">,</span> <span class="s2">&quot;Torrellano&quot;</span><span class="p">,</span> <span class="mi">6000</span><span class="p">),</span>
<span class="linenos" data-linenos="6 "></span>    <span class="p">(</span><span class="s2">&quot;Isabel&quot;</span><span class="p">,</span> <span class="s2">&quot;Guillén&quot;</span><span class="p">,</span> <span class="s2">&quot;Alicante&quot;</span><span class="p">,</span> <span class="mi">7000</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="p">]</span>
</code></pre></div>
<p>Para esta estructura, definiremos un esquema con los campos, indicando para cada uno de ellos su nombre, tipo y si admite valores nulos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">esquema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
<span class="linenos" data-linenos="2 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;nombre&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="3 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;apellidos&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;ciudad&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
<span class="linenos" data-linenos="5 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;sueldo&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="p">])</span>
</code></pre></div>
<p>A continuación ya podemos crear un <em>DataFrame</em> con datos propios que cumplen un esquema haciendo uso del método <code>createDataFrame</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clientes</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">esquema</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># root</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1">#  |-- nombre: string (nullable = false)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1">#  |-- apellidos: string (nullable = false)</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1">#  |-- ciudad: string (nullable = true)</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1">#  |-- sueldo: integer (nullable = false)</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |nombre|apellidos|ciudad    |sueldo|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |Aitor |Medrano  |Elche     |3000  |</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |Pedro |Casas    |Elche     |4000  |</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |Laura |García   |Elche     |5000  |</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |Miguel|Ruiz     |Torrellano|6000  |</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |Isabel|Guillén  |Alicante  |7000  |</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># +------+---------+----------+------+</span>
</code></pre></div>
<p>Si lo que queremos es asignarle un esquema a un <em>DataFrame</em> que vamos a leer desde una fuente de datos externa, hemos de emplear el método <code>schema</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfClientes</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">esquema</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;clientes.csv&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="admonition tip">
<p class="admonition-title">Rendimiento y esquema</p>
<p>La inferencia de los tipos de los datos es un proceso computacionalmente costoso. Por ello, si nuestro conjunto de datos es grande, es muy recomendable crear el esquema de forma programativa y configurarlo en la carga de datos.</p>
<p>Se recomienda la lectura del artículo <a href="https://t-redactyl.io/blog/2020/08/using-schemas-to-speed-up-reading-into-spark-dataframes.html">Using schemas to speed up reading into Spark DataFrames</a>.</p>
</div>
<p>Respecto al esquema, tenemos diferentes propiedades como <code>columns</code>, <code>dtypes</code> y <code>schema</code> con las que obtener su información:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># [&#39;nombre&#39;, &#39;apellidos&#39;, &#39;ciudad&#39;, &#39;sueldo&#39;]</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># [(&#39;nombre&#39;, &#39;string&#39;),</span>
<span class="linenos" data-linenos="5 "></span><span class="c1">#  (&#39;apellidos&#39;, &#39;string&#39;),</span>
<span class="linenos" data-linenos="6 "></span><span class="c1">#  (&#39;ciudad&#39;, &#39;string&#39;),</span>
<span class="linenos" data-linenos="7 "></span><span class="c1">#  (&#39;sueldo&#39;, &#39;int&#39;)]</span>
<span class="linenos" data-linenos="8 "></span><span class="n">df</span><span class="o">.</span><span class="n">schema</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># StructType(List(StructField(nombre,StringType,false),StructField(apellidos,StringType,false),StructField(ciudad,StringType,true),StructField(sueldo,IntegerType,false)))</span>
</code></pre></div>
<p>Si una vez hemos cargado un <em>DataFrame</em> queremos cambiar el tipo de una de sus columnas, podemos hacer uso del método <code>withColumn</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="c1"># Forma larga</span>
<span class="linenos" data-linenos="2 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">DoubleType</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;sueldo&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">sueldo</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">DoubleType</span><span class="p">())</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># Forma corta</span>
<span class="linenos" data-linenos="5 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;sueldo&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">sueldo</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">))</span>
<span class="linenos" data-linenos="6 "></span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># df = df.withColumn(&quot;fnac&quot;, to_date(df.Date, &quot;M/d/yyy&quot;))</span>
</code></pre></div>
<h2 id="dataframe-api">DataFrame API<a class="headerlink" href="#dataframe-api" title="Permanent link">&para;</a></h2>
<p>Una vez tenemos un <em>DataFrame</em> podemos trabajar con los datos mediante un conjunto de operaciones estructuradas, muy similares al lenguaje relacional. Estas operaciones también se clasifican en transformaciones y acciones, recordando que las transformaciones utilizan una evaluación perezosa.</p>
<p>Es muy importante tener en cuenta que todas las operaciones que vamos a realizar a continuación son immutables, es decir, nunca van a modificar el <em>DataFrame</em> sobre el que realizamos la transformación. Así pues, realizaremos encadenamiento de transformaciones (<em>transformation chaining</em>) o asignaremos el resultado a un nuevo <em>DataFrame</em>.</p>
<div class="admonition tip">
<p class="admonition-title">Preparación</p>
<p>Para los siguientes apartados, vamos a trabajar sobre el siguiente <em>DataFrame</em> con el fichero de <a href="../recursos/pdi/pdi_sales_small.csv">ventas</a> que hemos utilizado a lo largo del curso:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;s8a-dataframes-api&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># Lectura de CSV con el ; como separador de columnas y con encabezado</span>
<span class="linenos" data-linenos="5 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;pdi_sales_small.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<p>El esquema generado es:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>root
<span class="linenos" data-linenos="2 "></span>|-- ProductID: integer (nullable = true)
<span class="linenos" data-linenos="3 "></span>|-- Date: string (nullable = true)
<span class="linenos" data-linenos="4 "></span>|-- Zip: string (nullable = true)
<span class="linenos" data-linenos="5 "></span>|-- Units: integer (nullable = true)
<span class="linenos" data-linenos="6 "></span>|-- Revenue: double (nullable = true)
<span class="linenos" data-linenos="7 "></span>|-- Country: string (nullable = true)
</code></pre></div>
</div>
<h3 id="proyectando">Proyectando<a class="headerlink" href="#proyectando" title="Permanent link">&para;</a></h3>
<p>La operación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.select.html">select</a> permite indicar las columnas a recuperar pasándolas como parámetros:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">Consulta de columnas</label><label for="__tabbed_3_2">Resultado</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>+---------+-------+
<span class="linenos" data-linenos="2 "></span>|ProductID|Revenue|
<span class="linenos" data-linenos="3 "></span>+---------+-------+
<span class="linenos" data-linenos="4 "></span>|      725|  115.5|
<span class="linenos" data-linenos="5 "></span>|      787|  314.9|
<span class="linenos" data-linenos="6 "></span>|      788|  314.9|
<span class="linenos" data-linenos="7 "></span>+---------+-------+
<span class="linenos" data-linenos="8 "></span>only showing top 3 rows
</code></pre></div>
</div>
</div>
</div>
<p>También podemos realizar cálculos (referenciando a los campos con <code>nombreDataframe.nombreColumna</code>) sobre las columnas y crear un alias (operación asociada a un campo):</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">Cálculos y creación de alias</label><label for="__tabbed_4_2">Resultado</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">ProductID</span><span class="p">,(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;VentasMas10&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>+---------+-----------+
<span class="linenos" data-linenos="2 "></span>|ProductID|VentasMas10|
<span class="linenos" data-linenos="3 "></span>+---------+-----------+
<span class="linenos" data-linenos="4 "></span>|      725|      125.5|
<span class="linenos" data-linenos="5 "></span>|      787|      324.9|
<span class="linenos" data-linenos="6 "></span>|      788|      324.9|
<span class="linenos" data-linenos="7 "></span>+---------+-----------+
<span class="linenos" data-linenos="8 "></span>only showing top 3 rows
</code></pre></div>
</div>
</div>
</div>
<p>Si tenemos un <em>DataFrame</em> con un gran número de columnas y queremos recuperarlas todas a excepción de unas pocas, es más cómodo utilizar la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.drop.html">drop</a>, la cual funciona de manera opuesta a <code>select</code>, es decir, indicando las columnas que queremos quitar del resultado:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="c1"># Obtenemos el mismo resultado</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span> <span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="s2">&quot;Zip&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span><span class="p">,</span> <span class="s2">&quot;Country&quot;</span><span class="p">)</span>
</code></pre></div>
<h3 id="trabajando-con-columnas">Trabajando con columnas<a class="headerlink" href="#trabajando-con-columnas" title="Permanent link">&para;</a></h3>
<p>Para acceder a las columnas, debemos crear objetos <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.html">Column</a>. Para ello, podemos seleccionarlos a partir de un <em>DataFrame</em> como una propiedad o mediante la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.col.html">col</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">nomCliente</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">nombre</span>
<span class="linenos" data-linenos="2 "></span><span class="n">nomCliente</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ProductID&quot;</span><span class="p">]</span>
<span class="linenos" data-linenos="3 "></span><span class="n">nomCliente</span> <span class="o">=</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Así pues, podemos recuperar ciertas columnas de un DataFrame con cualquier de las siguientes expresiones:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">ProductID</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="5 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;ProductID&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Revenue&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="6 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h4 id="col-vs-expr">col vs expr<a class="headerlink" href="#col-vs-expr" title="Permanent link">&para;</a></h4>
<p>En ocasiones se confunde el uso de la función <code>col</code> con <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.expr.html">expr</a>. Aunque podemos referenciar a una columna haciendo uso de <code>expr</code>, su uso provoca que se parseé la cadena recibida para interpretarla.</p>
<p>Para el siguiente ejemplo, supongamos que tenemos un <em>DataFrame</em> con datos de clientes. Utilizaremos también la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.concat_ws.html">concat_ws</a> para concatenar textos utilizado un separador.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span><span class="n">expr</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">concat_ws</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;nombre&quot;</span><span class="p">),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;apellidos&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;nombreCompleto&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>          <span class="s2">&quot;sueldo&quot;</span><span class="p">,</span>
<span class="linenos" data-linenos="5 "></span>          <span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;sueldo&quot;</span><span class="p">)</span><span class="o">*</span><span class="mf">1.1</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;nuevoSueldo&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> 
<span class="linenos" data-linenos="6 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">concat_ws</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;nombre&quot;</span><span class="p">),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;apellidos&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;nombreCompleto&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="7 "></span>          <span class="s2">&quot;sueldo&quot;</span><span class="p">,</span>
<span class="linenos" data-linenos="8 "></span>          <span class="n">expr</span><span class="p">(</span><span class="s2">&quot;sueldo*1.1&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;nuevoSueldo&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> 
</code></pre></div>
<h4 id="anadiendo-columnas">Añadiendo columnas<a class="headerlink" href="#anadiendo-columnas" title="Permanent link">&para;</a></h4>
<p>Una vez tenemos un <em>DataFrame</em>, podemos añadir columnas mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.withColumn.html">withColumn</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">dfNuevo</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;total&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">Units</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">dfNuevo</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country| total|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |      725|1999-01-15|41540          |    1|  115.5|Germany| 115.5|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      787|2002-06-06|41540          |    1|  314.9|Germany| 314.9|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |      788|2002-06-06|41540          |    1|  314.9|Germany| 314.9|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      901|1999-02-15|13587          |    2|  818.9|Germany|1637.8|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># ...</span>
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">withColumn</p>
<p>Anteriormente hemos utilizado el método <code>withColumn</code> para cambiarle el tipo a un campo ya existente. Así pues, si referenciamos a una columna que ya existe, en vez de crearla, la sustituirá.</p>
</div>
<p>Otra forma de añadir una columna con una expresión es mediante la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.selectExpr.html"><code>selectExpr</code></a>. Por ejemplo, podemos conseguir el mismo resultado que en el ejemplo anterior de la siguiente manera:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="s2">&quot;Units * Revenue as total&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span><span class="err">`</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country| total|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |      725|1999-01-15|41540          |    1|  115.5|Germany| 115.5|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |      787|2002-06-06|41540          |    1|  314.9|Germany| 314.9|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># |      788|2002-06-06|41540          |    1|  314.9|Germany| 314.9|</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># |      901|1999-02-15|13587          |    2|  818.9|Germany|1637.8|</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># ...</span>
</code></pre></div>
<p>Aunque más adelante veremos como realizar transformaciones con agregaciones, mediante <code>selectExpr</code> también podemos realizar analítica de datos aprovechando la potencia de SQL:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;count(distinct(ProductID)) as productos&quot;</span><span class="p">,</span><span class="s2">&quot;count(distinct(Country)) as paises&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------+------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |productos|paises|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------+------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |      799|     4|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># +---------+------+</span>
</code></pre></div>
<h4 id="cambiando-el-nombre">Cambiando el nombre<a class="headerlink" href="#cambiando-el-nombre" title="Permanent link">&para;</a></h4>
<p>Si por algún extraño motivo necesitamos cambiarle el nombre a una columna (por ejemplo, vamos a unir dos <em>DataFrames</em> que tienen columnas con el mismo nombre pero en posiciones diferentes, o que al inferir el esquema tenga un nombre críptico o demasiado largo y queremos que sea más legible) podemos utilizar la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.withColumnRenamed.html">withColumnRenamed</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">,</span> <span class="s2">&quot;PostalCode&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |ProductID|      Date|     PostalCode|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      725|1999-01-15|41540          |    1|  115.5|Germany|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |      787|2002-06-06|41540          |    1|  314.9|Germany|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      788|2002-06-06|41540          |    1|  314.9|Germany|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |      940|1999-01-15|22587          |    1|  687.7|Germany|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      396|1999-01-15|22587          |    1|  857.1|Germany|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># only showing top 5 rows</span>
</code></pre></div>
<h3 id="filtrando">Filtrando<a class="headerlink" href="#filtrando" title="Permanent link">&para;</a></h3>
<p>Si queremos eliminar filas, usaremos el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.filter.html">filter</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="o">==</span><span class="s2">&quot;Germany&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |      725|1999-01-15|41540          |    1|  115.5|Germany|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |      787|2002-06-06|41540          |    1|  314.9|Germany|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># |      788|2002-06-06|41540          |    1|  314.9|Germany|</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># |      940|1999-01-15|22587          |    1|  687.7|Germany|</span>
</code></pre></div>
<p>Por similitud con SQL, podemos utilizar también <code>where</code> como un alias de <code>filter</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="o">&gt;</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      495|1999-03-15|75213 CEDEX 16 |   77|43194.1| France|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     2091|1999-05-15|9739           |   24| 3652.7| Mexico|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     2091|1999-06-15|40213          |   41| 6240.1|Germany|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |     2091|1999-10-15|40213          |   41| 6347.7|Germany|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     2091|1999-12-15|40213          |   23| 3560.9|Germany|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
</code></pre></div>
<p>Podemos utilizar los operadores lógicos (<code>&amp;</code> para conjunción y <code>|</code> para la disyunción) para crear condiciones compuestas (recordad rodear cada condición entre paréntesis):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">((</span><span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="o">==</span><span class="s2">&quot;Germany&quot;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="o">&gt;</span><span class="mi">20</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |     2091|1999-06-15|40213          |   41| 6240.1|Germany|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     2091|1999-10-15|40213          |   41| 6347.7|Germany|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     2091|1999-12-15|40213          |   23| 3560.9|Germany|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">((</span><span class="n">df</span><span class="o">.</span><span class="n">ProductID</span><span class="o">==</span><span class="mi">2314</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">ProductID</span><span class="o">==</span><span class="mi">1322</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |     2314|1999-05-15|46045          |    1|   13.9|Germany|</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |     1322|2000-01-06|75593 CEDEX 12 |    1|  254.5| France|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
</code></pre></div>
<p>Un caso particular de filtrado es la eliminación de los registros repetidos, lo cual lo podemos hacer de dos maneras:</p>
<ul>
<li>Haciendo uso del método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.distinct.html">distinct</a> tras haber realizado alguna transformación</li>
<li>Utilizando <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.dropDuplicates.html">dropDuplicates</a> sobre un <em>DataFrame</em>:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">dropDuplicates</span><span class="p">([</span><span class="s2">&quot;Country&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +-------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |Country|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Germany|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | France|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># | Mexico|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># | Canada|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+</span>
</code></pre></div>
<h3 id="ordenando">Ordenando<a class="headerlink" href="#ordenando" title="Permanent link">&para;</a></h3>
<p>Una vez recuperados los datos deseados, podemos ordenarlos mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sort.html">sort</a> u <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.orderBy.html">orderBy</a> (son operaciones totalmente equivalentes):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">.</span><span class="n">asc</span><span class="p">())</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># Ordenación descendiente</span>
<span class="linenos" data-linenos=" 7 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">.</span><span class="n">desc</span><span class="p">())</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 9 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">desc</span>
<span class="linenos" data-linenos="10 "></span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># Ordenación diferente en cada columna</span>
<span class="linenos" data-linenos="12 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">.</span><span class="n">desc</span><span class="p">(),</span> <span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="o">.</span><span class="n">asc</span><span class="p">())</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos="13 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">([</span><span class="s2">&quot;Revenue&quot;</span><span class="p">,</span><span class="s2">&quot;Units&quot;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<p>Por ejemplo, con la última operación obtendríamos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>+---------+----------+---------------+-----+-------+-------+
<span class="linenos" data-linenos=" 2 "></span>|ProductID|      Date|            Zip|Units|Revenue|Country|
<span class="linenos" data-linenos=" 3 "></span>+---------+----------+---------------+-----+-------+-------+
<span class="linenos" data-linenos=" 4 "></span>|      495|1999-03-15|75213 CEDEX 16 |   77|43194.1| France|
<span class="linenos" data-linenos=" 5 "></span>|      495|2000-03-01|75391 CEDEX 08 |   18|10395.0| France|
<span class="linenos" data-linenos=" 6 "></span>|      464|2003-06-11|75213 CEDEX 16 |   16|10075.8| France|
<span class="linenos" data-linenos=" 7 "></span>|      464|2000-08-01|22397          |   17| 9817.5|Germany|
<span class="linenos" data-linenos=" 8 "></span>|      495|2000-03-01|06175 CEDEX 2  |   16| 9240.0| France|
<span class="linenos" data-linenos=" 9 "></span>+---------+----------+---------------+-----+-------+-------+
<span class="linenos" data-linenos="10 "></span>only showing top 5 rows
</code></pre></div>
<p>Normalmente, tras realizar una ordenación, es habitual quedarse con un subconjunto de los datos. Para ello, podemos utilizar la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.limit.html">limit</a>.</p>
<p>Por ejemplo, la siguiente transformación es similar al ejemplo anterior, sólo que ahora al driver únicamente le llegan 5 registros, en vez de traerlos todos y sólo mostrar 5:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">.</span><span class="n">desc</span><span class="p">(),</span> <span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="o">.</span><span class="n">asc</span><span class="p">())</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h3 id="anadiendo-filas">Añadiendo filas<a class="headerlink" href="#anadiendo-filas" title="Permanent link">&para;</a></h3>
<p>La única manera de añadir filas a un <em>DataFrame</em> es creando uno nuevo que sea el resultado de unir dos <em>DataFrames</em> que compartan el mismo esquema (mismo nombres de columnas y en el mismo orden). Para ello, utilizaremos la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.union.html">union</a> que realiza la unión por el orden de las columnas:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">nuevasVenta</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos="2 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-24&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mf">3333.33</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="3 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-25&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mf">2222.22</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span><span class="p">]</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># Creamos un nuevo DataFrame con las nuevas Ventas</span>
<span class="linenos" data-linenos="6 "></span><span class="n">nvDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">nuevasVenta</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># Unimos los dos DataFrames</span>
<span class="linenos" data-linenos="8 "></span><span class="n">dfUpdated</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">nvDF</span><span class="p">)</span>
</code></pre></div>
<h3 id="cogiendo-muestras">Cogiendo muestras<a class="headerlink" href="#cogiendo-muestras" title="Permanent link">&para;</a></h3>
<p>Si necesitamos recoger un subconjunto de los datos, ya sea para preparar los datos para algún modelo de <em>machine learning</em> como para una muestra aleatoria de los mismos, podemos utilizar las siguientes transformaciones:</p>
<ul>
<li>
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sample.html">sample</a> permite obtener una muestra a partir de un porcentaje (no tiene porqué obtener una cantidad exacta). También admite un semilla e indicar si queremos que pueda repetir los datos.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>                  <span class="c1"># 120239</span>
<span class="linenos" data-linenos="2 "></span><span class="n">muestra</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mf">0.10</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">muestra</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>             <span class="c1"># 11876</span>
<span class="linenos" data-linenos="4 "></span><span class="n">muestraConRepetidos</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">)</span>
<span class="linenos" data-linenos="5 "></span><span class="n">muestraConRepetidos</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="c1"># 11923</span>
</code></pre></div>
</li>
<li>
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.randomSplit.html">randomSplit</a> recupera diferentes <em>DataFrames</em> cuyos tamaños en porcentaje se indican como parámetros (si no suman uno, los parámetros se normalizan):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfs</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">randomSplit</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfEntrenamiento</span> <span class="o">=</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfPrueba</span> <span class="o">=</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos" data-linenos="4 "></span><span class="n">dfEntrenamiento</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>     <span class="c1"># 96194</span>
<span class="linenos" data-linenos="5 "></span><span class="n">dfPrueba</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>            <span class="c1"># 24045</span>
</code></pre></div>
</li>
</ul>
<!--
* [sampleBy](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sampleBy.html)
-->

<h2 id="trabajando-con-datos-sucios">Trabajando con datos sucios<a class="headerlink" href="#trabajando-con-datos-sucios" title="Permanent link">&para;</a></h2>
<p>Hay tres formas de gestionar la suciedad de los datos o la omisión completa de los mismos:</p>
<ol>
<li>Eliminar las filas que tienen valores vacíos en una o más columnas.</li>
<li>Rellenar los valores nulos con valores que definimos nosotros.</li>
<li>Sustituir los datos erróneos por algún valor que sepamos como gestionarlo.</li>
</ol>
<p>Vamos a ver cada uno de estos casos a partir del siguiente <em>dataset</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">malasVentas</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-22&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mf">3333.33</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-22&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mf">3333.33</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-23&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mf">2222.22</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-24&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Espain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span><span class="p">]</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">malDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">malasVentas</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span> <span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="s2">&quot;Zip&quot;</span><span class="p">,</span> <span class="s2">&quot;Units&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span> <span class="p">,</span> <span class="s2">&quot;Country&quot;</span><span class="p">])</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |     6666|2022-03-22| null|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null| Espain|</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># |     6666|2022-03-25|03206| null|2222.22|   null|</span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
</code></pre></div>
<p>Si queremos saber si una columna contiene nulos, podemos hacer un filtrado utilizando el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.isNull.html">isNull</a> sobre los campos deseados (también podemos utilizar <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.isNotNull.html">isNotNull</a> si queremos el caso contrario):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">malDF</span><span class="o">.</span><span class="n">Zip</span><span class="o">.</span><span class="n">isNull</span><span class="p">())</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------+----------+----+-----+-------+-------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |ProductID|      Date| Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------+----------+----+-----+-------+-------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |     6666|2022-03-22|null|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># +---------+----------+----+-----+-------+-------+</span>
</code></pre></div>
<p>Para trabajar con las filas que contengan algún dato nulo, podemos acceder a la propiedad <code>na</code>, la cual devuelve un <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameNaFunctions.html">DataFrameNaFunctions</a> sobre la que podemos indicarle:</p>
<ul>
<li>
<p>que la elimine mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameNaFunctions.drop.html"><code>drop</code></a> / <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.dropna.html"><code>dropna</code></a>. Puede recibir <code>"any"</code> (borrará las filas que contengan algún nulo) o <code>"all"</code> (borrará las filas que todas sus columnas contengan nulos) y una lista con las columnas a considerar:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># Elimina todos los nulos</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># Elimina las filas que todas sus columnas son nulas</span>
<span class="linenos" data-linenos="10 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |     6666|2022-03-22| null|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null| Espain|</span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span><span class="c1"># Elimina las filas que tienen el Zip nulo</span>
<span class="linenos" data-linenos="21 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Zip&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="22 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="23 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="24 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="25 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="26 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos="27 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null| Espain|</span>
<span class="linenos" data-linenos="28 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
</code></pre></div>
<p>También podemos indicar la cantidad de nulos que ha de contener cada fila para eliminarla mediante el parámetro <code>thresh</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="c1"># Elimina las filas con 3 o más nulos</span>
<span class="linenos" data-linenos="2 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">thresh</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div>
</li>
<li>
<p>que la rellene mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameNaFunctions.fill.html"><code>fill</code></a> / <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.fillna.html"><code>fillna</code></a>, indicando el valor y si queremos, sobre qué columnas aplicar la modificación:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># Rellenamos los zips vacíos por 99999</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="s2">&quot;99999&quot;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Zip&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># malDF.na.fill(&quot;99999&quot;, [&quot;Zip&quot;]).show()</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># malDF.fillna({&quot;Zip&quot;: &quot;99999&quot;})</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     6666|2022-03-22|99999|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null| Espain|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |     null|      null|99999| null|   null|   null|</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
</code></pre></div>
</li>
<li>
<p>que la sustituya mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameNaFunctions.replace.html"><code>replace</code></a></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># Cambiamos Espain por Spain</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;Espain&quot;</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     6666|2022-03-22| null|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null|  Spain|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |     null|      null| null| null|   null|   null|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
</code></pre></div>
</li>
</ul>
<p>Otro caso muy común es realizar una operación sobre una columna para transformar su valor, por ejemplo, pasar todo el texto a minúsculas o dividir una columna entre 100 para cambiar la escala.</p>
<p>En nuestro caso, vamos a modificar las columnas <em>Zip</em> y <em>Country</em> para realizar un <code>trim</code> y borrar los espacios en blanco:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">trim</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">,</span> <span class="n">trim</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)))</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">,</span> <span class="n">trim</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">)))</span>
</code></pre></div>
<h2 id="usando-sql">Usando SQL<a class="headerlink" href="#usando-sql" title="Permanent link">&para;</a></h2>
<p>En la era del big data, SQL es la lengua franca, permitiendo a perfiles con pocos conocimientos de programación trabajar de forma eficiente con los datos (siempre poniendo el foco en la analítica de datos, no en el procesamiento transaccional).</p>
<p>Spark soporta el ANSI SQL 2003, ampliamente establecido en el mundo de las bases de datos.</p>
<p>Para correr SQL en Spark podemos hacerlo a través de:</p>
<ul>
<li>El cliente SQL, es cual se ofrece como un comando en <code>./bin/spark-sql</code></li>
<li>Mediante un servidor ODBC/JDBC</li>
<li>De forma programativa mediante aplicaciones <em>Spark</em>.</li>
</ul>
<p>Las dos primeras opciones se integran con <em>Apache Hive</em> para utilizar su metastore. Ahora nos vamos a centrar en la última.</p>
<h3 id="vistas-temporales">Vistas temporales<a class="headerlink" href="#vistas-temporales" title="Permanent link">&para;</a></h3>
<p>Ya hemos visto que los <em>DataFrames</em> tienen una estructura similar a una tabla de una base de datos relacional. Para poder realizar consultas, necesitaremos crear vistas temporales mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.createOrReplaceTempView.html"><code>createOrReplaceTempView</code></a> para posteriormente realizar una consulta sobre la vista creada a través de <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.sql.html"><code>spark.sql</code></a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># 1. definimos la vista</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;ventas&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># 2. realizamos la consulta</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">ventasCanada</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select * from ventas where trim(Country)=&#39;Canada&#39;&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">ventasCanada</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |ProductID|     Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      725|1/15/1999|H1B            |    1|  115.4|Canada |</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |     2235|1/15/1999|H1B            |    2|  131.1|Canada |</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |      713|1/15/1999|H1B            |    1|  160.1|Canada |</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># only showing top 3 rows</span>
</code></pre></div>
<h3 id="vistas-globales">Vistas globales<a class="headerlink" href="#vistas-globales" title="Permanent link">&para;</a></h3>
<p>Las vistas temporales tienen un alcance de <em>SparkSession</em>, de manera que desaparecen una vez finalice la sesión que ha creado la vista. Si necesitamos tener una vista que se comparta entre todas las sesiones y que permanezca viva hasta que la aplicación <em>Spark</em> finalice, podemos crear una vista temporal global.</p>
<p>Estas vistas se almacenan en la base de datos <code>global_temp</code> y en las consultas es necesario poner el prefijo <code>global_temp</code> para acceder a la sus vistas.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># 1. definimos la vista global</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceGlobalTempView</span><span class="p">(</span><span class="s2">&quot;ventasg&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># 2. realizamos la consulta</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">ventasCanadaG</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select * from global_temp.ventasg where trim(Country)=&#39;Canada&#39;&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">ventasCanadaG</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |ProductID|     Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      725|1/15/1999|H1B            |    1|  115.4|Canada |</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |     2235|1/15/1999|H1B            |    2|  131.1|Canada |</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |      713|1/15/1999|H1B            |    1|  160.1|Canada |</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># only showing top 3 rows</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># Creamos otra sesión y vemos como funciona</span>
<span class="linenos" data-linenos="16 "></span><span class="n">spark</span><span class="o">.</span><span class="n">newSession</span><span class="p">()</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select count(*) from global_temp.ventasg where trim(Country)=&#39;Canada&#39;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h3 id="tablas">Tablas<a class="headerlink" href="#tablas" title="Permanent link">&para;</a></h3>
<p>Spark permite crear bases de datos y tablas y almacenar los datos y metadatos en estructuras similares a como lo realiza Hive en un <em>metastore</em> central. De esta manera, vamos a poder crear tablas gestionadas y no gestionadas.</p>
<p>Para organizar las tablas y las vistas, es recomendable crear una base de datos. De la misma manera que hemos creado sentencias SQL, podemos generar sentencias DML:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;create database if not exists s8a&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;use database s8a&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Si queremos consultar las bases de datos existentes podemos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listDatabases</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># [Database(name=&#39;default&#39;, description=&#39;Default Hive database&#39;, locationUri=&quot;file:...spark-warehouse&quot;),</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1">#  Database(name=&#39;s8a&#39;, description=&#39;&#39;, locationUri=&quot;file:.../spark-warehouse/s8a.db&quot;)]</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;show databases&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |namespace|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># +---------+</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |  default|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      s8a|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+</span>
</code></pre></div>
<p>A continuación, podemos crear una tabla gestionada mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameWriter.saveAsTable.html"><code>saveAsTable</code></a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s2">&quot;ventast&quot;</span><span class="p">)</span>
</code></pre></div>
<p>De manera que podemos comprobar su estructura con SQL:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;describe table ventast&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+---------+-------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># | col_name|data_type|comment|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+---------+-------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |ProductID|      int|   null|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     Date|   string|   null|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      Zip|   string|   null|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |    Units|      int|   null|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |  Revenue|   double|   null|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |  Country|   string|   null|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +---------+---------+-------+</span>
</code></pre></div>
<p>Si queremos crear una tabla no gestionada, también conocida como tabla externa, necesitamos indicar la ruta de los datos en el momento de creación:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;CREATE TABLE ventase(ProductID INT, Date STRING, </span>
<span class="linenos" data-linenos="2 "></span><span class="s2">  Zip STRING, Units INT, Revenue DOUBLE, Country STRING) </span>
<span class="linenos" data-linenos="3 "></span><span class="s2">  USING csv OPTIONS (PATH </span>
<span class="linenos" data-linenos="4 "></span><span class="s2">  &#39;/pdi_sales_small.csv&#39;)&quot;&quot;&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Para ello, necesitamos colocar el archivo de datos dentro del almacén de <em>metastore</em>, que en nuestro caso es <code>spark-warehouse/s8a.db/</code></p>
<p>También podemos crear la tabla indicando la <a href="https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html#saving-to-persistent-tables">opción <code>path</code></a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;path&quot;</span><span class="p">,</span> <span class="s2">&quot;/tmp/datos/ventas&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s2">&quot;ventaset&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Internamente, podemos configurar <em>Spark</em> para trabajar con <em>Hive</em> como motor de almacenamiento. Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html">documentación oficial</a>.</p>
<h2 id="trabajando-con-databricks">Trabajando con <em>Databricks</em><a class="headerlink" href="#trabajando-con-databricks" title="Permanent link">&para;</a></h2>
<p>En la sesión anterior ya vimos como crear RDDs con <em>Databricks</em>. En esta ocasión, vamos a trabajar mediante <em>DataFrames</em> y SQL para ver toda la flexibilidad que nos aporta.</p>
<p>Una vez creado de nuevo el cluster, vamos a cargar los datos mediante la opción <em>Data</em>, subiendo el archivo <a href="../recursos/spark/pdi_sales_small.csv"><code>pdi_sales_small.csv</code></a>:</p>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-databricks-upload.png">
    <figcaption>Subiendo datos a Databricks</figcaption>
</figure>

<p>Una vez cargado el archivo, pulsamos sobre el botón <strong><em>Create table in notebook</em></strong> de manera que nos crea un cuaderno Jupyter donde podemos consultar los datos y crear una vista temporal:</p>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-databricks-read.png">
    <figcaption>Cargados los datos en un DataFrame</figcaption>
</figure>

<p>Para que funcione correctamente con nuestro datos, vamos a modificar el código:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">infer_schema</span> <span class="o">=</span> <span class="s2">&quot;true&quot;</span>
<span class="linenos" data-linenos="2 "></span><span class="n">first_row_is_header</span> <span class="o">=</span> <span class="s2">&quot;true&quot;</span>
<span class="linenos" data-linenos="3 "></span><span class="n">delimiter</span> <span class="o">=</span> <span class="s2">&quot;;&quot;</span>
</code></pre></div>
<p>Y tras cargar el dataset, antes de crear la vista, vamos a limpiar los países:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">trim</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">,</span> <span class="n">trim</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="p">))</span>
</code></pre></div>
<h3 id="datos-visuales">Datos visuales<a class="headerlink" href="#datos-visuales" title="Permanent link">&para;</a></h3>
<p>Si volvemos a ejecutar el cuaderno, ahora sí que cargará correctamente los datos. Si nos vamos a la celda que realiza una consulta sobre todos los datos, podemos ver en la parte superior derecha como el lenguaje empleado en la celda es SQL, por ello la primera línea comienza con <code>%sql</code>, y a continuación ya podemos introducir directamente código SQL, teniendo la opción de visualizar los datos tanto en modo texto como mediante gráficos:</p>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-databricks-sql.gif">
    <figcaption>Datos y gráficos mediante SQL</figcaption>
</figure>

<h3 id="cuadro-de-mandos">Cuadro de mandos<a class="headerlink" href="#cuadro-de-mandos" title="Permanent link">&para;</a></h3>
<p>Además, con las tablas y/o gráficos que generamos dentro de <em>Databricks</em>, podemos generar un sencillo cuadro de mandos.</p>
<p>Vamos a crear un par de consultas, una para obtener las ventas medias por país:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="o">%</span><span class="k">sql</span><span class="w"></span>
<span class="linenos" data-linenos="2 "></span><span class="k">select</span><span class="w"> </span><span class="n">Country</span><span class="p">,</span><span class="w"> </span><span class="k">avg</span><span class="p">(</span><span class="n">Revenue</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">ventas</span><span class="w"></span>
<span class="linenos" data-linenos="3 "></span><span class="k">from</span><span class="w"> </span><span class="n">pdi_sales_small_csv</span><span class="w"></span>
<span class="linenos" data-linenos="4 "></span><span class="k">group</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="n">Country</span><span class="w"></span>
<span class="linenos" data-linenos="5 "></span><span class="k">order</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="n">ventas</span><span class="w"> </span><span class="k">desc</span><span class="w"></span>
</code></pre></div>
<p>Y otra para las unidas pedidas por cada país:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="o">%</span><span class="k">sql</span><span class="w"></span>
<span class="linenos" data-linenos="2 "></span><span class="k">select</span><span class="w"> </span><span class="n">Country</span><span class="p">,</span><span class="w"> </span><span class="k">sum</span><span class="p">(</span><span class="n">Units</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">pedidos</span><span class="w"></span>
<span class="linenos" data-linenos="3 "></span><span class="k">from</span><span class="w"> </span><span class="n">pdi_sales_small_csv</span><span class="w"></span>
<span class="linenos" data-linenos="4 "></span><span class="k">group</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="n">Country</span><span class="w"></span>
<span class="linenos" data-linenos="5 "></span><span class="k">order</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="n">pedidos</span><span class="w"> </span><span class="k">desc</span><span class="w"></span>
</code></pre></div>
<p>Si pulsamos sobre el icono del gráfico de barras de la esquina superior derecha de una celda SQL, podemos añadir el resultado de la celda a un <em>dashboard</em>:</p>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-databricks-dashboard.gif">
    <figcaption>Creando un cuadro de mandos</figcaption>
</figure>

<p>Una vez creado, sólo tenemos que seleccionar las celdas que queramos, e ir añadiéndolas al cuadro de mandos creado. Posteriormente, podemos abrirlo, resituar los elementos y visualizarlo:</p>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-databricks-dashboard2.gif">
    <figcaption>Añadiendo elementos a un cuadro de mandos</figcaption>
</figure>

<h2 id="agregaciones">Agregaciones<a class="headerlink" href="#agregaciones" title="Permanent link">&para;</a></h2>
<p>Una vez tenemos un DataFrame, podemos realizar analítica de datos sobre el <em>dataset</em> entero, o sobre una o más columnas y aplicar una función de agregación que permita sumar, contar o calcular la media de cualquier grupo, entre otras opciones.</p>
<p>Para ello, <em>PySpark</em> ofrece un amplio <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions">conjunto de funciones</a>. En nuestro caso, vamos a realizar algunos ejemplos para practicar con las funciones más empleadas.</p>
<h3 id="contando">Contando<a class="headerlink" href="#contando" title="Permanent link">&para;</a></h3>
<div class="tabbed-set tabbed-alternate" data-tabs="5:3"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><input id="__tabbed_5_3" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">count</label><label for="__tabbed_5_2">count_distinct</label><label for="__tabbed_5_3">approx_count_distinct</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.count.html">count</a>: Devuelve la cantidad de elementos no nulos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">count</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +--------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |count(Country)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +--------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |        120239|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +--------------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.count_distinct.html">count_distinct / countDistinct</a>: Devuelve la cantidad de elementos no nulos diferentes:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">count_distinct</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">count_distinct</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">),</span> <span class="n">count_distinct</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +-----------------------+-------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |count(DISTINCT Country)|count(DISTINCT Zip)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +-----------------------+-------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |                      4|               2585|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +-----------------------+-------------------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.approx_count_distinct.html">approx_count_distinct / approxCountDistinct</a>: Devuelve aproximadamente la cantidad de elementos no nulos diferentes (puede recibir un segundo parámetro la máximo desviación estándar admitida). Este método es mucho más rápido que contar exactamente el número de resultado, y para datasets muy grandes, en ocasiones puede ser útil:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">approx_count_distinct</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">approx_count_distinct</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">),</span> <span class="n">approx_count_distinct</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +------------------------------+--------------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |approx_count_distinct(Country)|approx_count_distinct(Zip)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +------------------------------+--------------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |                             4|                      2737|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +------------------------------+--------------------------+</span>
</code></pre></div>
</div>
</div>
</div>
<h3 id="calculando">Calculando<a class="headerlink" href="#calculando" title="Permanent link">&para;</a></h3>
<div class="tabbed-set tabbed-alternate" data-tabs="6:4"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><input id="__tabbed_6_2" name="__tabbed_6" type="radio" /><input id="__tabbed_6_3" name="__tabbed_6" type="radio" /><input id="__tabbed_6_4" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">min y max</label><label for="__tabbed_6_2">sum</label><label for="__tabbed_6_3">sum_distinct</label><label for="__tabbed_6_4">avg</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.min.html">min</a> y <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.max.html">max</a> permiten obtener el menor y el mayor valor respectivamente:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +----------+----------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |min(Units)|max(Units)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +----------+----------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |         1|        77|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +----------+----------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.sum.html">sum</a> permite sumar todos los valores de una columna:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">sum</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">),</span> <span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +----------+--------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |sum(Units)|        sum(Revenue)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +----------+--------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |    125728|5.0107274999986745E7|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +----------+--------------------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.sum_distinct.html">sum_distinct / sumDistinct</a> suma los valores diferentes de una columna:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">sum_distinct</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">sum_distinct</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">),</span> <span class="n">sum_distinct</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +-------------------+---------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |sum(DISTINCT Units)|sum(DISTINCT Revenue)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +-------------------+---------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |                308|   1189127.0999999985|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +-------------------+---------------------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.avg.html">avg</a> calcula la media aritmética:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">sum</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">avg</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">avg</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">),</span> <span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">/</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +-----------------+-------------------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |     avg(Revenue)|(sum(Revenue) / count(Revenue))|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +-----------------+-------------------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |416.7306364822291|              416.7306364822291|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +-----------------+-------------------------------+</span>
</code></pre></div>
</div>
</div>
</div>
<div class="admonition info">
<p class="admonition-title">Asimetría, varianza y desviación estándar</p>
<p>Si nos interesa obtener información estadística sobre los datos, también disponemos de las funciones <code>skewness</code>, <code>kurtosis</code>, <code>variance</code>, <code>var_pop</code>, <code>stddev</code> y <code>stddev_pop</code>.</p>
</div>
<h3 id="agrupando">Agrupando<a class="headerlink" href="#agrupando" title="Permanent link">&para;</a></h3>
<p>Si agrupamos varias columnas de tipo categóricas (con una cardinalidad baja), podemos realizar cálculos sobre el resto de columnas.</p>
<p>Sobre un <em>DataFrame</em>, podemos agrupar los datos por la columna que queramos utilizando el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.groupBy.html">groupBy</a>, el cual nos devuelve un <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.GroupedData.html#pyspark.sql.GroupedData">GroupedData</a>, sobre el que posteriormente realizar operaciones como <code>avg(cols)</code>, <code>count()</code>, <code>mean(cols)</code>, <code>min(cols)</code>, <code>max(cols)</code> o <code>sum(cols)</code>:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="7:2"><input checked="checked" id="__tabbed_7_1" name="__tabbed_7" type="radio" /><input id="__tabbed_7_2" name="__tabbed_7" type="radio" /><div class="tabbed-labels"><label for="__tabbed_7_1">count</label><label for="__tabbed_7_2">sum</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">sum</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +-------+-----+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |Country|count|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------+-----+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Germany|30059|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | France|30060|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># | Mexico|30060|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># | Canada|30060|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+-----+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">sum</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +-------+--------------------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |Country|        sum(Revenue)|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------+--------------------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Germany|1.4982119999999512E7|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | France|1.2087942100000832E7|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># | Mexico| 1.139459870000116E7|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># | Canada|1.1642614200001905E7|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+--------------------+</span>
</code></pre></div>
</div>
</div>
</div>
<p>Si necesitamos realizar más de un agregación sobre el mismo grupo, mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.GroupedData.agg.html">agg</a> podemos indicar una o más expresiones de columnas:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">),</span> <span class="n">count</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +-------+--------------------+--------------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |Country|        sum(Revenue)|count(Revenue)|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +-------+--------------------+--------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |Germany|1.4982119999999512E7|         30059|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># | France|1.2087942100000832E7|         30060|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># | Mexico| 1.139459870000116E7|         30060|</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># | Canada|1.1642614200001905E7|         30060|</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># +-------+--------------------+--------------+</span>
</code></pre></div>
<p>También podemos indicar los elementos a calcular mediante un diccionario donde las claves son los campos y los valores la función a calcular:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">&quot;Zip&quot;</span><span class="p">:</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span><span class="p">:</span><span class="s2">&quot;avg&quot;</span><span class="p">})</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +-------+----------+------------------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |Country|count(Zip)|      avg(Revenue)|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +-------+----------+------------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |Germany|     30059| 498.4237665923521|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># | France|     30060| 402.1271490352905|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># | Mexico|     30060| 379.0618330007039|</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># | Canada|     30060|387.31251497012323|</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># +-------+----------+------------------+</span>
</code></pre></div>
<h3 id="agrupando-colecciones">Agrupando colecciones<a class="headerlink" href="#agrupando-colecciones" title="Permanent link">&para;</a></h3>
<p>En ocasiones necesitamos agrupar en una colección todos los valores para un grupo en particular. Para ello, podemos usar <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.collect_list.html">collect_list</a> (con repetidos) o <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.collect_set.html">collect_set</a> (sin repeticiones):</p>
<p>Por ejemplo, para cada país, vamos a recuperar un listado con los códigos postales de aquellos pedidos que hayan superado las 5 unidades:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">collect_list</span><span class="p">,</span> <span class="n">collect_set</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="s2">&quot;Units &gt; 5&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">collect_list</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">),</span> <span class="n">collect_set</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +-------+--------------------+--------------------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |Country|   collect_list(Zip)|    collect_set(Zip)|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------+--------------------+--------------------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Germany|[22397, 22111, 40...|[22111, 12589, 22...|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | France|[75213 CEDEX 16, ...|[06082 CEDEX 1, 0...|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># | Mexico|[7100, 7810, 9739...|[9739, 10300, 781...|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># | Canada|[T2X, V6G, V6G, T6V]|     [V6G, T2X, T6V]|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+--------------------+--------------------+</span>
</code></pre></div>
<h3 id="tablas-pivote">Tablas pivote<a class="headerlink" href="#tablas-pivote" title="Permanent link">&para;</a></h3>
<p>Las tablas pivote permite obtener un resumen de los datos a partir de columnas categóricas sobre la que realizar cálculos, tal como se hace en las hojas de cálculo con las tablas dinámicas.</p>
<p>Por ejemplo, vamos a obtener la cantidad recaudada por las ventas de cada año por cada pais:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">year</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +----------+------------------+------------------+------------------+------------------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |year(Date)|            Canada|            France|           Germany|            Mexico|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +----------+------------------+------------------+------------------+------------------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      2003| 2360085.999999947|1105230.9000000046|1407120.0000000007|         1049457.5|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |      2004| 1539140.499999946|              null|              null|              null|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      2001| 2193437.799999908|              null|              null|233419.20000000004|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |      2000|1806678.3999999042|1108846.8999999764| 4510606.799999941| 4240448.399999928|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      1999|1382756.6999999764| 7594921.200000435| 5928459.100000297|3419368.2000001906|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |      2002|2360514.7999998857| 2278943.099999957| 3135934.099999964|2451905.3999999263|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +----------+------------------+------------------+------------------+------------------+</span>
</code></pre></div>
<p>También podemos hacer más de un cálculo sobre la tabla pivote:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">year</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total&quot;</span><span class="p">),</span> <span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;cantidad&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +----------+------------------+---------------+------------------+---------------+------------------+----------------+------------------+---------------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |year(Date)|      Canada_total|Canada_cantidad|      France_total|France_cantidad|     Germany_total|Germany_cantidad|      Mexico_total|Mexico_cantidad|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +----------+------------------+---------------+------------------+---------------+------------------+----------------+------------------+---------------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      2003| 2360085.999999947|           6375|1105230.9000000046|           2794|1407120.0000000007|            3099|         1049457.5|           2510|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |      2004| 1539140.499999946|           3636|              null|           null|              null|            null|              null|           null|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      2001| 2193437.799999908|           5976|              null|           null|              null|            null|233419.20000000004|            583|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |      2000|1806678.3999999042|           5049|1108846.8999999764|           2456| 4510606.799999941|            9738| 4240448.399999928|          11935|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      1999|1382756.6999999764|           3964| 7594921.200000435|          20432| 5928459.100000297|           12266|3419368.2000001906|           9895|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |      2002|2360514.7999998857|           6148| 2278943.099999957|           6057| 3135934.099999964|            6643|2451905.3999999263|           6172|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +----------+------------------+---------------+------------------+---------------+------------------+----------------+------------------+---------------+</span>
</code></pre></div>
<h2 id="joins">Joins<a class="headerlink" href="#joins" title="Permanent link">&para;</a></h2>
<p>Hasta ahora todo la analítica la hemos realizado sobre un único <em>DataFrame</em>. Aunque si seguimos un proceso ELT es probable que tengamos todos los datos en un único lugar, en ocasiones necesitamos cruzar la información de dos datasets.</p>
<p>Si nos basamos en el planteamiento de una base de datos relacional, Para unir dos DataFrames necesitamos unir la clave ajena de uno con la clave primaria del otro.</p>
<p>Para estos ejemplos, vamos a cambiar de <em>datasets</em> y utilizar datos de vuelos de avión que han tenido algún tipo de retraso (<a href="../recursos/spark/departure_delays.csv">departure_delays.csv</a>) y otro con los códigos de los aeropuertos (<a href="../recursos/spark/airport-codes-na.tsv">airport-codes-na.tsv</a>).</p>
<div class="tabbed-set tabbed-alternate" data-tabs="8:2"><input checked="checked" id="__tabbed_8_1" name="__tabbed_8" type="radio" /><input id="__tabbed_8_2" name="__tabbed_8" type="radio" /><div class="tabbed-labels"><label for="__tabbed_8_1">Vuelos con retraso</label><label for="__tabbed_8_2">Códigos de aeropuertos</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>Fichero CSV con la coma como separador de campos.</p>
<div class="highlight"><span class="filename">departure_delays.csv</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span>date,delay,distance,origin,destination
<span class="linenos" data-linenos="2 "></span>01011245,6,602,ABE,ATL
<span class="linenos" data-linenos="3 "></span>01020600,-8,369,ABE,DTW
<span class="linenos" data-linenos="4 "></span>01021245,-2,602,ABE,ATL
<span class="linenos" data-linenos="5 "></span>01020605,-4,602,ABE,ATL
</code></pre></div>
</div>
<div class="tabbed-block">
<p>Fichero TSV con el tabulador como separador campos</p>
<div class="highlight"><span class="filename">airport-codes-na.tsv</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span>City State Country IATA
<span class="linenos" data-linenos="2 "></span>Abbotsford BC Canada YXX
<span class="linenos" data-linenos="3 "></span>Aberdeen SD USA ABR
<span class="linenos" data-linenos="4 "></span>Abilene TX USA ABI
<span class="linenos" data-linenos="5 "></span>Akron OH USA CAK
<span class="linenos" data-linenos="6 "></span>Alamosa CO USA ALS
<span class="linenos" data-linenos="7 "></span>Albany GA USA ABY
</code></pre></div>
</div>
</div>
</div>
<p>Así pues, lo primero que vamos a hacer es cargar ambos <em>DataFrames</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;s8a-dataframes-joins&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span>
<span class="linenos" data-linenos="5 "></span><span class="n">df_vuelos</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span><span class="s2">&quot;,&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;departure_delays.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># df_vuelos.printSchema()</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># df_vuelos.count()   # 1391578</span>
<span class="linenos" data-linenos="8 "></span><span class="n">df_aeropuertos</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;airport-codes-na.tsv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># df_aeropuertos.printSchema()</span>
</code></pre></div>
<h3 id="mediante-sql">Mediante SQL<a class="headerlink" href="#mediante-sql" title="Permanent link">&para;</a></h3>
<p>Si queremos hacer un <em>join</em> mediante SQL, sólo tenemos que emplear la misma sintaxis que con cualquier sistema relacional, de manera que primero crearemos las vistas temporales y luego realizaremos la consulta:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df_vuelos</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;vuelos&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df_aeropuertos</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;aeropuertos&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">df_join</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select v.*, a.City as originCity, b.City as destinationCity from vuelos v JOIN aeropuertos a on v.origin == a.IATA join aeropuertos b on v.destination = b.IATA&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># df_join.count()   # 1361141</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">df_join</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># +-------+-----+--------+------+-----------+----------+---------------+</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |   date|delay|distance|origin|destination|originCity|destinationCity|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +-------+-----+--------+------+-----------+----------+---------------+</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |1011245|    6|     602|   ABE|        ATL| Allentown|        Atlanta|</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |1020600|   -8|     369|   ABE|        DTW| Allentown|        Detroit|</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |1021245|   -2|     602|   ABE|        ATL| Allentown|        Atlanta|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># +-------+-----+--------+------+-----------+----------+---------------+</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># only showing top 3 rows</span>
</code></pre></div>
<p>Si tuviéramos algún vuelo con algún código que no tuviéramos disponible en el dataset con los códigos de aeropuertos no nos aparecería. Por tanto, sería más conveniente realizar un left join:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df_left_join</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select v.*, a.City as originCity, b.City as destinationCity from vuelos v LEFT JOIN aeropuertos a on v.origin == a.IATA LEFT JOIN aeropuertos b on v.destination = b.IATA&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df_left_join</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df_left_join</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>    <span class="c1"># 1391578</span>
</code></pre></div>
<p>Un caso particular que conviene conocer es el <em>left anti join</em>. Este tipo de <em>join</em> permite obtener aquellos registros de la izquierda que no aparecen en la parte derecha, de manera que si seguimos con el ejemplo, podemos recuperar aquellos vuelos cuyos aeropuertos no tenemos en el dataset con los códigos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df_left_anti_join</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select * from vuelos v LEFT ANTI JOIN aeropuertos a ON v.origin == a.IATA &quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df_left_anti_join</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>   <span class="c1"># 14416</span>
</code></pre></div>
<h3 id="mediante-python">Mediante Python<a class="headerlink" href="#mediante-python" title="Permanent link">&para;</a></h3>
<p>Si no queremos utilizar SQL o ya tenemos fragmentos de código que interactuar con el DataFrame API, podemos utilizar el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.join.html">join</a>.</p>
<p>Este método une dos <em>DataFrames</em>, indicando la expresión de unión y opcionalmente el tipo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">exprJoin1</span> <span class="o">=</span> <span class="n">df_vuelos</span><span class="o">.</span><span class="n">origin</span> <span class="o">==</span> <span class="n">df_aeropuertos</span><span class="o">.</span><span class="n">IATA</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df_joinp1</span> <span class="o">=</span> <span class="n">df_vuelos</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_aeropuertos</span><span class="p">,</span> <span class="n">exprJoin1</span><span class="p">,</span> <span class="s2">&quot;inner&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df_joinp1</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>    <span class="c1"># 1377162</span>
</code></pre></div>
<div class="admonition tip">
<p class="admonition-title">Forma corta</p>
<p>Si las columnas que unen los DataFrames tienen el mismo nombre, podemos simplificar el código indicando únicamente su nombre:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span> <span class="s2">&quot;user_id&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Además, si queremos hacer un <em>inner join</em>, podemos no indicarlo ya que es el tipo por defecto.</p>
</div>
<p>Como en nuestro caso, teníamos dos joins, tanto para los vuelos de origen como los de destino, necesitamos volver a unir:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># le indicamos alias a los campos para eliminar ambigüedades</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df_joinp2</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_joinp1</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">join</span><span class="p">((</span><span class="n">df_aeropuertos</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">)),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;a.destination&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;b.IATA&quot;</span><span class="p">),</span> <span class="s2">&quot;inner&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span><span class="n">df_joinp2</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>    <span class="c1"># 1361141</span>
</code></pre></div>
<p>En vez de pasarle <code>inner</code>, le podemos indicar el tipo de join: <code>left</code>, <code>right</code>, <code>cross</code>, <code>left_anti</code>, etc...</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">exprJoin1</span> <span class="o">=</span> <span class="n">df_vuelos</span><span class="o">.</span><span class="n">origin</span> <span class="o">==</span> <span class="n">df_aeropuertos</span><span class="o">.</span><span class="n">IATA</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df_left_anti_join</span> <span class="o">=</span> <span class="n">df_vuelos</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_aeropuertos</span><span class="p">,</span> <span class="n">exprJoin1</span><span class="p">,</span> <span class="s2">&quot;left_anti&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df_left_anti_join</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>   <span class="c1"># 14416</span>
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">Todo tipo de joins</p>
<p>Además de los casos vistos, podemos realizar otros tipos de joins como <em>cross</em>, <em>semi</em>, <em>full</em>, <em>outer</em>, etc... Más información en la <a href="https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-join.html">documentación oficial</a></p>
</div>
<h2 id="funciones">Funciones<a class="headerlink" href="#funciones" title="Permanent link">&para;</a></h2>
<p>Para dominar realmente Spark, hay que tener destreza en todas las funciones existente para el tratamiento de fechas, cadenas, operaciones matemáticas, para trabajar con colecciones, etc...</p>
<p>Además, siempre podemos crear nuestras propias funciones de usuario para ampliar el lenguaje.</p>
<p>Aunque ya hemos utilizado algunas a lo largo de los apuntes, a continuación vamos a repasar las funciones más empleadas.</p>
<h3 id="fechas">Fechas<a class="headerlink" href="#fechas" title="Permanent link">&para;</a></h3>
<ul>
<li>Si necesitamos convertir de texto a fecha: <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.to_date.html"><code>to_date</code></a>, <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.to_timestamp.html"><code>to_timestamp</code></a>, <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.unix_timestamp.html"><code>unix_timestamp</code></a></li>
<li>Para formatear las fechas: <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.date_format.html"><code>date_format</code></a>, <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.from_unixtime.html"><code>from_unixtime</code></a> (<a href="https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html">patrones de fechas</a>)</li>
<li>Para realizar cálculos sobre fechas: <code>datediff</code>, <code>months_between</code>, <code>last_day</code>, <code>date_add</code>, <code>date_sub</code>, <code>next_day</code></li>
<li>Extraer un valor de una fecha: <code>year</code>, <code>month</code>, <code>weekofyear</code>, <code>dayofmonth</code>, <code>dayofyear</code>, <code>hour</code>, <code>minute</code>, <code>second</code></li>
</ul>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#date-and-timestamp-functions">documentación oficial</a></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">to_date</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;s8a-dataframes-sql&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;pdi_sales_small.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># Cambiamos el tipo de dato a fecha</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="n">to_date</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Date</span><span class="p">,</span> <span class="s2">&quot;M/d/yyy&quot;</span><span class="p">))</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span><span class="kn">import</span> <span class="nn">pyspark.sql.functions</span>
<span class="linenos" data-linenos="11 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="n">date_format</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="s2">&quot;dd-MM-yyy&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="12 "></span>            <span class="n">next_day</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="s2">&quot;Sun&quot;</span><span class="p">),</span> <span class="n">last_day</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="13 "></span>            <span class="n">dayofmonth</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">),</span> <span class="n">dayofyear</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="14 "></span>            <span class="n">month</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">),</span> <span class="n">year</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># +----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |      Date|date_format(Date, dd-MM-yyy)|next_day(Date, Sun)|last_day(Date)|dayofmonth(Date)|dayofyear(Date)|month(Date)|year(Date)|</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># +----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+</span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># |1999-01-15|                  15-01-1999|         1999-01-17|    1999-01-31|              15|             15|          1|      1999|</span>
<span class="linenos" data-linenos="19 "></span><span class="c1"># |2002-06-06|                  06-06-2002|         2002-06-09|    2002-06-30|               6|            157|          6|      2002|</span>
<span class="linenos" data-linenos="20 "></span><span class="c1"># +----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+</span>
<span class="linenos" data-linenos="21 "></span><span class="c1"># only showing top 2 rows</span>
</code></pre></div>
<h3 id="cadenas">Cadenas<a class="headerlink" href="#cadenas" title="Permanent link">&para;</a></h3>
<p>Por ejemplo, tenemos las funciones para quitar espacios (<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.ltrim.html"><code>ltrim</code></a>, <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.rtrim.html"><code>rtrim</code></a>, <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.trim.html"><code>trim</code></a>) y pasar a mayúsculas/minúsculas (<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.lower.html"><code>lower</code></a>, <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.upper.html"><code>upper</code></a>):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">,</span> <span class="n">ltrim</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;l&quot;</span><span class="p">),</span> <span class="n">rtrim</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">),</span> 
<span class="linenos" data-linenos="2 "></span>         <span class="n">lower</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">),</span> <span class="n">upper</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span>         <span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">trim</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="p">)</span><span class="o">==</span><span class="s2">&quot;Canada&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------------+---------------+---+---------------+---------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |            Zip|              l|  r|     lower(Zip)|     upper(Zip)|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># +---------------+---------------+---+---------------+---------------+</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># |H1B            |H1B            |H1B|h1b            |H1B            |</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># +---------------+---------------+---+---------------+---------------+</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># only showing top 1 row</span>
</code></pre></div>
<p>O funciones para poner la inicial en mayúsculas (<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.initcap.html"><code>initcap</code></a>), darle la vuelta (<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.reverse.html"><code>reverse</code></a>), obtener su tamaño o reemplazar caracteres (<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.translate.html"><code>translate</code></a>):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">,</span> <span class="n">initcap</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">),</span> <span class="n">reverse</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="2 "></span>          <span class="n">length</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">),</span> <span class="n">translate</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">,</span> <span class="s2">&quot;na&quot;</span><span class="p">,</span> <span class="s2">&quot;pe&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span>         <span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">trim</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="p">)</span><span class="o">==</span><span class="s2">&quot;Canada&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +-------+----------------+----------------+---------------+--------------------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |Country|initcap(Country)|reverse(Country)|length(Country)|translate(Country, na, pe)|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># +-------+----------------+----------------+---------------+--------------------------+</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># |Canada |         Canada |          adanaC|              7|                   Cepede |</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># +-------+----------------+----------------+---------------+--------------------------+</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># only showing top 1 row</span>
</code></pre></div>
<p>También podemos trabajar con subcadenas (<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.substring.html"><code>substring</code></a>), encontrar ocurrencias (<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.locate.html"><code>locate</code></a>) o partir una cadena en trozos (<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.split.html"><code>split</code></a>):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">,</span> <span class="n">split</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="n">locate</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;Country&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="2 "></span>          <span class="n">substring</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span>         <span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">trim</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="p">)</span><span class="o">==</span><span class="s2">&quot;Canada&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span><span class="o">+-------+---------------------+---------------------+------------------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="o">|</span><span class="n">Country</span><span class="o">|</span><span class="n">split</span><span class="p">(</span><span class="n">Country</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">|</span><span class="n">locate</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">Country</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">|</span><span class="n">substring</span><span class="p">(</span><span class="n">Country</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">|</span>
<span class="linenos" data-linenos="6 "></span><span class="o">+-------+---------------------+---------------------+------------------------+</span>
<span class="linenos" data-linenos="7 "></span><span class="o">|</span><span class="n">Canada</span> <span class="o">|</span>         <span class="p">[</span><span class="n">C</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span>  <span class="p">]</span><span class="o">|</span>                    <span class="mi">2</span><span class="o">|</span>                      <span class="n">na</span><span class="o">|</span>
<span class="linenos" data-linenos="8 "></span><span class="o">+-------+---------------------+---------------------+------------------------+</span>
<span class="linenos" data-linenos="9 "></span><span class="n">only</span> <span class="n">showing</span> <span class="n">top</span> <span class="mi">1</span> <span class="n">row</span>
</code></pre></div>
<p>Otras funciones que se suelen utilizar son <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.concat.html"><code>concat</code></a> y  <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.concat.html"><code>concat_ws</code></a> para unir cadenas, <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.levenshtein.html"><code>levenshtein</code></a> para calcular la distancia entre dos cadenas, <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.lpad.html"><code>lpad</code></a> y <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.rpad.html"><code>rpad</code></a> para completar con espacios, etc... Si necesitas trabajar con expresiones regulares puedes utilizar <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.regexp_extract.html"><code>regexp_extract</code></a> para extraer parte de una cadena como <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.regexp_replace.html"><code>regexp_replace</code></a> para sustituir.</p>
<h3 id="colecciones">Colecciones<a class="headerlink" href="#colecciones" title="Permanent link">&para;</a></h3>
<p>Para probar las funciones que trabajan con colecciones, vamos a cambiar de <em>dataset</em> y trabajar con uno compartido por <a href="https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset">Kaggle</a> con datos de negocios de Yelp que tenemos almacenados en una versión reducida en <a href="../recursos/spark/yelp_academic_dataset_business.json">yelp_academic_dataset_business.json</a>. Los negocios tienen una propiedad denominada <code>categories</code> que contiene un array con las categorías de los mismos:</p>
<div class="highlight"><span class="filename">persons.json</span><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="p">{</span><span class="w"></span>
<span class="linenos" data-linenos=" 2 "></span><span class="w">   </span><span class="nt">&quot;business_id&quot;</span><span class="p">:</span><span class="s2">&quot;O_X3PGhk3Y5JWVi866qlJg&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos=" 3 "></span><span class="w">   </span><span class="nt">&quot;full_address&quot;</span><span class="p">:</span><span class="s2">&quot;1501 W Bell Rd\nPhoenix, AZ 85023&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos=" 4 "></span><span class="w">   </span><span class="nt">&quot;hours&quot;</span><span class="p">:{</span><span class="w"></span>
<span class="linenos" data-linenos=" 5 "></span><span class="w">      </span><span class="nt">&quot;Monday&quot;</span><span class="p">:{</span><span class="w"></span>
<span class="linenos" data-linenos=" 6 "></span><span class="w">         </span><span class="nt">&quot;close&quot;</span><span class="p">:</span><span class="s2">&quot;18:00&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos=" 7 "></span><span class="w">         </span><span class="nt">&quot;open&quot;</span><span class="p">:</span><span class="s2">&quot;11:00&quot;</span><span class="w"></span>
<span class="linenos" data-linenos=" 8 "></span><span class="w">      </span><span class="p">},</span><span class="w"></span>
<span class="linenos" data-linenos=" 9 "></span><span class="w">      </span><span class="nt">&quot;Tuesday&quot;</span><span class="p">:{</span><span class="w"></span>
<span class="linenos" data-linenos="10 "></span><span class="w">         </span><span class="nt">&quot;close&quot;</span><span class="p">:</span><span class="s2">&quot;18:00&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos="11 "></span><span class="w">         </span><span class="nt">&quot;open&quot;</span><span class="p">:</span><span class="s2">&quot;11:00&quot;</span><span class="w"></span>
<span class="linenos" data-linenos="12 "></span><span class="w">      </span><span class="p">},</span><span class="w"></span>
<span class="linenos" data-linenos="13 "></span><span class="w">        </span><span class="err">...</span><span class="w"></span>
<span class="linenos" data-linenos="14 "></span><span class="w">   </span><span class="p">},</span><span class="w"></span>
<span class="linenos" data-linenos="15 "></span><span class="w">   </span><span class="nt">&quot;open&quot;</span><span class="p">:</span><span class="kc">true</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos="16 "></span><span class="w">   </span><span class="nt">&quot;categories&quot;</span><span class="p">:[</span><span class="w"></span>
<span class="linenos" data-linenos="17 "></span><span class="w">      </span><span class="s2">&quot;Active Life&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos="18 "></span><span class="w">      </span><span class="s2">&quot;Arts &amp; Entertainment&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos="19 "></span><span class="w">      </span><span class="s2">&quot;Stadiums &amp; Arenas&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos="20 "></span><span class="w">      </span><span class="s2">&quot;Horse Racing&quot;</span><span class="w"></span>
<span class="linenos" data-linenos="21 "></span><span class="w">   </span><span class="p">],</span><span class="w"></span>
<span class="linenos" data-linenos="22 "></span><span class="w">   </span><span class="nt">&quot;city&quot;</span><span class="p">:</span><span class="s2">&quot;Phoenix&quot;</span><span class="p">,</span><span class="w"></span>
<span class="linenos" data-linenos="23 "></span><span class="w">   </span><span class="err">...</span><span class="w"></span>
<span class="linenos" data-linenos="24 "></span><span class="p">}</span><span class="w"></span>
</code></pre></div>
<p>El primer paso es cargar el documento y ver el esquema leído por <em>Spark</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;s8a-dataframes-arrays&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span>
<span class="linenos" data-linenos="5 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;multiline&quot;</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;yelp_academic_dataset_business.json&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span>
<span class="linenos" data-linenos="7 "></span><span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<p>Como podemos observar, sigue una estructura de elementos anidados:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>root
<span class="linenos" data-linenos=" 2 "></span> |-- attributes: struct (nullable = true)
<span class="linenos" data-linenos=" 3 "></span> |    |-- Accepts Credit Cards: boolean (nullable = true)
<span class="linenos" data-linenos=" 4 "></span> |    |-- Alcohol: string (nullable = true)
<span class="linenos" data-linenos=" 5 "></span> |    |-- Ambience: struct (nullable = true)
<span class="linenos" data-linenos=" 6 "></span> |    |    |-- casual: boolean (nullable = true)
<span class="linenos" data-linenos=" 7 "></span> |    |    |-- classy: boolean (nullable = true)
<span class="linenos" data-linenos=" 8 "></span> |    |    |-- divey: boolean (nullable = true)
<span class="linenos" data-linenos=" 9 "></span> |    |    |-- hipster: boolean (nullable = true)
<span class="linenos" data-linenos="10 "></span> |    |    |-- intimate: boolean (nullable = true)
<span class="linenos" data-linenos="11 "></span> |    |    |-- romantic: boolean (nullable = true)
<span class="linenos" data-linenos="12 "></span> |    |    |-- touristy: boolean (nullable = true)
<span class="linenos" data-linenos="13 "></span> |    |    |-- trendy: boolean (nullable = true)
<span class="linenos" data-linenos="14 "></span> |    |    |-- upscale: boolean (nullable = true)
<span class="linenos" data-linenos="15 "></span> |    |-- Attire: string (nullable = true)
<span class="linenos" data-linenos="16 "></span> ...
<span class="linenos" data-linenos="17 "></span> |    |-- Wi-Fi: string (nullable = true)
<span class="linenos" data-linenos="18 "></span> |-- business_id: string (nullable = true)
<span class="linenos" data-linenos="19 "></span> |-- categories: array (nullable = true)
<span class="linenos" data-linenos="20 "></span> |    |-- element: string (containsNull = true)
<span class="linenos" data-linenos="21 "></span> |-- city: string (nullable = true)
<span class="linenos" data-linenos="22 "></span> |-- full_address: string (nullable = true)
<span class="linenos" data-linenos="23 "></span> ...
</code></pre></div>
<p>Por ejemplo, vamos a ver mediante un ejemplo las siguientes funciones:</p>
<ul>
<li><code>size</code>: devuelve el tamaño de la colección</li>
<li><code>sort_array</code>: ordena la colección</li>
<li><code>array_contains</code>: comprueba si hay un elemento en la colección</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;hours.Sunday&quot;</span><span class="p">,</span> <span class="n">size</span><span class="p">(</span><span class="s2">&quot;categories&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;totalCategorias&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 3 "></span>               <span class="n">sort_array</span><span class="p">(</span><span class="s2">&quot;categories&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;categorias&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 4 "></span>               <span class="n">array_contains</span><span class="p">(</span><span class="s2">&quot;categories&quot;</span><span class="p">,</span> <span class="s2">&quot;Restaurants&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;Restaurantes&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------------------------------+--------------+---------------+---------------------------------------------------------------------------------+------------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |name                           |Sunday        |totalCategorias|categorias                                                                       |Restaurantes|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># +-------------------------------+--------------+---------------+---------------------------------------------------------------------------------+------------+</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |Turf Paradise Race Course      |{18:00, 11:00}|4              |[Active Life, Arts &amp; Entertainment, Horse Racing, Stadiums &amp; Arenas]             |false       |</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |Sam&#39;s Club Members Only        |null          |5              |[Automotive, Department Stores, Fashion, Shopping, Tires]                        |false       |</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |Forever 21                     |{18:00, 11:00}|5              |[Accessories, Fashion, Men&#39;s Clothing, Shopping, Women&#39;s Clothing]               |false       |</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |Loving Hands Pet Care          |{19:00, 06:00}|3              |[Pet Boarding/Pet Sitting, Pet Services, Pets]                                   |false       |</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |Amec Mid-City Animal Hospital  |null          |2              |[Pets, Veterinarians]                                                            |false       |</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |Los Armandos Asadero Y Mariscos|{03:00, 20:00}|2              |[Mexican, Restaurants]                                                           |true        |</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |Clayton Companies              |null          |4              |[Home Services, Property Management, Real Estate, Real Estate Services]          |false       |</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |Bertha&#39;s Café                  |null          |5              |[Bakeries, Breakfast &amp; Brunch, Food, Restaurants, Sandwiches]                    |true        |</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |Jerry&#39;s Artarama               |{17:00, 11:00}|4              |[Art Supplies, Arts &amp; Crafts, Framing, Shopping]                                 |false       |</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># |Shauna Brown Fitness           |null          |5              |[Active Life, Fitness &amp; Instruction, Health &amp; Medical, Massage Therapy, Trainers]|false       |</span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># +-------------------------------+--------------+---------------+---------------------------------------------------------------------------------+------------+</span>
<span class="linenos" data-linenos="19 "></span><span class="n">only</span> <span class="n">showing</span> <span class="n">top</span> <span class="mi">10</span> <span class="n">rows</span>
</code></pre></div>
<div class="admonition tip inline end">
<p class="admonition-title">Tip</p>
<p>Recuerda que en el apartado <a href="#agrupando-colecciones">Agrupando colecciones</a> vimos como podemos crear colecciones al realizar una agrupación.</p>
</div>
<p>Así pues, además del nombre, hemos obtenido el horario de los domingos utilizando la notación <code>.</code> para acceder a los campos anidados, la cantidad de categorías de cada comercio, un listado ordenado con sus categorías y finalmente si es un restaurante.</p>
<p>Otro tipo de operación que podemos realizar es desenrollar una colección mediante la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.explode.html"><code>explode</code></a> y generar una fila nueva por cada elemento de la colección:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="n">explode</span><span class="p">(</span><span class="s2">&quot;categories&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +-------------------------+--------------------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |name                     |col                 |</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +-------------------------+--------------------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |Turf Paradise Race Course|Active Life         |</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Turf Paradise Race Course|Arts &amp; Entertainment|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |Turf Paradise Race Course|Stadiums &amp; Arenas   |</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |Turf Paradise Race Course|Horse Racing        |</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |Sam&#39;s Club Members Only  |Tires               |</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |Sam&#39;s Club Members Only  |Automotive          |</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |Sam&#39;s Club Members Only  |Fashion             |</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |Sam&#39;s Club Members Only  |Shopping            |</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |Sam&#39;s Club Members Only  |Department Stores   |</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |Forever 21               |Women&#39;s Clothing    |</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># +-------------------------+--------------------+</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># only showing top 10 rows</span>
</code></pre></div>
<h3 id="json">JSON<a class="headerlink" href="#json" title="Permanent link">&para;</a></h3>
<p>Es común que se de el caso de que los datos que leemos desde un sistema externo estén en formato JSON pero que el proceso de ingesta lo haya realizado como si fuera una cadena de texto.</p>
<p>Supongamos que tenemos la siguiente cadena y generados un DataFrame a partir de un RDD:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">tareas</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;&quot;{&quot;dia&quot;: &quot;Lunes&quot;, &quot;tareas&quot;: [&quot;Corregir ejercicios&quot;, &quot;Ir a nadar&quot;, &quot;Comprar pan&quot;]}&quot;&quot;&quot;</span><span class="p">]</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># [&#39;{&quot;dia&quot;: &quot;Lunes&quot;, &quot;tareas&quot;: [&quot;Corregir ejercicios&quot;, &quot;Ir a nadar&quot;, &quot;Comprar pan&quot;]}&#39;]</span>
<span class="linenos" data-linenos=" 3 "></span><span class="n">tareasRDD</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">tareas</span><span class="p">)</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">tareasStrDF</span> <span class="o">=</span> <span class="n">tareasRDD</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># tareasStrDF es un DF con una columna con nombre value de tipo string</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">tareasStrDF</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># root</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1">#  |-- value: string (nullable = true)</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">tareasStrDF</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +--------------------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |               value|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +--------------------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |{&quot;dia&quot;: &quot;Lunes&quot;, ...|</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># +--------------------+</span>
</code></pre></div>
<p>Para pasarlo a JSON, necesitamos definir un esquema con la estructura del documento JSON:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">ArrayType</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">esquemaTareas</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
<span class="linenos" data-linenos="4 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;dia&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="5 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;tareas&quot;</span><span class="p">,</span> <span class="n">ArrayType</span><span class="p">(</span><span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span> <span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="p">])</span>
</code></pre></div>
<p>Y a continuación ya podemos transformar el formato mediante la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.from_json.html"><code>from_json</code></a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">todosDF</span> <span class="o">=</span> <span class="n">tareasStrDF</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">from_json</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">esquemaTareas</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;datos&quot;</span><span class="p">))</span>
<span class="linenos" data-linenos="2 "></span><span class="n">todosDF</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># root</span>
<span class="linenos" data-linenos="4 "></span><span class="c1">#  |-- datos: struct (nullable = true)</span>
<span class="linenos" data-linenos="5 "></span><span class="c1">#  |    |-- dia: string (nullable = true)</span>
<span class="linenos" data-linenos="6 "></span><span class="c1">#  |    |-- tareas: array (nullable = true)</span>
<span class="linenos" data-linenos="7 "></span><span class="c1">#  |    |    |-- element: string (containsNull = true)</span>
</code></pre></div>
<p>Y ahora ya podemos acceder a los datos (en el siguiente ejemplo empleamos la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.getItem.html"><code>getItem</code></a> para acceder a un elemento de una columna):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">todosDF</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;datos&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getItem</span><span class="p">(</span><span class="s2">&quot;dia&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="2 "></span>     <span class="s2">&quot;datos.tareas&quot;</span><span class="p">,</span>
<span class="linenos" data-linenos="3 "></span>     <span class="p">(</span><span class="n">todosDF</span><span class="o">.</span><span class="n">datos</span><span class="o">.</span><span class="n">getItem</span><span class="p">(</span><span class="s2">&quot;tareas&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;tarea1&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span><span class="o">+---------+----------------------------------------------+-------------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="o">|</span><span class="n">datos</span><span class="o">.</span><span class="n">dia</span><span class="o">|</span><span class="n">tareas</span>                                        <span class="o">|</span><span class="n">tarea1</span>             <span class="o">|</span>
<span class="linenos" data-linenos="6 "></span><span class="o">+---------+----------------------------------------------+-------------------+</span>
<span class="linenos" data-linenos="7 "></span><span class="o">|</span><span class="n">Lunes</span>    <span class="o">|</span><span class="p">[</span><span class="n">Corregir</span> <span class="n">ejercicios</span><span class="p">,</span> <span class="n">Ir</span> <span class="n">a</span> <span class="n">nadar</span><span class="p">,</span> <span class="n">Comprar</span> <span class="n">pan</span><span class="p">]</span><span class="o">|</span><span class="n">Corregir</span> <span class="n">ejercicios</span><span class="o">|</span>
<span class="linenos" data-linenos="8 "></span><span class="o">+---------+----------------------------------------------+-------------------+</span>
</code></pre></div>
<p>Para terminar, si necesitamos la operación inversa, y lo que queremos es crear una representación JSON de una columna, podemos utilizar la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.getItem.html"><code>getItem</code></a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">todosDF</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">to_json</span><span class="p">(</span><span class="s2">&quot;datos&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------------------------------------------------------------------------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |to_json(datos)                                                             |</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------------------------------------------------------------------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |{&quot;dia&quot;:&quot;Lunes&quot;,&quot;tareas&quot;:[&quot;Corregir ejercicios&quot;,&quot;Ir a nadar&quot;,&quot;Comprar pan&quot;]}|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># +---------------------------------------------------------------------------+</span>
</code></pre></div>
<h3 id="udf">UDF<a class="headerlink" href="#udf" title="Permanent link">&para;</a></h3>
<p>Además de las funciones que ofrece Spark, en cualquier momento podemos crear nuestras funciones de usuario (<em>User-Defined Functions</em>) para ampliar la expresividad de Spark. Antes de utilizarlas, las hemos de definir y registrar.</p>
<p>Si volvemos al <em>dataset</em> de ventas, teníamos la siguiente información:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span><span class="p">,</span> <span class="s2">&quot;Units&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+-------+-----+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |ProductID|Revenue|Units|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+-------+-----+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      495|43194.1|   77|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     2091| 6347.7|   41|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     2091| 6240.1|   41|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |     2091| 3652.7|   24|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     2091| 3560.9|   23|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+-------+-----+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># only showing top 5 rows</span>
</code></pre></div>
<p>Vamos a crear una función para que, si vende más de una unidad, se le asigne a cada producto un bonus de un 1%. Para ello, primero definiremos la función mediante <em>Python</em>, y posteriormente, la registraremos mediante la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.udf.html"><code>udf</code></a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">udf</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">DoubleType</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span><span class="k">def</span> <span class="nf">bonus</span><span class="p">(</span><span class="n">unidades</span><span class="p">,</span> <span class="n">ventas</span><span class="p">):</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="k">if</span> <span class="n">unidades</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">:</span>
<span class="linenos" data-linenos=" 6 "></span>        <span class="k">return</span> <span class="mf">0.0</span>
<span class="linenos" data-linenos=" 7 "></span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos" data-linenos=" 8 "></span>        <span class="k">return</span> <span class="n">unidades</span> <span class="o">*</span> <span class="n">ventas</span> <span class="o">/</span> <span class="mi">100</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span><span class="n">udfBonus</span> <span class="o">=</span> <span class="n">udf</span><span class="p">(</span><span class="n">bonus</span><span class="p">,</span> <span class="n">DoubleType</span><span class="p">())</span>
</code></pre></div>
<p>Así pues, si realizamos una consulta, ya podemos utilizar la función recién creada como si fuera una propia de <em>Spark</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span><span class="p">,</span> <span class="s2">&quot;Units&quot;</span><span class="p">,</span> <span class="n">udfBonus</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="p">))</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+-------+-----+---------------------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |ProductID|Revenue|Units|bonus(Units, Revenue)|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+-------+-----+---------------------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      495|43194.1|   77|   33259.456999999995|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     2091| 6347.7|   41|             2602.557|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     2091| 6240.1|   41|   2558.4410000000003|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |     2091| 3652.7|   24|    876.6479999999999|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     2091| 3560.9|   23|              819.007|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+-------+-----+---------------------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># only showing top 5 rows</span>
</code></pre></div>
<p>Si queremos definir la función para poder utilizarla dentro de Spark SQL y obtener el mismo resultado, hemos de registrar la función mediante <strong><em><code>spark.udf.register</code></em></strong>, la cual recibe el nombre que le asignaremos a la función, el nombre de la función Python a invocar, y el tipo de dato que devuelve:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">spark</span><span class="o">.</span><span class="n">udf</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;udfBonus&quot;</span><span class="p">,</span> <span class="n">bonus</span><span class="p">,</span> <span class="n">DoubleType</span><span class="p">())</span>
<span class="linenos" data-linenos="2 "></span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select ProductID, Revenue, Units,  udfBonus(Units, Revenue) as bonus from ventas order by Units desc&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<div class="admonition caution">
<p class="admonition-title">UDF y Python</p>
<p>En un principio, se desaconseja la creación de UDF mediante <em>Python</em>, ya que su uso penalizar de forma significativa el rendimiento.
Los ejecutores son procesos en máquinas virtuales de Java que están escritos en Java, y por ello, ejecutan código Java o Scala de forma nativa. En cambio, para Python tiene que ejecutar un proceso separado para ejecutar la UDF, lo que implica un coste extra para serializar y volver a deserializar los datos para cada fila del <em>dataset</em>.</p>
</div>
<h2 id="persistencia">Persistencia<a class="headerlink" href="#persistencia" title="Permanent link">&para;</a></h2>
<p>Un <em>DataFrame</em> se puede persistir/cachear en memoria conforme necesitemos (también lo podemos hacer con los RDD). Su principal propósito es cuando vamos a acceder a un DataFrame una y otra vez y no necesitamos que se vuelvan a evaluar todas las operaciones (como pueden ser los algoritmos iterativos utilizados en <em>Machine Learning</em>).</p>
<p>Cuando persistimos un <em>dataset</em>, cada nodo almacena sus datos particionados en memoria y/o disco y los reutiliza en otras operaciones sobre dicho <em>dataset</em>.</p>
<p>Para ello, se emplean los métodos <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.cache.html"><code>cache</code></a> / <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.persist.html"><code>persist</code></a> y <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.unpersist.html"><code>unpersist</code></a> para cachear y liberar los datos.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">persist</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># forzamos la evaluación perezosa</span>
</code></pre></div>
<p>Si queremos realizarlo con <em>SparkSQL</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">ventasCanada</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;ventasCanada&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="o">//</span> <span class="n">Si</span> <span class="n">queremos</span> <span class="n">cachear</span> <span class="n">la</span> <span class="n">tabla</span> <span class="n">mediante</span> <span class="n">SQl</span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">cacheTable</span><span class="p">(</span><span class="s2">&quot;ventasCanada&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Una vez persistidos los datos, si accedemos a <a href="http://localhost:4040">http://localhost:4040</a> veremos en la pestaña <em>Storage</em> que se ha creado la tabla, su tipo de almacenamiento y particiones cacheadas:</p>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-persist.png">
    <figcaption>Elementos cacheados con Spark UI</figcaption>
</figure>

<p>Una diferencia fundamental a la hora de persistir un <em>DataFrame</em> en comparación con un RDD, es que como Spark SQL conoce el esquema de los datos en el <em>DataFrame</em>, puede organizarlos de forma columnar y aplicar compresión sobre éstos para minimizar el espacio necesario.</p>
<h2 id="dataframes-y-pandas">DataFrames y Pandas<a class="headerlink" href="#dataframes-y-pandas" title="Permanent link">&para;</a></h2>
<p>En cualquier momento podemos pasar los datos de un <em>DataFrame</em> de <em>PySpark</em> a uno de <em>Pandas</em> para poder aprovechar su API.</p>
<p>Si seguimos con el <em>dataset</em> de <em>Yelp</em>, vamos a preparar una consulta de nos devuelva la cantidad de votos recibidos y puntuación media de cada ciudad:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">count</span><span class="p">,</span> <span class="n">avg</span><span class="p">,</span> <span class="nb">round</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">dfVotosCiudades</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;city&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;city&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;votos&quot;</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg</span><span class="p">(</span><span class="s2">&quot;stars&quot;</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;media&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;votos&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span><span class="n">dfVotosCiudades</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +----------+-----+-----+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      city|votos|media|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># +----------+-----+-----+</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |   Phoenix| 5492|3.658|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |Scottsdale| 2617|3.809|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     Tempe| 1444| 3.64|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |      Mesa| 1348|3.644|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |  Chandler| 1178|3.677|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |  Glendale|  821|3.588|</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |   Gilbert|  630|3.755|</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |    Peoria|  385|3.614|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |  Surprise|  241|3.598|</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |  Goodyear|  214|3.498|</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># +----------+-----+-----+</span>
</code></pre></div>
<p>Nos traemos esos datos a <em>Pandas</em> mediante el método <strong><code>.toPandas()</code></strong>.:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">pdVC</span> <span class="o">=</span> <span class="n">dfVotosCiudades</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
</code></pre></div>
<p>A partir de este momento <code>pdVC</code> es un <em>DataFrame</em> de <em>Pandas</em>:</p>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-pandas09.png">
    <figcaption>Conversión a un DataFrame de Pandas</figcaption>
</figure>

<p>Y con el <em>DataFrame</em> de <em>Pandas</em>, ya podemos generar gráficos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="linenos" data-linenos=" 2 "></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="linenos" data-linenos=" 3 "></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="linenos" data-linenos=" 4 "></span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">plt</span><span class="o">.</span><span class="n">ticklabel_format</span><span class="p">(</span><span class="n">useOffset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;plain&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span><span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;votos&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;city&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">pdVC</span><span class="p">)</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Votos por Ciudad&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Votos emitidos&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="10 "></span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Ciudades&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-pandas01.png">
    <figcaption>Gráfico generado mediante Pandas y Spark</figcaption>
</figure>

<p>O por ejemplo, si queremos unir dos gráficos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="linenos" data-linenos="2 "></span><span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">pdVC</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;votos&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;city&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span>
<span class="linenos" data-linenos="5 "></span><span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
<span class="linenos" data-linenos="6 "></span><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">pdVC</span><span class="p">[</span><span class="s1">&#39;media&#39;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;crimson&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>Obteniendo:</p>
<figure style="align: center;">
    <img src="../imagenes/spark/02spark-pandas02.png">
    <figcaption>Gráfico generado mediante Pandas y Spark</figcaption>
</figure>

<div class="admonition warning">
<p class="admonition-title">Out of Memory</p>
<p>Mucho cuidado al utilizar Pandas, ya que al convertir el <em>DataFrame</em> nos vamos a traer todos los datos al driver, perdiendo la distribución de los datos y pudiendo provocar un error de falta de memoria.</p>
</div>
<p>Así pues, hay que evitar a toda costa utilizar <em>Pandas</em> para tratar los datos, ya que perdemos toda la potencia de trabajo en clúster (<em>Pandas</em> sólo puede utilizar los recursos del nodo principal). Únicamente lo utilizaremos cuando vayamos a visualizar los datos mediante <em>Matplotlib</em> / <em>Seaborn</em> como requisito de estas librerías.</p>
<!--
https://github.com/vivek-bombatkar/MyLearningNotes/tree/master/spark#from-pandas-to-spark
-->

<h2 id="referencias">Referencias<a class="headerlink" href="#referencias" title="Permanent link">&para;</a></h2>
<ul>
<li>Documentación oficial sobre <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL, DataFrames and Datasets Guide</a></li>
<li><a href="https://link.springer.com/book/10.1007/978-1-4842-7383-8">Beginning Apache Spark 3: With DataFrame, Spark SQL, Structured Streaming, and Spark Machine Learning Library</a></li>
<li><a href="https://sparkbyexamples.com/pyspark/">Spark by Examples</a></li>
<li><a href="https://towardsdatascience.com/the-most-complete-guide-to-pyspark-dataframes-2702c343b2e8">The Most Complete Guide to pySpark DataFrames</a></li>
<li><a href="http://datacamp-community-prod.s3.amazonaws.com/02213cb4-b391-4516-adcd-57243ced8eed">Spark SQL Cheatsheet en PDF</a> y en <a href="https://www.datacamp.com/blog/pyspark-cheat-sheet-spark-dataframes-in-python">formato web</a></li>
</ul>
<!--
2085680-8372834-1990332-1616010-5139491-4428950-8671321-4806110-3358726

Bomberos de San Francisco: https://data.sfgov.org/Public-Safety/Fire-Incidents/wr8u-xric/data 212MB
https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3 2139 MB
https://github.com/yukia3e/learning-spark-3/tree/master/src/sql/02_basic
-->

<h2 id="actividades">Actividades<a class="headerlink" href="#actividades" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>A partir del archivo <a href="../recursos/spark/nombres.json">nombres.json</a>, crea un DataFrame y realiza las siguientes operaciones:</p>
<ol>
<li>Crea una nueva columna (columna <code>Mayor30</code>) que indique si la persona es mayor de 30 años.</li>
<li>Crea una nueva columna (columna <code>FaltanJubilación</code>) que calcule cuantos años le faltan para jubilarse (supongamos que se jubila a los 67 años)</li>
<li>Crea una nueva columna (columna <code>Apellidos</code>) que contenga <code>XYZ</code> (puedes utilizar la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.lit.html"><code>lit</code></a>)</li>
<li>Elimina las columna <code>Mayor30</code> y <code>Apellidos</code>?</li>
<li>Crea una nueva columna (columna <code>AnyoNac</code>) con el año de nacimiento de cada persona (puedes utilizar la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.current_date.html"><code>current_date</code></a>).</li>
<li>Añade un id incremental para cada fila (campo <code>Id</code>) y haz que al hacer un <code>show</code> se vea en primer lugar (puedes utilizar la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.monotonically_increasing_id.html"><code>monotonically_increasing_id</code></a>) seguidos del <code>Nombre</code>, <code>Edad</code>, <code>AnyoNac</code>, <code>FaltaJubilacion</code> y <code>Ciudad</code></li>
</ol>
<p>Al realizar los seis pasos, el resultado del DataFrame será similar a :</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>+---+------+----+-------+----------------+--------+
<span class="linenos" data-linenos="2 "></span>| Id|Nombre|Edad|AnyoNac|FaltanJubilacion|  Ciudad|
<span class="linenos" data-linenos="3 "></span>+---+------+----+-------+----------------+--------+
<span class="linenos" data-linenos="4 "></span>|  0| Aitor|  45|   1977|              22|   Elche|
<span class="linenos" data-linenos="5 "></span>|  1| María|  23|   1999|              44|Alicante|
<span class="linenos" data-linenos="6 "></span>|  2| Laura|  19|   2003|              48|   Elche|
<span class="linenos" data-linenos="7 "></span>|  3| Sonia|  45|   1977|              22|    Aspe|
<span class="linenos" data-linenos="8 "></span>|  4| Pedro|null|   null|            null|   Elche|
<span class="linenos" data-linenos="9 "></span>+---+------+----+-------+----------------+--------+
</code></pre></div>
</li>
<li>
<p>(opcional) A partir del archivo <a href="../recursos/spark/VentasNulos.csv"><code>VentasNulos.csv</code></a>:</p>
<ol>
<li>
<p>Elimina las filas que tengan al menos 4 nulos.</p>
</li>
<li>
<p>Con las filas restantes, sustituye:</p>
<ol>
<li>Los nombres nulos por <code>Empleado</code></li>
<li>Las ventas nulas por la media de las ventas de los compañeros(redondeado a entero).</li>
<li>Los euros nulos por el valor del compañero que menos € ha ganado</li>
<li>La ciudad nula por <code>C.V.</code></li>
<li>El identificador nulo por <code>XYZ</code></li>
</ol>
<p>Para los pasos ii) y iii) puedes crear un <em>DataFrame</em> que obtenga el valor a asignar y luego pasarlo como parámetro al método para rellenar los nulos.</p>
</li>
</ol>
</li>
<li>
<p>A partir del archivo <a href="../recursos/spark/movies.tsv"><code>movies.tsv</code></a>, crea una esquema de forma declarativa con los campos:</p>
<ul>
<li><code>interprete</code> de tipo <code>string</code></li>
<li><code>pelicula</code> de tipo <code>string</code></li>
<li><code>anyo</code> de tipo <code>int</code></li>
</ul>
<p>Cada fila del fichero implica que el actor/actriz ha trabajado en dicha película en el año indicado.</p>
<ol>
<li>Una vez creado el esquema, carga los datos en un <em>DataFrame</em>.</li>
<li>¿Cuantas películas diferentes hay?</li>
<li>¿En cuantas películas ha trabajado <code>Murphy, Eddie (I)</code>?</li>
<li>Muestra los intérpretes que aparecen tanto en <code>Superman</code> como en <code>Superman II</code>.</li>
<li>¿Cuáles son los actores que han aparecido en más de 30 películas?</li>
<li>¿En que película anterior a 1980 aparecen al menos 25 intérpretes?</li>
<li>Muestra la cantidad de películas producidas cada año (solo debe mostrar el año y la cantidad), ordenando el listado por la cantidad de forma descendente.</li>
<li>A partir de la consulta anterior, crea un gráfico de barras que muestre el año y la cantidad de películas, ordenados por fecha.</li>
</ol>
</li>
<li>
<p>Vamos a seguir realizando analíticas de datos sobre las películas, ya que nos han enviado un nuevo archivo llamado <a href="../recursos/spark/movie-ratings.tsv"><code>movie-ratings.tsv</code></a> que contiene las calificaciones de las películas.</p>
<ol>
<li>Crea un DataFrame que contenga los datos de ambos <em>datasets</em>.</li>
<li>Muestra para cada año, la película con mayor puntuación (año, título de la película, puntuación)</li>
<li>Sobre los datos anteriores, obtén también una lista con los nombres de los intérpretes.</li>
<li>Averigua las tres parejas de intérpretes han trabajado juntos en más ocasiones. La salida debe tener tres columnas: <code>interprete1</code>, <code>interprete2</code> y <code>cantidad</code>. (necesitas utilizar un <em>self-join</em>)</li>
</ol>
</li>
<li>
<p>Hemos recibido un dataset con las ventas de 2019 de una tienda americana de productos de tecnología, mediante un conjunto de ficheros en formato CSV comprimidos en <a href="../recursos/spark/salesdata.zip">salesdata.zip</a>.</p>
<ol>
<li>Una vez descomprimidos los datos, crea un <em>DataFrame</em> con todos los datos, infiriendo el esquema.</li>
<li>
<p>Vuelve a realizar la lectura de los datos pero con el siguiente esquema:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">,</span> <span class="n">DoubleType</span>
<span class="linenos" data-linenos="2 "></span><span class="n">esquema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
<span class="linenos" data-linenos="3 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;Order ID&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;Product&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="5 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;Quantity Ordered&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
<span class="linenos" data-linenos="6 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;Price Each&quot;</span><span class="p">,</span> <span class="n">DoubleType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="7 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;Order Date&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="8 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;Purchase Address&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos="9 "></span><span class="p">])</span>
</code></pre></div>
</li>
<li>
<p>Tras la lectura, vamos a realizar la limpieza de datos. El primer paso será renombrar la columnas para eliminar los espacios en blanco.</p>
</li>
<li>Elimina las filas que contengan algún campo nulo.</li>
<li>Comprueba si las cabeceras de los archivos aparecen como datos del <em>dataset</em> (por ejemplo, un producto cuyo nombre sea <code>Product</code>). Si fuera el caso, elimina dichas filas.</li>
<li>A partir del campo dirección, crea dos nuevas columnas para almacenar la ciudad (<code>City</code>) y el estado (<code>State</code>). Por ejemplo, para la dirección <code>136 Church St, New York City, NY 10001</code>, la ciudad es <code>New York City</code> y el estado es <code>NY</code>.</li>
<li>Modifica el campo con la fecha del pedido para que su formato sea <em>timestamp</em>.</li>
<li>Sobre el campo anterior, crea dos nuevas columnas, con el mes (<code>Month</code>) y el año (<code>Year</code>) del pedido.</li>
<li>Almacena los datos en formato Parquet en la carpeta <code>salesoutput</code> particionando los datos por año y mes. Tras ejecutar esta operación, comprueba en disco la estructura de archivos creada.</li>
<li>Sobre los datos almacenados, realiza una nueva lectura pero solo leyendo los datos de 2019 los cuales deberían estar almacenados en <code>./salesdataoutput/Year=2019</code>.</li>
<li>
<p>Averigua cual ha sido el mes que ha recaudado más. Para ello, deberás multiplicar el precio por la cantidad de unidades, y posteriormente, realizar alguna agregación. Sobre el resultado, crea un gráfico similar al siguiente:</p>
<p><figure style="align: center;">
    <img src="../imagenes/spark/02ventas01.png">
    <figcaption>Ventas por mes</figcaption>
</figure></p>
</li>
<li>
<p>Obtén un gráfico con las 10 ciudades que más unidades han vendido.</p>
<p><figure style="align: center;">
    <img src="../imagenes/spark/02ventas02.png">
    <figcaption>Ciudades con más unidades vendidas</figcaption>
</figure></p>
</li>
<li>
<p>Cantidad de pedidos por Horas en las que se ha realizado un pedido que contenía al menos dos productos:</p>
<p><figure style="align: center;">
    <img src="../imagenes/spark/02ventas03.png">
    <figcaption>Pedidos de al menos dos productos por horas</figcaption>
</figure></p>
</li>
<li>
<p>Listado con los productos del estado de <code>NY</code> que se han comprado a la vez, obteniendo un resultado similar a:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>+------------------------------------------------------------+-----+
<span class="linenos" data-linenos="2 "></span>|Productos                                                   |count|
<span class="linenos" data-linenos="3 "></span>+------------------------------------------------------------+-----+
<span class="linenos" data-linenos="4 "></span>|[iPhone, Lightning Charging Cable]                          |126  |
<span class="linenos" data-linenos="5 "></span>|[Google Phone, USB-C Charging Cable]                        |124  |
<span class="linenos" data-linenos="6 "></span>|[Google Phone, Wired Headphones]                            |52   |
<span class="linenos" data-linenos="7 "></span>...
</code></pre></div>
</li>
</ol>
</li>
<li>
<p>(opcional) Vuelve a realizar todo el ejercicio anterior pero utilizando únicamente Spark SQL.</p>
</li>
</ol>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Volver al principio
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Pie">
      
        
        <a href="spark01rdd.html" class="md-footer__link md-footer__link--prev" aria-label="Anterior: 1.- Spark" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Anterior
              </span>
              1.- Spark
            </div>
          </div>
        </a>
      
      
        
        <a href="spark03streaming.html" class="md-footer__link md-footer__link--next" aria-label="Siguiente: 3.- Spark Streaming" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Siguiente
              </span>
              3.- Spark Streaming
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      2021-2022 Aitor Medrano - Licencia CC BY-NC-SA
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/aitormedrano" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    <a href="mailto:<a.medrano@edu.gva.es>" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M464 64c26.5 0 48 21.49 48 48 0 15.1-7.1 29.3-19.2 38.4L275.2 313.6a32.1 32.1 0 0 1-38.4 0L19.2 150.4C7.113 141.3 0 127.1 0 112c0-26.51 21.49-48 48-48h416zM217.6 339.2a63.9 63.9 0 0 0 76.8 0L512 176v208c0 35.3-28.7 64-64 64H64c-35.35 0-64-28.7-64-64V176l217.6 163.2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide", "navigation.top", "navigation.expand", "navigation.tracking", "content.code.annotate"], "search": "../assets/javascripts/workers/search.5e67fbfe.min.js", "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.config.lang": "es", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "B\u00fasqueda", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version.title": "Seleccionar versi\u00f3n"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c44cc438.min.js"></script>
      
    
  </body>
</html>