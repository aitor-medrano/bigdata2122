
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://aitor-medrano.github.io/bigdata2122/apuntes/spark02dataframe.html">
      
      <link rel="icon" href="../imagenes/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.8">
    
    
      
        <title>Spark DataFrames / SQL - Inteligencia Artificial y Big Data</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.644de097.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.e6a45f82.min.css">
        
          
          
          <meta name="theme-color" content="#02a6f2">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-MV889H0W63"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-MV889H0W63",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MV889H0W63"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="light-blue" data-md-color-accent="teal">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#spark-dataframes-sql" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-header__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Inteligencia Artificial y Big Data
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Spark DataFrames / SQL
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Búsqueda" placeholder="Búsqueda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando búsqueda
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Inteligencia Artificial y Big Data" class="md-nav__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../imagenes/logoIABD3.png" alt="logo">

    </a>
    Inteligencia Artificial y Big Data
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Inicio
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" data-md-state="indeterminate" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Arquitecturas Big Data
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Arquitecturas Big Data" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Arquitecturas Big Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube01.html" class="md-nav__link">
        1.- Cloud Computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube02aws.html" class="md-nav__link">
        2.- AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube03computacion.html" class="md-nav__link">
        3.- Computación
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube04almacenamiento.html" class="md-nav__link">
        4.- Almacenamiento
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="nube05datos.html" class="md-nav__link">
        5.- Datos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="arquitecturas01.html" class="md-nav__link">
        6.- Arquitecturas
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Ingesta de Datos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Ingesta de Datos" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Ingesta de Datos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta01.html" class="md-nav__link">
        1.- ETL
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta02pentaho.html" class="md-nav__link">
        2.- Pentaho DI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta03nifi1.html" class="md-nav__link">
        3.- Nifi I
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta04nifi2.html" class="md-nav__link">
        4.- Nifi II
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ingesta05python.html" class="md-nav__link">
        5.- Python y AWS
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" data-md-state="indeterminate" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Big Data Aplicado
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Big Data Aplicado" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Big Data Aplicado
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado01hadoop.html" class="md-nav__link">
        1.- Hadoop
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado02hdfs.html" class="md-nav__link">
        2.- HDFS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado03flume.html" class="md-nav__link">
        3.- Sqoop / Flume
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado04hive.html" class="md-nav__link">
        4.- Hive
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="bdaplicado05kafka.html" class="md-nav__link">
        5.- Kafka
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" data-md-state="indeterminate" type="checkbox" id="__nav_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Analítica de Datos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Analítica de Datos" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Analítica de Datos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="spark01rdd.html" class="md-nav__link">
        1.- Spark
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dataframes" class="md-nav__link">
    DataFrames
  </a>
  
    <nav class="md-nav" aria-label="DataFrames">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creando-dataframes" class="md-nav__link">
    Creando Dataframes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mostrando-los-datos" class="md-nav__link">
    Mostrando los datos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cargando-diferentes-formatos" class="md-nav__link">
    Cargando diferentes formatos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprimiendo-los-datos" class="md-nav__link">
    Comprimiendo los datos
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#datos-y-esquemas" class="md-nav__link">
    Datos y Esquemas
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataframe-api" class="md-nav__link">
    DataFrame API
  </a>
  
    <nav class="md-nav" aria-label="DataFrame API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#proyectando" class="md-nav__link">
    Proyectando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trabajando-con-columnas" class="md-nav__link">
    Trabajando con columnas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#filtrando" class="md-nav__link">
    Filtrando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ordenando" class="md-nav__link">
    Ordenando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anadiendo-filas" class="md-nav__link">
    Añadiendo filas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cogiendo-muestras" class="md-nav__link">
    Cogiendo muestras
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabajando-con-datos-sucios" class="md-nav__link">
    Trabajando con datos sucios
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#usando-sql" class="md-nav__link">
    Usando SQL
  </a>
  
    <nav class="md-nav" aria-label="Usando SQL">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vistas-temporales" class="md-nav__link">
    Vistas temporales
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vistas-globales" class="md-nav__link">
    Vistas globales
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tablas" class="md-nav__link">
    Tablas
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#agregaciones" class="md-nav__link">
    Agregaciones
  </a>
  
    <nav class="md-nav" aria-label="Agregaciones">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contando" class="md-nav__link">
    Contando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#calculando" class="md-nav__link">
    Calculando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agrupando" class="md-nav__link">
    Agrupando
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agrupando-colecciones" class="md-nav__link">
    Agrupando colecciones
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tablas-pivote" class="md-nav__link">
    Tablas pivote
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#joins" class="md-nav__link">
    Joins
  </a>
  
    <nav class="md-nav" aria-label="Joins">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mediante-sql" class="md-nav__link">
    Mediante SQL
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataframes-y-pandas" class="md-nav__link">
    DataFrames y Pandas
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    Referencias
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="spark-dataframes-sql">Spark DataFrames / SQL<a class="headerlink" href="#spark-dataframes-sql" title="Permanent link">&para;</a></h1>
<p>En la sesión anterior hemos introducido Spark y el uso de RDD para interactuar con los datos. Tal como comentamos, los RDD permiten trabajar a bajo nivel, siendo más cómodo y eficiente hacer uso de <em>DataFrames</em> y el lenguaje SQL.</p>
<h2 id="dataframes">DataFrames<a class="headerlink" href="#dataframes" title="Permanent link">&para;</a></h2>
<p>Un <em>DataFrame</em> es una estructura equivalente a una tabla de base de datos relacional, con un motor bien optimizado para el trabajo en un clúster. Los datos se almacenan en filas y columnas y ofrece un conjunto de operaciones para manipular los datos.</p>
<p>El trabajo con <em>DataFrames</em> es más sencillo y eficiente que el procesamiento con RDD, por eso su uso es predominante en los nuevos desarrollos con <em>Spark</em>.</p>
<p>A continuación veremos cómo podemos obtener y persistir <em>DataFrames</em> desde diferentes fuentes y formatos de datos</p>
<h3 id="creando-dataframes">Creando Dataframes<a class="headerlink" href="#creando-dataframes" title="Permanent link">&para;</a></h3>
<p>El caso más básico es crear un <em>DataFrame</em> a partir de una <em>SparkSession</em> pasándole un RDD:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span> <span class="c1"># SparkSession de forma programativa</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># Creamos un RDD</span>
<span class="linenos" data-linenos="5 "></span><span class="n">datos</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;Aitor&quot;</span><span class="p">,</span> <span class="mi">182</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;Pedro&quot;</span><span class="p">,</span> <span class="mi">178</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;Marina&quot;</span><span class="p">,</span> <span class="mi">161</span><span class="p">)]</span>
<span class="linenos" data-linenos="6 "></span><span class="n">rdd</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">datos</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># Creamos un DataFrame y mostramos su esquema</span>
<span class="linenos" data-linenos="8 "></span><span class="n">dfRDD</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>
<span class="linenos" data-linenos="9 "></span><span class="n">dfRDD</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<p>Y obtenemos un resumen del esquema del <em>DataFrame</em>, donde para cada columna se indica el nombre, el tipo y si admite valores nulos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>root
<span class="linenos" data-linenos="2 "></span> |-- _1: string (nullable = true)
<span class="linenos" data-linenos="3 "></span> |-- _2: long (nullable = true)
</code></pre></div>
<p>Podemos ver como los nombres de las columnas son <code>_1</code> y <code>_2</code>. Para asignarle un nombre adecuado podemos pasarle una lista con los nombres a la hora de crear el <em>DataFrame</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">columnas</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;nombre&quot;</span><span class="p">,</span><span class="s2">&quot;altura&quot;</span><span class="p">]</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfRDD</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="n">columnas</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfRDD</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<p>Y ahora obtenemos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>root
<span class="linenos" data-linenos="2 "></span> |-- nombre: string (nullable = true)
<span class="linenos" data-linenos="3 "></span> |-- altura: long (nullable = true)
</code></pre></div>
<p>Si queremos mostrar sus datos, haremos uso del método <code>show</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>df.show<span class="o">()</span>
</code></pre></div>
<p>Obteniendo una vista de los datos en forma de tabla:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>+------+------+
<span class="linenos" data-linenos="2 "></span>|nombre|altura|
<span class="linenos" data-linenos="3 "></span>+------+------+
<span class="linenos" data-linenos="4 "></span>| Aitor|   182|
<span class="linenos" data-linenos="5 "></span>| Pedro|   178|
<span class="linenos" data-linenos="6 "></span>|Marina|   161|
<span class="linenos" data-linenos="7 "></span>+------+------+
</code></pre></div>
<p>También podemos crear un <em>DataFrame</em> directamente desde una <em>SparkSession</em> sin crear un RDD previamente:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="c1"># También podemos crear un DF desde SparkSession</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfDesdeDatos</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">datos</span><span class="p">)</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="o">*</span><span class="n">columnas</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfDesdeDatos</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<h3 id="mostrando-los-datos">Mostrando los datos<a class="headerlink" href="#mostrando-los-datos" title="Permanent link">&para;</a></h3>
<p>Para los siguientes apartados, supongamos que queremos almacenar ciertos datos de clientes, como son su nombre y apellidos, ciudad y sueldo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">clientes</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos="2 "></span>    <span class="p">(</span><span class="s2">&quot;Aitor&quot;</span><span class="p">,</span> <span class="s2">&quot;Medrano&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">3000</span><span class="p">),</span>
<span class="linenos" data-linenos="3 "></span>    <span class="p">(</span><span class="s2">&quot;Pedro&quot;</span><span class="p">,</span> <span class="s2">&quot;Casas&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">4000</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>    <span class="p">(</span><span class="s2">&quot;Laura&quot;</span><span class="p">,</span> <span class="s2">&quot;García&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">5000</span><span class="p">),</span> 
<span class="linenos" data-linenos="5 "></span>    <span class="p">(</span><span class="s2">&quot;Miguel&quot;</span><span class="p">,</span> <span class="s2">&quot;Ruiz&quot;</span><span class="p">,</span> <span class="s2">&quot;Torrellano&quot;</span><span class="p">,</span> <span class="mi">6000</span><span class="p">),</span>
<span class="linenos" data-linenos="6 "></span>    <span class="p">(</span><span class="s2">&quot;Isabel&quot;</span><span class="p">,</span> <span class="s2">&quot;Guillén&quot;</span><span class="p">,</span> <span class="s2">&quot;Alicante&quot;</span><span class="p">,</span> <span class="mi">7000</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="p">]</span>
<span class="linenos" data-linenos="8 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clientes</span><span class="p">)</span>
</code></pre></div>
<p>Para mostrar los datos, ya hemos visto que podemos utilizar el método <code>show</code>, al cual le podemos indicar o no la cantidad de registros a recuperar, así como si queremos que los datos se trunquen o no, o si los queremos mostrar en vertical:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +------+---------+------+------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |nombre|apellidos|ciudad|sueldo|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +------+---------+------+------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># | Aitor|  Medrano| Elche|  3000|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># | Pedro|    Casas| Elche|  4000|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># +------+---------+------+------+</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># only showing top 2 rows</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |nombre|apellidos|ciudad    |sueldo|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |Aitor |Medrano  |Elche     |3000  |</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |Pedro |Casas    |Elche     |4000  |</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |Laura |García   |Elche     |5000  |</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |Miguel|Ruiz     |Torrellano|6000  |</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># |Isabel|Guillén  |Alicante  |7000  |</span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="19 "></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">vertical</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos" data-linenos="20 "></span><span class="c1"># -RECORD 0------------</span>
<span class="linenos" data-linenos="21 "></span><span class="c1">#  nombre    | Aitor   </span>
<span class="linenos" data-linenos="22 "></span><span class="c1">#  apellidos | Medrano </span>
<span class="linenos" data-linenos="23 "></span><span class="c1">#  ciudad    | Elche   </span>
<span class="linenos" data-linenos="24 "></span><span class="c1">#  sueldo    | 3000    </span>
<span class="linenos" data-linenos="25 "></span><span class="c1"># -RECORD 1------------</span>
<span class="linenos" data-linenos="26 "></span><span class="c1">#  nombre    | Pedro   </span>
<span class="linenos" data-linenos="27 "></span><span class="c1">#  apellidos | Casas   </span>
<span class="linenos" data-linenos="28 "></span><span class="c1">#  ciudad    | Elche   </span>
<span class="linenos" data-linenos="29 "></span><span class="c1">#  sueldo    | 4000    </span>
<span class="linenos" data-linenos="30 "></span><span class="c1"># -RECORD 2------------</span>
<span class="linenos" data-linenos="31 "></span><span class="c1">#  nombre    | Laura   </span>
<span class="linenos" data-linenos="32 "></span><span class="c1">#  apellidos | García  </span>
<span class="linenos" data-linenos="33 "></span><span class="c1">#  ciudad    | Elche   </span>
<span class="linenos" data-linenos="34 "></span><span class="c1">#  sueldo    | 5000    </span>
<span class="linenos" data-linenos="35 "></span><span class="c1"># only showing top 3 rows</span>
</code></pre></div>
<p>Si sólo queremos recuperar unos pocos datos, podemos hacer uso de <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.head.html">head</a> o <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.first.html">first</a> los cuales devuelven objetos <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Row.html">Row</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000)</span>
<span class="linenos" data-linenos="5 "></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># [Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000),</span>
<span class="linenos" data-linenos="7 "></span><span class="c1">#  Row(nombre=&#39;Pedro&#39;, apellidos=&#39;Casas&#39;, ciudad=&#39;Elche&#39;, sueldo=4000),</span>
<span class="linenos" data-linenos="8 "></span><span class="c1">#  Row(nombre=&#39;Laura&#39;, apellidos=&#39;García&#39;, ciudad=&#39;Elche&#39;, sueldo=5000)]</span>
</code></pre></div>
<p>También podemos obtener un sumario de los datos (igual que con <em>Pandas</em>) mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.describe.html">describe</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +-------+------+---------+----------+------------------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |summary|nombre|apellidos|    ciudad|            sueldo|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +-------+------+---------+----------+------------------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |  count|     5|        5|         5|                 5|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |   mean|  null|     null|      null|            5000.0|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | stddev|  null|     null|      null|1581.1388300841897|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |    min| Aitor|    Casas|  Alicante|              3000|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |    max| Pedro|     Ruiz|Torrellano|              7000|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+------+---------+----------+------------------+</span>
</code></pre></div>
<p>Si únicamente nos interesa saber cuantas filas tiene nuestro <em>DataFrame</em>, podemos hacer uso de <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.count.html">count</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># 5</span>
</code></pre></div>
<p>Por último, como un <em>DataFrame</em> por debajo es un RDD, podemos usar <code>collect</code> y <code>take</code> conforme necesitemos y recuperar objetos de tipo <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Row.html">Row</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># [Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000),</span>
<span class="linenos" data-linenos="3 "></span><span class="c1">#  Row(nombre=&#39;Pedro&#39;, apellidos=&#39;Casas&#39;, ciudad=&#39;Elche&#39;, sueldo=4000),</span>
<span class="linenos" data-linenos="4 "></span><span class="c1">#  Row(nombre=&#39;Laura&#39;, apellidos=&#39;García&#39;, ciudad=&#39;Elche&#39;, sueldo=5000),</span>
<span class="linenos" data-linenos="5 "></span><span class="c1">#  Row(nombre=&#39;Miguel&#39;, apellidos=&#39;Ruiz&#39;, ciudad=&#39;Torrellano&#39;, sueldo=6000),</span>
<span class="linenos" data-linenos="6 "></span><span class="c1">#  Row(nombre=&#39;Isabel&#39;, apellidos=&#39;Guillén&#39;, ciudad=&#39;Alicante&#39;, sueldo=7000)]</span>
<span class="linenos" data-linenos="7 "></span><span class="n">df</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># [Row(nombre=&#39;Aitor&#39;, apellidos=&#39;Medrano&#39;, ciudad=&#39;Elche&#39;, sueldo=3000),</span>
<span class="linenos" data-linenos="9 "></span><span class="c1">#  Row(nombre=&#39;Pedro&#39;, apellidos=&#39;Casas&#39;, ciudad=&#39;Elche&#39;, sueldo=4000)]</span>
</code></pre></div>
<h3 id="cargando-diferentes-formatos">Cargando diferentes formatos<a class="headerlink" href="#cargando-diferentes-formatos" title="Permanent link">&para;</a></h3>
<p>Lo más usual es cargar los datos desde una archivo externo. Para ello, mediante el API de <em>DataFrameReader</em> cargaremos los datos directamente en un <em>Dataframe</em> mediante diferentes métodos dependiendo del formato (admite tanto el nombre de un recurso como una ruta de una carpeta).</p>
<p>Para cada formato, existe un método corto que se llama como el formato en sí, y un método general que finaliza en con el método <code>load</code>, siempre dentro de <code>spark.read</code>:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:4"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><input id="__tabbed_1_4" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">CSV</label><label for="__tabbed_1_2">TXT</label><label for="__tabbed_1_3">JSON</label><label for="__tabbed_1_4">Parquet</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos/*.csv&quot;</span><span class="p">)</span>   <span class="c1"># Una carpeta entera</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span> <span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="5 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span> 
<span class="linenos" data-linenos="7 "></span><span class="n">dfCSV</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-csv.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfTXT</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># cada fichero se lee entero como un registro</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfTXT</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;wholetext&quot;</span><span class="p">,</span> <span class="n">true</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s2">&quot;datos/&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span>
<span class="linenos" data-linenos="5 "></span><span class="n">dfTXT</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-text.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfJSON</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfJSON</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-json.html">documentación oficial</a></p>
<div class="admonition caution">
<p class="admonition-title">DataFrames desde JSON</p>
<p><em>Spark</em> espera que cada documento JSON ocupe una única línea.</p>
</div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfParquet</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;datos.parquet&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfParquet</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;datos.parquet&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html">documentación oficial</a></p>
<div class="admonition caution">
<p class="admonition-title">DataFrames desde JSON</p>
<p><em>Spark</em> espera que cada documento JSON ocupe una única línea.</p>
</div>
</div>
</div>
</div>
<p>Si lo que queremos es persistir los datos, en vez de <code>read</code>, utilizaremos <code>write</code> y si usamos la forma general usaremos el método <code>save</code>:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:4"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><input id="__tabbed_2_4" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">CSV</label><label for="__tabbed_2_2">TXT</label><label for="__tabbed_2_3">JSON</label><label for="__tabbed_2_4">Parquet</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfCSV</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfCSV</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfCSV</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.csv&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-csv.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfTXT</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfTXT</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;lineSep&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfTXT</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.txt&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-text.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfJSON</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfJSON</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.json&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-json.html">documentación oficial</a></p>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfParquet</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;datos.parquet&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfParquet</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;datos.parquet&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Más información en la <a href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html">documentación oficial</a></p>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Un único archivo de salida</p>
<p>Por cada partición, Spark generará un archivo de salida. Recuerda que podemos <a href="spark01rdd.html#modificando-las-particiones">reducir el número de particiones</a> mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.coalesce.html">coalesce</a> o <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.repartition.html">repartition</a>.</p>
</div>
<p>Una vez vista la sintaxis, vamos a ver un ejemplo completo de lectura de un archivo CSV (el archivo <code>pdi_sales.csv</code> que hemos utilizado durante todo el curso) que está almacenado en HDFS y que tras leerlo, lo guardamos como JSON de nuevo en HDFS:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos=" 2 "></span>
<span class="linenos" data-linenos=" 3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;s8a-dataframe-csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="linenos" data-linenos=" 4 "></span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># Lectura de CSV con el ; como separador de columnas y con encabezado</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;delimiter&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;hdfs://iabd-virtualbox:9000/user/iabd/pdi_sales.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># df.printSchema()</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span><span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;hdfs://iabd-virtualbox:9000/user/iabd/pdi_sales_json&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Es conveniente destacar que para acceder a HDFS, únicamente hemos de indicar la URL del recurso con el prefijo <code>hdfs://</code> más el host del <em>namenode</em>.</p>
<h3 id="comprimiendo-los-datos">Comprimiendo los datos<a class="headerlink" href="#comprimiendo-los-datos" title="Permanent link">&para;</a></h3>
<p>Para configurar el algoritmo de compresión, si los datos está en Parquet o Avro, a nivel de la sesión de Spark, podemos realizar su configuración:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">spark</span><span class="o">.</span><span class="n">setConf</span><span class="p">(</span><span class="s2">&quot;spark.sql.parquet.compression.codec&quot;</span><span class="p">,</span><span class="s2">&quot;snappy&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">spark</span><span class="o">.</span><span class="n">setConf</span><span class="p">(</span><span class="s2">&quot;spark.sql.parquet.compression.codec&quot;</span><span class="p">,</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span><span class="o">.</span><span class="n">setConf</span><span class="p">(</span><span class="s2">&quot;spark.sql.avro.compression.codec&quot;</span><span class="p">,</span><span class="s2">&quot;snappy&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Si sólo queremos hacerlo para una operación en particular, para cada lectura/escritura le añadimos <code>.option("compression", "algoritmo")</code>. Por ejemplo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfVentas</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;compression&quot;</span><span class="p">,</span> <span class="s2">&quot;snappy&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;delimiter&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;pdi_sales.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfClientes</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;compression&quot;</span><span class="p">,</span> <span class="s2">&quot;snappy&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;clientes.parquet&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfVentas</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;compression&quot;</span><span class="p">,</span> <span class="s2">&quot;snappy&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;avro&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;ventas.avro&quot;</span><span class="p">)</span>
</code></pre></div>
<h2 id="datos-y-esquemas">Datos y Esquemas<a class="headerlink" href="#datos-y-esquemas" title="Permanent link">&para;</a></h2>
<p>El esquema completo de un <em>DataFrame</em> se modela mediante un <code>StructType</code>, el cual contiene una colección de objetos <code>StructField</code>.
Así pues, cada columna de un <em>DataFrame</em> de <em>Spark</em> se modela mediante un objeto <code>StructField</code> indicando su nombre, tipo y gestión de los nulos.</p>
<p>Hemos visto que al crear un <em>DataFrame</em> desde un archivo externo, podemos inferir el esquema. Si queremos crear un <em>DataFrame</em> desde un esquema propio utilizaremos los tipos <code>StructType</code>, <code>StructField</code>, así como <code>StringType</code>, <code>IntegerType</code> o el tipo necesario para cada columna. Para ello, primero hemos de importarlos (como puedes observar, estas clases pertenecen a las librerías SQL de <em>PySpark</em>):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">IntegerType</span>
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">Tipos</p>
<p>Además de cadenas y enteros, flotantes (<code>FloatType</code>) o dobles (<code>DoubleType</code>), tenemos tipos booleanos (<code>BooleanType</code>), de fecha (DateType y TimestampType), así como tipos complejos como <code>ArrayType</code>, <code>MapType</code> y <code>StructType</code>.
Para más información, consultar la <a href="https://spark.apache.org/docs/latest/sql-ref-datatypes.html">documentación oficial</a>.</p>
</div>
<p>Volvamos al ejemplo anterior donde tenemos ciertos datos de clientes, como son su nombre y apellidos, ciudad y sueldo:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">clientes</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos="2 "></span>    <span class="p">(</span><span class="s2">&quot;Aitor&quot;</span><span class="p">,</span> <span class="s2">&quot;Medrano&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">3000</span><span class="p">),</span>
<span class="linenos" data-linenos="3 "></span>    <span class="p">(</span><span class="s2">&quot;Pedro&quot;</span><span class="p">,</span> <span class="s2">&quot;Casas&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">4000</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>    <span class="p">(</span><span class="s2">&quot;Laura&quot;</span><span class="p">,</span> <span class="s2">&quot;García&quot;</span><span class="p">,</span> <span class="s2">&quot;Elche&quot;</span><span class="p">,</span> <span class="mi">5000</span><span class="p">),</span> 
<span class="linenos" data-linenos="5 "></span>    <span class="p">(</span><span class="s2">&quot;Miguel&quot;</span><span class="p">,</span> <span class="s2">&quot;Ruiz&quot;</span><span class="p">,</span> <span class="s2">&quot;Torrellano&quot;</span><span class="p">,</span> <span class="mi">6000</span><span class="p">),</span>
<span class="linenos" data-linenos="6 "></span>    <span class="p">(</span><span class="s2">&quot;Isabel&quot;</span><span class="p">,</span> <span class="s2">&quot;Guillén&quot;</span><span class="p">,</span> <span class="s2">&quot;Alicante&quot;</span><span class="p">,</span> <span class="mi">7000</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="p">]</span>
</code></pre></div>
<p>Para esta estructura, definiremos un esquema con los campos, indicando para cada uno de ellos su nombre, tipo y si admite valores nulos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">esquema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
<span class="linenos" data-linenos="2 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;nombre&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="3 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;apellidos&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;ciudad&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
<span class="linenos" data-linenos="5 "></span>    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;sueldo&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="p">])</span>
</code></pre></div>
<p>A continuación ya podemos crear un <em>DataFrame</em> con datos propios que cumplen un esquema haciendo uso del método <code>createDataFrame</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clientes</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">esquema</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># root</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1">#  |-- nombre: string (nullable = false)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1">#  |-- apellidos: string (nullable = false)</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1">#  |-- ciudad: string (nullable = true)</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1">#  |-- sueldo: integer (nullable = false)</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |nombre|apellidos|ciudad    |sueldo|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +------+---------+----------+------+</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |Aitor |Medrano  |Elche     |3000  |</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |Pedro |Casas    |Elche     |4000  |</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |Laura |García   |Elche     |5000  |</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |Miguel|Ruiz     |Torrellano|6000  |</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |Isabel|Guillén  |Alicante  |7000  |</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># +------+---------+----------+------+</span>
</code></pre></div>
<p>Respecto al esquema, tenemos diferentes propiedades como <code>columns</code>, <code>dtypes</code> y <code>schema</code> con las que obtener su información:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># [&#39;nombre&#39;, &#39;apellidos&#39;, &#39;ciudad&#39;, &#39;sueldo&#39;]</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># [(&#39;nombre&#39;, &#39;string&#39;),</span>
<span class="linenos" data-linenos="5 "></span><span class="c1">#  (&#39;apellidos&#39;, &#39;string&#39;),</span>
<span class="linenos" data-linenos="6 "></span><span class="c1">#  (&#39;ciudad&#39;, &#39;string&#39;),</span>
<span class="linenos" data-linenos="7 "></span><span class="c1">#  (&#39;sueldo&#39;, &#39;int&#39;)]</span>
<span class="linenos" data-linenos="8 "></span><span class="n">df</span><span class="o">.</span><span class="n">schema</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># StructType(List(StructField(nombre,StringType,false),StructField(apellidos,StringType,false),StructField(ciudad,StringType,true),StructField(sueldo,IntegerType,false)))</span>
</code></pre></div>
<p>Si una vez hemos cargado un <em>DataFrame</em> queremos cambiar el tipo de una de sus columnas, podemos hacer uso del método <code>withColumn</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;sueldo&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">sueldo</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">))</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># df = df.withColumn(&quot;fnac&quot;, to_date(df.Date, &quot;M/d/yyy&quot;))</span>
</code></pre></div>
<h2 id="dataframe-api">DataFrame API<a class="headerlink" href="#dataframe-api" title="Permanent link">&para;</a></h2>
<p>Una vez tenemos un <em>DataFrame</em> podemos trabajar con los datos mediante un conjunto de operaciones estructuradas, muy similares al lenguaje relacional. Estas operaciones también se clasifican en transformaciones y acciones, recordando que las transformaciones utilizan una evaluación perezosa.</p>
<div class="admonition tip">
<p class="admonition-title">Preparación</p>
<p>Para los siguientes apartados, vamos a trabajar sobre el siguiente <em>DataFrame</em> con el fichero de <a href="../recursos/pdi/pdi_sales_small.csv">ventas</a> que hemos utilizado a lo largo del curso:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;s8a-dataframes-api&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># Lectura de CSV con el ; como separador de columnas y con encabezado</span>
<span class="linenos" data-linenos="5 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span><span class="s2">&quot;;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;pdi_sales_small.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</code></pre></div>
<p>El esquema generado es:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>root
<span class="linenos" data-linenos="2 "></span>|-- ProductID: integer (nullable = true)
<span class="linenos" data-linenos="3 "></span>|-- Date: string (nullable = true)
<span class="linenos" data-linenos="4 "></span>|-- Zip: string (nullable = true)
<span class="linenos" data-linenos="5 "></span>|-- Units: integer (nullable = true)
<span class="linenos" data-linenos="6 "></span>|-- Revenue: double (nullable = true)
<span class="linenos" data-linenos="7 "></span>|-- Country: string (nullable = true)
</code></pre></div>
</div>
<h3 id="proyectando">Proyectando<a class="headerlink" href="#proyectando" title="Permanent link">&para;</a></h3>
<p>La operación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.select.html">select</a> permite indicar las columnas a recuperar pasándolas como parámetros:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">Consulta de columnas</label><label for="__tabbed_3_2">Resultado</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>+---------+-------+
<span class="linenos" data-linenos="2 "></span>|ProductID|Revenue|
<span class="linenos" data-linenos="3 "></span>+---------+-------+
<span class="linenos" data-linenos="4 "></span>|      725|  115.5|
<span class="linenos" data-linenos="5 "></span>|      787|  314.9|
<span class="linenos" data-linenos="6 "></span>|      788|  314.9|
<span class="linenos" data-linenos="7 "></span>+---------+-------+
<span class="linenos" data-linenos="8 "></span>only showing top 3 rows
</code></pre></div>
</div>
</div>
</div>
<p>También podemos realizar cálculos (referenciando a los campos con <code>nombreDataframe.nombreColumna</code>) sobre las columnas y crear un alias (operación asociada a un campo):</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">Cálculos y creación de alias</label><label for="__tabbed_4_2">Resultado</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">ProductID</span><span class="p">,(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;VentasMas10&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>+---------+-----------+
<span class="linenos" data-linenos="2 "></span>|ProductID|VentasMas10|
<span class="linenos" data-linenos="3 "></span>+---------+-----------+
<span class="linenos" data-linenos="4 "></span>|      725|      125.5|
<span class="linenos" data-linenos="5 "></span>|      787|      324.9|
<span class="linenos" data-linenos="6 "></span>|      788|      324.9|
<span class="linenos" data-linenos="7 "></span>+---------+-----------+
<span class="linenos" data-linenos="8 "></span>only showing top 3 rows
</code></pre></div>
</div>
</div>
</div>
<p>Si tenemos un <em>DataFrame</em> con un gran número de columnas y queremos recuperarlas todas a excepción de unas pocas, es más cómodo utilizar la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.drop.html">drop</a>, la cual funciona de manera opuesta a <code>select</code>, es decir, indicando las columnas que queremos quitar del resultado:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="c1"># Obtenemos el mismo resultado</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span> <span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="s2">&quot;Zip&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span><span class="p">,</span> <span class="s2">&quot;Country&quot;</span><span class="p">)</span>
</code></pre></div>
<h3 id="trabajando-con-columnas">Trabajando con columnas<a class="headerlink" href="#trabajando-con-columnas" title="Permanent link">&para;</a></h3>
<p>Para acceder a las columnas, debemos crear objetos <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.html">Column</a>. Para ello, podemos seleccionarnos a partir de un dataframe como una propiedad o mediante la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.col.html">col</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">nomCliente</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">nombre</span>
<span class="linenos" data-linenos="2 "></span><span class="n">nomCliente</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ProductID&quot;</span><span class="p">]</span>
<span class="linenos" data-linenos="3 "></span><span class="n">nomCliente</span> <span class="o">=</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Así pues, podemos recuperar ciertas columnas de un DataFrame con cualquier de las siguientes expresiones:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">ProductID</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="5 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;ProductID&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Revenue&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="6 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h4 id="col-vs-expr">col vs expr<a class="headerlink" href="#col-vs-expr" title="Permanent link">&para;</a></h4>
<p>En ocasiones se confunde el uso de la función <code>col</code> con <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.expr.html">expr</a>. Aunque podemos referenciar a una columna haciendo uso de <code>expr</code>, su uso provoca que se parsee la cadena recibida para interpretarla.</p>
<p>Para el siguiente ejemplo, supongamos que tenemos un DataFrame con datos de clientes. Utilizaremos también la función <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.concat_ws.html">concat_ws</a> para concatenar textos utilizado un separador.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span><span class="n">expr</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">concat_ws</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;nombre&quot;</span><span class="p">),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;apellidos&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;nombreCompleto&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span>          <span class="s2">&quot;sueldo&quot;</span><span class="p">,</span>
<span class="linenos" data-linenos="5 "></span>          <span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;sueldo&quot;</span><span class="p">)</span><span class="o">*</span><span class="mf">1.1</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;nuevoSueldo&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> 
<span class="linenos" data-linenos="6 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">concat_ws</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;nombre&quot;</span><span class="p">),</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;apellidos&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;nombreCompleto&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="7 "></span>          <span class="s2">&quot;sueldo&quot;</span><span class="p">,</span>
<span class="linenos" data-linenos="8 "></span>          <span class="n">expr</span><span class="p">(</span><span class="s2">&quot;sueldo*1.1&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;nuevoSueldo&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> 
</code></pre></div>
<h4 id="anadiendo-columnas">Añadiendo columnas<a class="headerlink" href="#anadiendo-columnas" title="Permanent link">&para;</a></h4>
<p>Una vez tenemos un <em>DataFrame</em>, podemos añadir columnas mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.withColumn.html">withColumn</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">dfNuevo</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;total&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">Units</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">dfNuevo</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country| total|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |      725|1999-01-15|41540          |    1|  115.5|Germany| 115.5|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      787|2002-06-06|41540          |    1|  314.9|Germany| 314.9|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |      788|2002-06-06|41540          |    1|  314.9|Germany| 314.9|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      901|1999-02-15|13587          |    2|  818.9|Germany|1637.8|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># ...</span>
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">withColumn</p>
<p>Anteriormente utilizamos el método <code>withColumn</code> para cambiarle el tipo a un campo ya existente. Así pues, si referenciamos a una columna existente, en vez de crearla, la sustituirá.</p>
</div>
<p>Otra forma de añadir una columna con una expresión es mediante la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.selectExpr.html">selectExpr</a>. Por ejemplo, podemos conseguir el mismo resultado que en el ejemplo anterior de la siguiente manera:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="s2">&quot;Units * Revenue as total&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span><span class="err">`</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country| total|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |      725|1999-01-15|41540          |    1|  115.5|Germany| 115.5|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |      787|2002-06-06|41540          |    1|  314.9|Germany| 314.9|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># |      788|2002-06-06|41540          |    1|  314.9|Germany| 314.9|</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># |      901|1999-02-15|13587          |    2|  818.9|Germany|1637.8|</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># ...</span>
</code></pre></div>
<p>Aunque más adelante veremos como realizar transformaciones con agregaciones, mediante <code>selectExpr</code> también podemos realizar analítica de datos aprovechando la potencia de SQL:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;count(distinct(ProductID)) as productos&quot;</span><span class="p">,</span><span class="s2">&quot;count(distinct(Country)) as paises&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------+------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |productos|paises|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------+------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |      799|     4|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># +---------+------+</span>
</code></pre></div>
<h4 id="cambiando-el-nombre">Cambiando el nombre<a class="headerlink" href="#cambiando-el-nombre" title="Permanent link">&para;</a></h4>
<p>Si por algún extraño motivo necesitamos cambiarle el nombre a una columna (por ejemplo, vamos a unir dos <em>DataFrames</em> que tienen columnas con el mismo nombre pero en posiciones diferentes, o que al inferir el esquema tenga un nombre críptico y queramos que sea más legible) podemos utilizar la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.withColumnRenamed.html">withColumnRenamed</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">,</span> <span class="s2">&quot;PostalCode&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |ProductID|      Date|     PostalCode|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      725|1999-01-15|41540          |    1|  115.5|Germany|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |      787|2002-06-06|41540          |    1|  314.9|Germany|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      788|2002-06-06|41540          |    1|  314.9|Germany|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |      940|1999-01-15|22587          |    1|  687.7|Germany|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      396|1999-01-15|22587          |    1|  857.1|Germany|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># only showing top 5 rows</span>
</code></pre></div>
<h3 id="filtrando">Filtrando<a class="headerlink" href="#filtrando" title="Permanent link">&para;</a></h3>
<p>Si queremos eliminar filas, usaremos el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.filter.html">filter</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="o">==</span><span class="s2">&quot;Germany&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |      725|1999-01-15|41540          |    1|  115.5|Germany|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |      787|2002-06-06|41540          |    1|  314.9|Germany|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># |      788|2002-06-06|41540          |    1|  314.9|Germany|</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># |      940|1999-01-15|22587          |    1|  687.7|Germany|</span>
</code></pre></div>
<p>Por similitud con SQL, podemos utilizar también <code>where</code> como un alias de <code>filter</code>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="o">&gt;</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      495|1999-03-15|75213 CEDEX 16 |   77|43194.1| France|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     2091|1999-05-15|9739           |   24| 3652.7| Mexico|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     2091|1999-06-15|40213          |   41| 6240.1|Germany|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |     2091|1999-10-15|40213          |   41| 6347.7|Germany|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     2091|1999-12-15|40213          |   23| 3560.9|Germany|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
</code></pre></div>
<p>Podemos utilizar los operadores lógicos (<code>&amp;</code> para conjunción y <code>|</code> para la disyunción) para crear condiciones compuestas (recordad rodear cada condición entre paréntesis)</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">((</span><span class="n">df</span><span class="o">.</span><span class="n">Country</span><span class="o">==</span><span class="s2">&quot;Germany&quot;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="o">&gt;</span><span class="mi">20</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |     2091|1999-06-15|40213          |   41| 6240.1|Germany|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     2091|1999-10-15|40213          |   41| 6347.7|Germany|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     2091|1999-12-15|40213          |   23| 3560.9|Germany|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">((</span><span class="n">df</span><span class="o">.</span><span class="n">ProductID</span><span class="o">==</span><span class="mi">2314</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">ProductID</span><span class="o">==</span><span class="mi">1322</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |ProductID|      Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |     2314|1999-05-15|46045          |    1|   13.9|Germany|</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |     1322|2000-01-06|75593 CEDEX 12 |    1|  254.5| France|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># +---------+----------+---------------+-----+-------+-------+</span>
</code></pre></div>
<p>Un caso particular de filtrado es la eliminación de los registros repetidos, lo cual lo podemos hacer de dos maneras:</p>
<ul>
<li>Haciendo uso del método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.distinct.html">distinct</a> tras haber realizado alguna transformación</li>
<li>Utilizando <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.dropDuplicates.html">dropDuplicates</a> sobre un <em>DataFrame</em>:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">dropDuplicates</span><span class="p">([</span><span class="s2">&quot;Country&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +-------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |Country|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Germany|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | France|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># | Mexico|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># | Canada|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+</span>
</code></pre></div>
<h3 id="ordenando">Ordenando<a class="headerlink" href="#ordenando" title="Permanent link">&para;</a></h3>
<p>Una vez recuperados los datos deseados, podemos ordenarlos mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sort.html">sort</a> u <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.orderBy.html">orderBy</a> (son operaciones totalmente equivalentes):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">.</span><span class="n">asc</span><span class="p">())</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># Ordenación descendiente</span>
<span class="linenos" data-linenos=" 7 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">.</span><span class="n">desc</span><span class="p">())</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos=" 9 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">desc</span>
<span class="linenos" data-linenos="10 "></span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># Ordenación diferente en cada columna</span>
<span class="linenos" data-linenos="12 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">.</span><span class="n">desc</span><span class="p">(),</span> <span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="o">.</span><span class="n">asc</span><span class="p">())</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="linenos" data-linenos="13 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">([</span><span class="s2">&quot;Revenue&quot;</span><span class="p">,</span><span class="s2">&quot;Units&quot;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<p>Por ejemplo, con la última operación obtendríamos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>+---------+----------+---------------+-----+-------+-------+
<span class="linenos" data-linenos=" 2 "></span>|ProductID|      Date|            Zip|Units|Revenue|Country|
<span class="linenos" data-linenos=" 3 "></span>+---------+----------+---------------+-----+-------+-------+
<span class="linenos" data-linenos=" 4 "></span>|      495|1999-03-15|75213 CEDEX 16 |   77|43194.1| France|
<span class="linenos" data-linenos=" 5 "></span>|      495|2000-03-01|75391 CEDEX 08 |   18|10395.0| France|
<span class="linenos" data-linenos=" 6 "></span>|      464|2003-06-11|75213 CEDEX 16 |   16|10075.8| France|
<span class="linenos" data-linenos=" 7 "></span>|      464|2000-08-01|22397          |   17| 9817.5|Germany|
<span class="linenos" data-linenos=" 8 "></span>|      495|2000-03-01|06175 CEDEX 2  |   16| 9240.0| France|
<span class="linenos" data-linenos=" 9 "></span>+---------+----------+---------------+-----+-------+-------+
<span class="linenos" data-linenos="10 "></span>only showing top 5 rows
</code></pre></div>
<p>Normalmente, tras realizar una ordenación, es habitual quedarse con un subconjunto de los datos. Para ello, podemos utilizar la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.limit.html">limit</a>.</p>
<p>Por ejemplo, la siguiente transformación es similar al ejemplo anterior, sólo que ahora al driver únicamente le llegan 5 registros, en vez de traerlos todos y sólo mostrar 5:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Revenue</span><span class="o">.</span><span class="n">desc</span><span class="p">(),</span> <span class="n">df</span><span class="o">.</span><span class="n">Units</span><span class="o">.</span><span class="n">asc</span><span class="p">())</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h3 id="anadiendo-filas">Añadiendo filas<a class="headerlink" href="#anadiendo-filas" title="Permanent link">&para;</a></h3>
<p>La única manera de añadir filas a un <em>DataFrame</em> es creando uno nuevo que sea el resultado de unir dos <em>DataFrames</em> que compartan el mismo esquema (mismo nombres de columnas y en el mismo orden). Para ello, utilizaremos la transformación <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.union.html">union</a> que realiza la unión por el orden de las columnas:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">nuevasVenta</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos="2 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-24&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mf">3333.33</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="3 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-25&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mf">2222.22</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos="4 "></span><span class="p">]</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># Creamos un nuevo DataFrame con las nuevas Ventas</span>
<span class="linenos" data-linenos="6 "></span><span class="n">nvDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">nuevasVenta</span><span class="p">)</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># Unimos los dos DataFrames</span>
<span class="linenos" data-linenos="8 "></span><span class="n">dfUpdated</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">nvDF</span><span class="p">)</span>
</code></pre></div>
<h3 id="cogiendo-muestras">Cogiendo muestras<a class="headerlink" href="#cogiendo-muestras" title="Permanent link">&para;</a></h3>
<p>Si necesitamos recoger un subconjunto de los datos, ya sea para preparar los datos para algún modelo de <em>machine learning</em> como para una muestra aleatoria de los mismos, podemos utilizar las siguientes transformaciones:</p>
<ul>
<li>
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sample.html">sample</a> permite obtener una muestra a partir de un porcentaje (no tiene porqué obtener una cantidad exacta). También admite un semilla e indicar si queremos que pueda repetir los datos.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>                  <span class="c1"># 120239</span>
<span class="linenos" data-linenos="2 "></span><span class="n">muestra</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mf">0.10</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">muestra</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>             <span class="c1"># 11876</span>
<span class="linenos" data-linenos="4 "></span><span class="n">muestraConRepetidos</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">)</span>
<span class="linenos" data-linenos="5 "></span><span class="n">muestraConRepetidos</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="c1"># 11923</span>
</code></pre></div>
</li>
<li>
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.randomSplit.html">randomSplit</a> recupera diferentes <em>DataFrames</em> cuyos tamaños en porcentaje se indican como parámetros (si no suman uno, los parámetros se normalizan):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dfs</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">randomSplit</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
<span class="linenos" data-linenos="2 "></span><span class="n">dfEntrenamiento</span> <span class="o">=</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos" data-linenos="3 "></span><span class="n">dfPrueba</span> <span class="o">=</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos" data-linenos="4 "></span><span class="n">dfEntrenamiento</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>     <span class="c1"># 96194</span>
<span class="linenos" data-linenos="5 "></span><span class="n">dfPrueba</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>            <span class="c1"># 24045</span>
</code></pre></div>
</li>
</ul>
<p>FIXME: ampliar con muestras por estratos</p>
<ul>
<li>sampleBy</li>
</ul>
<h2 id="trabajando-con-datos-sucios">Trabajando con datos sucios<a class="headerlink" href="#trabajando-con-datos-sucios" title="Permanent link">&para;</a></h2>
<p>Hay tres formas de gestionar la suciedad de los datos o la omisión completa de los mismos:</p>
<ol>
<li>Eliminar las filas que tienen valores vacíos en una o más columnas.</li>
<li>Rellenar los valores nulos con valores que definimos nosotros.</li>
<li>Sustituir los datos erróneos por algún valor que sepamos como gestionarlo.</li>
</ol>
<p>Vamos a ver cada uno de estos casos a partir del siguiente <em>dataset</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">malasVentas</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-22&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mf">3333.33</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-22&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mf">3333.33</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-23&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mf">2222.22</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="p">(</span><span class="mi">6666</span><span class="p">,</span> <span class="s2">&quot;2022-03-24&quot;</span><span class="p">,</span> <span class="s2">&quot;03206&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Espain&quot;</span><span class="p">),</span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span><span class="p">]</span>
<span class="linenos" data-linenos=" 8 "></span><span class="n">malDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">malasVentas</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;ProductID&quot;</span><span class="p">,</span> <span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="s2">&quot;Zip&quot;</span><span class="p">,</span> <span class="s2">&quot;Units&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span> <span class="p">,</span> <span class="s2">&quot;Country&quot;</span><span class="p">])</span>
<span class="linenos" data-linenos=" 9 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |     6666|2022-03-22| null|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null| Espain|</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># |     6666|2022-03-25|03206| null|2222.22|   null|</span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
</code></pre></div>
<p>Si queremos saber si una columna contiene nulos, podemos hacer un filtrado utilizando el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.isNull.html">isNull</a> sobre los campos deseados (también podemos utilizar <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.isNotNull.html">isNotNull</a> si queremos el caso contrario):</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">malDF</span><span class="o">.</span><span class="n">Zip</span><span class="o">.</span><span class="n">isNull</span><span class="p">())</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +---------+----------+----+-----+-------+-------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |ProductID|      Date| Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +---------+----------+----+-----+-------+-------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |     6666|2022-03-22|null|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># +---------+----------+----+-----+-------+-------+</span>
</code></pre></div>
<p>Para trabajar con las filas que contengan algún dato nulo, podemos acceder a la propiedad <code>na</code> que devuelve un <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameNaFunctions.html">DataFrameNaFunctions</a> sobre la cual podemos indicarle:</p>
<ul>
<li>
<p>que la elimine mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameNaFunctions.drop.html">drop</a>. Puede recibir <code>"any"</code> (borrará las filas que contengan algún nulo), <code>"all"</code> (borrará las filas que todas sus columnas contengan nulos) y una lista con las columnas a considerar:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># Elimina todos los nulos</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># Elimina las filas que todas sus columnas son nulas</span>
<span class="linenos" data-linenos="10 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># |     6666|2022-03-22| null|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos="17 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null| Espain|</span>
<span class="linenos" data-linenos="18 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span><span class="c1"># Elimina las filas que tienen el Zip nulo</span>
<span class="linenos" data-linenos="21 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Zip&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="22 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="23 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos="24 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos="25 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos="26 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos="27 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null| Espain|</span>
<span class="linenos" data-linenos="28 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
</code></pre></div>
</li>
<li>
<p>que la rellene mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameNaFunctions.fill.html">fill</a>, indicando el valor y si queremos, sobre qué columnas aplicar la modificación:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># Rellenamos los zips vacios por 99999</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="s2">&quot;99999&quot;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Zip&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     6666|2022-03-22|99999|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null| Espain|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |     null|      null|99999| null|   null|   null|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
</code></pre></div>
</li>
<li>
<p>que la sustituya mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameNaFunctions.replace.html">replace</a></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># Cambiamos Espain por Spain</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">malDF</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;Espain&quot;</span><span class="p">,</span> <span class="s2">&quot;Spain&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |ProductID|      Date|  Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |     6666|2022-03-22|03206|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |     6666|2022-03-22| null|   33|3333.33|  Spain|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |     6666|2022-03-23|03206| null|2222.22|  Spain|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |     6666|2022-03-24|03206| null|   null|  Spain|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |     null|      null| null| null|   null|   null|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +---------+----------+-----+-----+-------+-------+</span>
</code></pre></div>
</li>
</ul>
<p>Otro caso muy común es realizar una operación sobre una columna para transformar su valor, por ejemplo, pasar todo el texto a minúsculas o dividir una columna entre 100 para cambiar la escala.</p>
<p>En nuestro caso, vamos a modificar las columnas <em>Zip</em> y <em>Country</em> para realizar un <code>trim</code> y borrar los espacios en blanco:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">trim</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">,</span> <span class="n">trim</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)))</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">,</span> <span class="n">trim</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">)))</span>
</code></pre></div>
<h2 id="usando-sql">Usando SQL<a class="headerlink" href="#usando-sql" title="Permanent link">&para;</a></h2>
<p>En la era del big data, SQL es la lengua franca, permitiendo a perfiles con pocos conocimientos de programación trabajar de forma eficiente con los datos (siempre poniendo el foco en la analítica de datos, no en el procesamiento transaccional).</p>
<p>Spark soporta el ANSI SQL 2003, ampliamente establecido en el mundo de las bases de datos.</p>
<p>Para correr SQL en Spark podemos hacerlo a través de:</p>
<ul>
<li>El cliente SQL, es cual se ofrece como un comando en <code>./bin/spark-sql</code></li>
<li>Mediante un servidor ODBC/JDBC</li>
<li>De forma programativa mediante aplicaciones Spark.</li>
</ul>
<p>Las dos primeras opciones se integran con Apache Hive para utilizar su metastore. Ahora nos vamos a centrar en la última.</p>
<h3 id="vistas-temporales">Vistas temporales<a class="headerlink" href="#vistas-temporales" title="Permanent link">&para;</a></h3>
<p>Ya hemos visto que los <em>DataFrames</em> tienen una estructura similar a una tabla de una base de datos relacional. Para poder realizar consultas, necesitaremos crear vistas temporales mediante el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.createOrReplaceTempView.html">createOrReplaceTempView</a> para posteriormente realizar una consulta sobre la vista creada a través de <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.sql.html">spark.sql</a>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># 1. definimos la vista</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;ventas&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># 2. realizamos la consulta</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">ventasCanada</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select * from ventas where trim(Country)=&#39;Canada&#39;&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">ventasCanada</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |ProductID|     Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      725|1/15/1999|H1B            |    1|  115.4|Canada |</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |     2235|1/15/1999|H1B            |    2|  131.1|Canada |</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |      713|1/15/1999|H1B            |    1|  160.1|Canada |</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># only showing top 3 rows</span>
</code></pre></div>
<h3 id="vistas-globales">Vistas globales<a class="headerlink" href="#vistas-globales" title="Permanent link">&para;</a></h3>
<p>Las vistas temporales tienen un alcance de <em>SparkSession</em>, de manera que desaparecen una vez finalice la sesión que ha creado la vista. Si necesitamos tener una vista que se comparta entre todas las sesiones y que permanezca viva hasta que la aplicación <em>Spark</em> finalice, podemos crear una vista temporal global.</p>
<p>Estas vistas se almacenan en la base de datos <code>global_temp</code> y en las consultas es necesario poner el prefijo <code>global_temp</code> para acceder a la sus vistas.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># 1. definimos la vista global</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceGlobalTempView</span><span class="p">(</span><span class="s2">&quot;ventasg&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># 2. realizamos la consulta</span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">ventasCanadaG</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select * from global_temp.ventasg where trim(Country)=&#39;Canada&#39;&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="n">ventasCanadaG</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |ProductID|     Date|            Zip|Units|Revenue|Country|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      725|1/15/1999|H1B            |    1|  115.4|Canada |</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |     2235|1/15/1999|H1B            |    2|  131.1|Canada |</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># |      713|1/15/1999|H1B            |    1|  160.1|Canada |</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># +---------+---------+---------------+-----+-------+-------+</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># only showing top 3 rows</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># Creamos otra sesión y vemos como funciona</span>
<span class="linenos" data-linenos="16 "></span><span class="n">spark</span><span class="o">.</span><span class="n">newSession</span><span class="p">()</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select count(*) from global_temp.ventasg where trim(Country)=&#39;Canada&#39;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h3 id="tablas">Tablas<a class="headerlink" href="#tablas" title="Permanent link">&para;</a></h3>
<p>Otra forma de trabajar con SQL es creando bases de datos y tablas de forma similar al planteamiento de Hive.</p>
<p>CREATE DATABASE
CREATE TABLE
???</p>
<p><a href="https://medium.com/@durgaswaroop/list-tables-and-databases-in-spark-2d03594d2883">https://medium.com/@durgaswaroop/list-tables-and-databases-in-spark-2d03594d2883</a></p>
<h2 id="agregaciones">Agregaciones<a class="headerlink" href="#agregaciones" title="Permanent link">&para;</a></h2>
<p>Una vez tenemos un DataFrame, podemos realizar analítica de datos sobre el <em>dataset</em> entero, o sobre una o más columnas y aplicar una función de agregación que permita sumar, contar o calcular la media de cualquier grupo, entre otras opciones.</p>
<p>Para ello, <em>PySpark</em> ofrece un amplio <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions">conjunto de funciones</a>. En nuestro caso, vamos a realizar algunos ejemplos para practicar con las funciones más empleadas.</p>
<h3 id="contando">Contando<a class="headerlink" href="#contando" title="Permanent link">&para;</a></h3>
<div class="tabbed-set tabbed-alternate" data-tabs="5:3"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><input id="__tabbed_5_3" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">count</label><label for="__tabbed_5_2">count_distinct</label><label for="__tabbed_5_3">approx_count_distinct</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.count.html">count</a>: Devuelve la cantidad de elementos no nulos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">count</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +--------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |count(Country)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +--------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |        120239|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +--------------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.count_distinct.html">count_distinct / countDistinct</a>: Devuelve la cantidad de elementos no nulos diferentes:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">count_distinct</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">count_distinct</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">),</span> <span class="n">count_distinct</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +-----------------------+-------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |count(DISTINCT Country)|count(DISTINCT Zip)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +-----------------------+-------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |                      4|               2585|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +-----------------------+-------------------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.approx_count_distinct.html">approx_count_distinct / approxCountDistinct</a>: Devuelve aproximadamente la cantidad de elementos no nulos diferentes (puede recibir un segundo parámetro la máximo desviación estándar admitida). Este método es mucho más rápido que contar exactamente el número de resultado, y para datasets muy grandes, en ocasiones puede ser útil:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">approx_count_distinct</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">approx_count_distinct</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">),</span> <span class="n">approx_count_distinct</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +------------------------------+--------------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |approx_count_distinct(Country)|approx_count_distinct(Zip)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +------------------------------+--------------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |                             4|                      2737|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +------------------------------+--------------------------+</span>
</code></pre></div>
</div>
</div>
</div>
<h3 id="calculando">Calculando<a class="headerlink" href="#calculando" title="Permanent link">&para;</a></h3>
<div class="tabbed-set tabbed-alternate" data-tabs="6:4"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><input id="__tabbed_6_2" name="__tabbed_6" type="radio" /><input id="__tabbed_6_3" name="__tabbed_6" type="radio" /><input id="__tabbed_6_4" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">min y max</label><label for="__tabbed_6_2">sum</label><label for="__tabbed_6_3">sum_distinct</label><label for="__tabbed_6_4">avg</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.min.html">min</a> y <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.max.html">max</a> permiten obtener el menor y el mayor valor respectivamente:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +----------+----------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |min(Units)|max(Units)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +----------+----------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |         1|        77|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +----------+----------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.sum.html">sum</a> permite sumar todos los valores de una columna:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">sum</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">),</span> <span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +----------+--------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |sum(Units)|        sum(Revenue)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +----------+--------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |    125728|5.0107274999986745E7|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +----------+--------------------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.sum_distinct.html">sum_distinct / sumDistinct</a> suma los valores diferentes de una columna:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">sum_distinct</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">sum_distinct</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">),</span> <span class="n">sum_distinct</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +-------------------+---------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |sum(DISTINCT Units)|sum(DISTINCT Revenue)|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +-------------------+---------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |                308|   1189127.0999999985|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +-------------------+---------------------+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.avg.html">avg</a> calcula la media aritmética:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">sum</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">avg</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">avg</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">),</span> <span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">/</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># +-----------------+-------------------------------+</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># |     avg(Revenue)|(sum(Revenue) / count(Revenue))|</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># +-----------------+-------------------------------+</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># |416.7306364822291|              416.7306364822291|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># +-----------------+-------------------------------+</span>
</code></pre></div>
</div>
</div>
</div>
<div class="admonition info">
<p class="admonition-title">Asimetría, varianza y desviación estándard</p>
<p>Si nos interesa obtener información estadística sobre los datos, también disponemos de las funciones <code>skewness</code>, <code>kurtosis</code>, <code>variance</code>, <code>var_pop</code>, <code>stddev</code> y <code>stddev_pop</code>.</p>
</div>
<h3 id="agrupando">Agrupando<a class="headerlink" href="#agrupando" title="Permanent link">&para;</a></h3>
<p>Si agrupamos varias columnas de tipo categóricas (con una cardinalidad baja), podemos realizar cálculos sobre el resto de columnas.</p>
<p>Sobre un <em>DataFrame</em>, podemos agrupar los datos por la columna que queramos utilizando el método <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.groupBy.html">groupBy</a>, el cual nos devuelve un <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.GroupedData.html#pyspark.sql.GroupedData">GroupedData</a>, sobre el que posteriormente realizar operaciones como <code>avg(cols)</code>, <code>count()</code>, <code>mean(cols)</code>, <code>min(cols)</code>, <code>max(cols)</code> o <code>sum(cols)</code>:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="7:2"><input checked="checked" id="__tabbed_7_1" name="__tabbed_7" type="radio" /><input id="__tabbed_7_2" name="__tabbed_7" type="radio" /><div class="tabbed-labels"><label for="__tabbed_7_1">count</label><label for="__tabbed_7_2">sum</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">sum</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +-------+-----+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |Country|count|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------+-----+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Germany|30059|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | France|30060|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># | Mexico|30060|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># | Canada|30060|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+-----+</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">sum</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +-------+--------------------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |Country|        sum(Revenue)|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------+--------------------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Germany|1.4982119999999512E7|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | France|1.2087942100000832E7|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># | Mexico| 1.139459870000116E7|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># | Canada|1.1642614200001905E7|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+--------------------+</span>
</code></pre></div>
</div>
</div>
</div>
<p>Si necesitamos realizar más de un agregación sobre el mismo grupo, mediante <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.GroupedData.agg.html">agg</a> podemos indicar una o más expresiones de columnas:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">),</span> <span class="n">count</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +-------+--------------------+--------------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |Country|        sum(Revenue)|count(Revenue)|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +-------+--------------------+--------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |Germany|1.4982119999999512E7|         30059|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># | France|1.2087942100000832E7|         30060|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># | Mexico| 1.139459870000116E7|         30060|</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># | Canada|1.1642614200001905E7|         30060|</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># +-------+--------------------+--------------+</span>
</code></pre></div>
<p>También podemos indicar los elementos a calcular mediante un diccionario donde las claves son los campos y los valores la función a calcular:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">&quot;Zip&quot;</span><span class="p">:</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="s2">&quot;Revenue&quot;</span><span class="p">:</span><span class="s2">&quot;avg&quot;</span><span class="p">})</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># +-------+----------+------------------+</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># |Country|count(Zip)|      avg(Revenue)|</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># +-------+----------+------------------+</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># |Germany|     30059| 498.4237665923521|</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># | France|     30060| 402.1271490352905|</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># | Mexico|     30060| 379.0618330007039|</span>
<span class="linenos" data-linenos="8 "></span><span class="c1"># | Canada|     30060|387.31251497012323|</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># +-------+----------+------------------+</span>
</code></pre></div>
<h3 id="agrupando-colecciones">Agrupando colecciones<a class="headerlink" href="#agrupando-colecciones" title="Permanent link">&para;</a></h3>
<p>En ocasiones necesitamos agrupar en una colección todos los valores para un grupo en particular. Para ello, podemos usar <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.collect_list.html">collect_list</a> (con repetidos) o <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.collect_set.html">collect_set</a> (sin repeticiones):</p>
<p>Por ejemplo, para cada pais, vamos a recuperar un listado con los códigos postales de aquellos pedidos que hayan superado las 5 unidades:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">collect_list</span><span class="p">,</span> <span class="n">collect_set</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="s2">&quot;Units &gt; 5&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">collect_list</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">),</span> <span class="n">collect_set</span><span class="p">(</span><span class="s2">&quot;Zip&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># +-------+--------------------+--------------------+</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># |Country|   collect_list(Zip)|    collect_set(Zip)|</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># +-------+--------------------+--------------------+</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |Germany|[22397, 22111, 40...|[22111, 12589, 22...|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># | France|[75213 CEDEX 16, ...|[06082 CEDEX 1, 0...|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># | Mexico|[7100, 7810, 9739...|[9739, 10300, 781...|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># | Canada|[T2X, V6G, V6G, T6V]|     [V6G, T2X, T6V]|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># +-------+--------------------+--------------------+</span>
</code></pre></div>
<h3 id="tablas-pivote">Tablas pivote<a class="headerlink" href="#tablas-pivote" title="Permanent link">&para;</a></h3>
<p>Las tablas pivote permite obtener un resumen de los datos a partir de columnas categóricas sobre la que realizar cálculos, tal como se hace en las hojas de cálculo con las tablas dinámicas.</p>
<p>Por ejemplo, vamos a obtener la cantidad recaudada por las ventas de cada año por cada pais:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">year</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +----------+------------------+------------------+------------------+------------------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |year(Date)|            Canada|            France|           Germany|            Mexico|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +----------+------------------+------------------+------------------+------------------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      2003| 2360085.999999947|1105230.9000000046|1407120.0000000007|         1049457.5|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |      2004| 1539140.499999946|              null|              null|              null|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      2001| 2193437.799999908|              null|              null|233419.20000000004|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |      2000|1806678.3999999042|1108846.8999999764| 4510606.799999941| 4240448.399999928|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      1999|1382756.6999999764| 7594921.200000435| 5928459.100000297|3419368.2000001906|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |      2002|2360514.7999998857| 2278943.099999957| 3135934.099999964|2451905.3999999263|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +----------+------------------+------------------+------------------+------------------+</span>
</code></pre></div>
<p>También podemos hacer más de un cálculo sobre la tabla pivote:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">year</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Revenue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total&quot;</span><span class="p">),</span> <span class="nb">sum</span><span class="p">(</span><span class="s2">&quot;Units&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;cantidad&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="linenos" data-linenos=" 2 "></span><span class="c1"># +----------+------------------+---------------+------------------+---------------+------------------+----------------+------------------+---------------+</span>
<span class="linenos" data-linenos=" 3 "></span><span class="c1"># |year(Date)|      Canada_total|Canada_cantidad|      France_total|France_cantidad|     Germany_total|Germany_cantidad|      Mexico_total|Mexico_cantidad|</span>
<span class="linenos" data-linenos=" 4 "></span><span class="c1"># +----------+------------------+---------------+------------------+---------------+------------------+----------------+------------------+---------------+</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># |      2003| 2360085.999999947|           6375|1105230.9000000046|           2794|1407120.0000000007|            3099|         1049457.5|           2510|</span>
<span class="linenos" data-linenos=" 6 "></span><span class="c1"># |      2004| 1539140.499999946|           3636|              null|           null|              null|            null|              null|           null|</span>
<span class="linenos" data-linenos=" 7 "></span><span class="c1"># |      2001| 2193437.799999908|           5976|              null|           null|              null|            null|233419.20000000004|            583|</span>
<span class="linenos" data-linenos=" 8 "></span><span class="c1"># |      2000|1806678.3999999042|           5049|1108846.8999999764|           2456| 4510606.799999941|            9738| 4240448.399999928|          11935|</span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># |      1999|1382756.6999999764|           3964| 7594921.200000435|          20432| 5928459.100000297|           12266|3419368.2000001906|           9895|</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |      2002|2360514.7999998857|           6148| 2278943.099999957|           6057| 3135934.099999964|            6643|2451905.3999999263|           6172|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +----------+------------------+---------------+------------------+---------------+------------------+----------------+------------------+---------------+</span>
</code></pre></div>
<h2 id="joins">Joins<a class="headerlink" href="#joins" title="Permanent link">&para;</a></h2>
<p>Hasta ahora todo la analítica la hemos realizado sobre un único <em>DataFrame</em>. Aunque si seguimos un proceso ELT es probable que tengamos todos los datos en un único lugar, en ocasiones necesitamos cruzar la información de dos datasets.</p>
<p>Si nos basamos en el planteamiento de una base de datos relacional, Para unir dos DataFrames necesitamos unir la clave ajena de uno con la clave primaria del otro.</p>
<p>Para estos ejemplos, vamos a cambiar de <em>datasets</em> y utilizar datos de vuelos de avión que han tenido algún tipo de retraso (<a href="../recursos/spark/departure_delays.csv">departure_delays.csv</a>) y otro con los códigos de los aeropuertos (<a href="../recursos/spark/airport-codes-na.tsv">airport-codes-na.tsv</a>).</p>
<div class="tabbed-set tabbed-alternate" data-tabs="8:2"><input checked="checked" id="__tabbed_8_1" name="__tabbed_8" type="radio" /><input id="__tabbed_8_2" name="__tabbed_8" type="radio" /><div class="tabbed-labels"><label for="__tabbed_8_1">Vuelos con retraso</label><label for="__tabbed_8_2">Códigos de aeropuertos</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>Fichero CSV con la coma como separador de campos.</p>
<div class="highlight"><span class="filename">departure_delays.csv</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span>date,delay,distance,origin,destination
<span class="linenos" data-linenos="2 "></span>01011245,6,602,ABE,ATL
<span class="linenos" data-linenos="3 "></span>01020600,-8,369,ABE,DTW
<span class="linenos" data-linenos="4 "></span>01021245,-2,602,ABE,ATL
<span class="linenos" data-linenos="5 "></span>01020605,-4,602,ABE,ATL
</code></pre></div>
</div>
<div class="tabbed-block">
<p>Fichero TSV con el tabulador como separador campos</p>
<div class="highlight"><span class="filename">airport-codes-na.tsv</span><pre><span></span><code><span class="linenos" data-linenos="1 "></span>City State Country IATA
<span class="linenos" data-linenos="2 "></span>Abbotsford BC Canada YXX
<span class="linenos" data-linenos="3 "></span>Aberdeen SD USA ABR
<span class="linenos" data-linenos="4 "></span>Abilene TX USA ABI
<span class="linenos" data-linenos="5 "></span>Akron OH USA CAK
<span class="linenos" data-linenos="6 "></span>Alamosa CO USA ALS
<span class="linenos" data-linenos="7 "></span>Albany GA USA ABY
</code></pre></div>
</div>
</div>
</div>
<p>Así pues, lo primero que vamos a hacer es cargar ambos <em>DataFrames</em>:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;s8a-dataframes-joins&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="linenos" data-linenos="4 "></span>
<span class="linenos" data-linenos="5 "></span><span class="n">df_vuelos</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span><span class="s2">&quot;,&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;departure_delays.csv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span><span class="c1"># df_vuelos.printSchema()</span>
<span class="linenos" data-linenos="7 "></span><span class="c1"># df_vuelos.count()   # 1391578</span>
<span class="linenos" data-linenos="8 "></span><span class="n">df_aeropuertos</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;airport-codes-na.tsv&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="9 "></span><span class="c1"># df_aeropuertos.printSchema()</span>
</code></pre></div>
<h3 id="mediante-sql">Mediante SQL<a class="headerlink" href="#mediante-sql" title="Permanent link">&para;</a></h3>
<p>Si queremos hacer un <em>join</em> mediante SQL, sólo tenemos que emplear la misma sintaxis que con cualquier sistema relacional, de manera que primero crearemos las vistas temporales y luego realizaremos la consulta:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="n">df_vuelos</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;vuelos&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 2 "></span><span class="n">df_aeropuertos</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;aeropuertos&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span><span class="n">df_join</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select v.*, a.City as originCity, b.City as destinationCity from vuelos v JOIN aeropuertos a on v.origin == a.IATA join aeropuertos b on v.destination = b.IATA&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span><span class="c1"># df_join.count()   # 1361141</span>
<span class="linenos" data-linenos=" 6 "></span><span class="n">df_join</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span><span class="c1"># +-------+-----+--------+------+-----------+----------+---------------+</span>
<span class="linenos" data-linenos="10 "></span><span class="c1"># |   date|delay|distance|origin|destination|originCity|destinationCity|</span>
<span class="linenos" data-linenos="11 "></span><span class="c1"># +-------+-----+--------+------+-----------+----------+---------------+</span>
<span class="linenos" data-linenos="12 "></span><span class="c1"># |1011245|    6|     602|   ABE|        ATL| Allentown|        Atlanta|</span>
<span class="linenos" data-linenos="13 "></span><span class="c1"># |1020600|   -8|     369|   ABE|        DTW| Allentown|        Detroit|</span>
<span class="linenos" data-linenos="14 "></span><span class="c1"># |1021245|   -2|     602|   ABE|        ATL| Allentown|        Atlanta|</span>
<span class="linenos" data-linenos="15 "></span><span class="c1"># +-------+-----+--------+------+-----------+----------+---------------+</span>
<span class="linenos" data-linenos="16 "></span><span class="c1"># only showing top 3 rows</span>
</code></pre></div>
<p>Si tuviéramos algún vuelo con algún código que no tuviéramos disponible en el dataset con los códigos de aeropuertos no nos aparecería. Por tanto, sería más conveniente realizar un left join:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df_left_join</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select v.*, a.City as originCity, b.City as destinationCity from vuelos v LEFT JOIN aeropuertos a on v.origin == a.IATA LEFT JOIN aeropuertos b on v.destination = b.IATA&quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df_left_join</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">df_left_join</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>    <span class="c1"># 1391578</span>
</code></pre></div>
<p>Un caso particular que conviene conocer es el <em>left anti join</em>. Este tipo de <em>join</em> permite obtener aquellos registros de la izquierda que no aparecen en la parte derecha del <em>join</em>, de manera que si seguimos con el ejemplo, podemos recuperar aquellos vuelos cuyos aeropuertos no tenemos en el dataset con los códigos:</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df_left_anti_join</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select * from vuelos v LEFT ANTI JOIN aeropuertos a ON v.origin == a.IATA &quot;</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">df_left_anti_join</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>   <span class="c1"># 14416</span>
</code></pre></div>
<p>!!! </p>
<p>FIXME: continuar - Joins
<a href="https://learning.oreilly.com/library/view/beginning-apache-spark/9781484273838/html/419951_2_En_4_Chapter.xhtml#PC26">https://learning.oreilly.com/library/view/beginning-apache-spark/9781484273838/html/419951_2_En_4_Chapter.xhtml#PC26</a></p>
<h2 id="dataframes-y-pandas">DataFrames y Pandas<a class="headerlink" href="#dataframes-y-pandas" title="Permanent link">&para;</a></h2>
<p>PySpark DataFrame also provides the conversion back to a pandas DataFrame to leverage pandas API. Note that toPandas also collects all data into the driver side that can easily cause an out-of-memory-error when the data is too large to fit into the driver side.</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">df</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="c1"># a b c d e</span>
<span class="linenos" data-linenos="3 "></span><span class="c1"># 0 1 2.0 string1 2000-01-01 2000-01-01 12:00:00</span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># 1 2 3.0 string2 2000-02-01 2000-01-02 12:00:00</span>
<span class="linenos" data-linenos="5 "></span><span class="c1"># 2 3 4.0 string3 2000-03-01 2000-01-03 12:00:00</span>
</code></pre></div>
<p><a href="https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_ps.html">https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_ps.html</a></p>
<h2 id="referencias">Referencias<a class="headerlink" href="#referencias" title="Permanent link">&para;</a></h2>
<ul>
<li>Documentación oficial sobre <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL, DataFrames and Datasets Guide</a></li>
<li><a href="https://sparkbyexamples.com/pyspark/">Spark by Examples</a></li>
<li><a href="https://towardsdatascience.com/the-most-complete-guide-to-pyspark-dataframes-2702c343b2e8">The Most Complete Guide to pySpark DataFrames</a></li>
</ul>
<p><a href="https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html">https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html</a></p>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Volver al principio
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      2021-2022 Aitor Medrano - Licencia CC BY-NC-SA
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/aitormedrano" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    <a href="mailto:<a.medrano@edu.gva.es>" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M464 64c26.5 0 48 21.49 48 48 0 15.1-7.1 29.3-19.2 38.4L275.2 313.6a32.1 32.1 0 0 1-38.4 0L19.2 150.4C7.113 141.3 0 127.1 0 112c0-26.51 21.49-48 48-48h416zM217.6 339.2a63.9 63.9 0 0 0 76.8 0L512 176v208c0 35.3-28.7 64-64 64H64c-35.35 0-64-28.7-64-64V176l217.6 163.2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide", "navigation.top", "navigation.expand", "navigation.tracking", "content.code.annotate"], "search": "../assets/javascripts/workers/search.5e67fbfe.min.js", "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.config.lang": "es", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "B\u00fasqueda", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version.title": "Seleccionar versi\u00f3n"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c44cc438.min.js"></script>
      
    
  </body>
</html>